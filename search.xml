<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Java虚拟线程</title>
      <link href="/f6b1ecf8ea6e/"/>
      <url>/f6b1ecf8ea6e/</url>
      
        <content type="html"><![CDATA[<p>参考：<br><a href="https://www.nasuiyile.cn/794.html">https://www.nasuiyile.cn/794.html</a><br><a href="https://www.jdon.com/76350-synchronized-xunixiancheng.html">https://www.jdon.com/76350-synchronized-xunixiancheng.html</a></p><p>JDK 21 正式推出的虚拟线程（Virtual Thread，JEP 444）是 Java 并发模型的一次重大演进。它旨在以近乎零成本的资源消耗应对海量并发连接，特别适合 IO 密集型应用，可以大大提高 CPU 的使用率，同时保持了与现有线程 API 的完全兼容。</p><h1 id="传统并发模型的瓶颈"><a href="#传统并发模型的瓶颈" class="headerlink" title="传统并发模型的瓶颈"></a>传统并发模型的瓶颈</h1><p>在虚拟线程之前，Java 的并发构建于<strong>平台线程</strong>之上，即对操作系统内核线程的一对一包装。其生命周期与调度完全由操作系统内核管理。</p><p>这种模型在高并发 IO 场景下暴露出固有缺陷：</p><ul><li><strong>资源成本高</strong>：每个线程都需要分配独立的栈内存（通常 MB 级别），创建数千个线程就会消耗大量内存，并触及 OS 的线程数上限。</li><li><strong>调度开销大</strong>：线程的创建、销毁以及上下文切换都涉及昂贵的系统调用（用户态与内核态切换）。</li><li><strong>并发能力受限</strong>：为平衡资源开销与调度成本，应用通常采用线程池。例如，Tomcat 默认工作线程池大小为 200。当所有线程都在等待数据库、网络等 IO 响应时，即便 CPU 空闲，新的请求也无法被处理，形成瓶颈。</li></ul><h1 id="虚拟线程的核心设计"><a href="#虚拟线程的核心设计" class="headerlink" title="虚拟线程的核心设计"></a>虚拟线程的核心设计</h1><p>虚拟线程是 <strong>JVM 实现的轻量级用户态线程</strong>。它不再与 OS 线程绑定，而是由 JVM 负责调度到少量的<strong>载体线程</strong>上执行。</p><p>其核心特性如下：</p><ul><li><strong>极致轻量</strong>：栈内存可动态伸缩，初始占用极小，使得创建数百万个虚拟线程成为可能。</li><li><strong>高效调度</strong>：当虚拟线程执行阻塞操作（如 IO、<code>Thread.sleep</code>）时，JVM 会将其<strong>挂起</strong>，并释放其占用的载体线程，该载体线程可立即去执行其他就绪的虚拟线程。这一切都在<strong>用户态</strong>完成，规避了内核切换的开销。</li><li><strong>无缝兼容</strong>：<code>java.lang.Thread</code> API 保持不变，现有代码几乎无需修改即可使用虚拟线程。</li></ul><h1 id="调度原理"><a href="#调度原理" class="headerlink" title="调度原理"></a>调度原理</h1><p>理解虚拟线程的调度机制是正确使用的关键。</p><h2 id="非抢占式（协作式）用户态调度"><a href="#非抢占式（协作式）用户态调度" class="headerlink" title="非抢占式（协作式）用户态调度"></a>非抢占式（协作式）用户态调度</h2><p>与操作系统内核基于时间片<strong>抢占式</strong>调度平台线程不同，JVM 对虚拟线程采用<strong>非抢占式</strong>调度。虚拟线程只会在遇到<strong>阻塞点</strong>（如 IO 操作、<code>LockSupport.park</code> 等）时主动让出执行权。如果一个虚拟线程永不阻塞，它将独占其载体线程。</p><p>以下代码示例展示了这一特性。首先，我们创建 CPU 核心数个虚拟线程，每个线程都包含一个 <code>sleep(1)</code> 阻塞点：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Main</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">busyThreads</span> <span class="operator">=</span> Runtime.getRuntime().availableProcessors();</span><br><span class="line">        <span class="type">int</span> <span class="variable">newThreadIndex</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        List&lt;Thread&gt; threads = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建并启动&quot;死循环虚拟线程&quot;</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; busyThreads; i++) &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">id</span> <span class="operator">=</span> i;</span><br><span class="line">            <span class="type">Thread</span> <span class="variable">virtualThread</span> <span class="operator">=</span> Thread.ofVirtual()</span><br><span class="line">                    .name(<span class="string">&quot;busy-virtual-thread-&quot;</span> + id)</span><br><span class="line">                    .start(() -&gt; &#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;Busy virtual thread &quot;</span> + id + <span class="string">&quot; started&quot;</span>);</span><br><span class="line">                        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">                            <span class="keyword">try</span> &#123;</span><br><span class="line">                                Thread.sleep(<span class="number">1</span>);</span><br><span class="line">                            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;);</span><br><span class="line">            threads.add(virtualThread);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 等待一会儿，让死循环线程占满平台线程</span></span><br><span class="line">        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建并启动一个新虚拟线程尝试执行</span></span><br><span class="line">        <span class="type">Thread</span> <span class="variable">newVirtualThread</span> <span class="operator">=</span> Thread.ofVirtual()</span><br><span class="line">                .name(<span class="string">&quot;new-virtual-thread-&quot;</span> + newThreadIndex)</span><br><span class="line">                .start(() -&gt; &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;New virtual thread &quot;</span> + newThreadIndex + <span class="string">&quot; started&quot;</span>);</span><br><span class="line">                &#125;);</span><br><span class="line">        threads.add(newVirtualThread);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 等待一会儿查看结果</span></span><br><span class="line">        Thread.sleep(<span class="number">10000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为其他线程的循环中的 <code>sleep</code> 函数将会使这些虚拟线程将当前执行权让给新来的线程，所以这段代码能够成功输出 “New virtual thread”。</p><p>然而，如果我们稍微修改一下代码，移除 <code>sleep</code> 调用，使其变为纯 CPU 循环：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Main</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">busyThreads</span> <span class="operator">=</span> Runtime.getRuntime().availableProcessors();</span><br><span class="line">        <span class="type">int</span> <span class="variable">newThreadIndex</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        List&lt;Thread&gt; threads = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建并启动&quot;死循环虚拟线程&quot;</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; busyThreads; i++) &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">id</span> <span class="operator">=</span> i;</span><br><span class="line">            <span class="type">Thread</span> <span class="variable">virtualThread</span> <span class="operator">=</span> Thread.ofVirtual()</span><br><span class="line">                    .name(<span class="string">&quot;busy-virtual-thread-&quot;</span> + id)</span><br><span class="line">                    .start(() -&gt; &#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;Busy virtual thread &quot;</span> + id + <span class="string">&quot; started&quot;</span>);</span><br><span class="line">                        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">                            <span class="comment">// 纯 CPU 循环，不阻塞</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;);</span><br><span class="line">            threads.add(virtualThread);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 等待一会儿，让死循环线程占满平台线程</span></span><br><span class="line">        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建并启动一个新虚拟线程尝试执行</span></span><br><span class="line">        <span class="type">Thread</span> <span class="variable">newVirtualThread</span> <span class="operator">=</span> Thread.ofVirtual()</span><br><span class="line">                .name(<span class="string">&quot;new-virtual-thread-&quot;</span> + newThreadIndex)</span><br><span class="line">                .start(() -&gt; &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;New virtual thread &quot;</span> + newThreadIndex + <span class="string">&quot; started&quot;</span>);</span><br><span class="line">                &#125;);</span><br><span class="line">        threads.add(newVirtualThread);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 等待一会儿查看结果</span></span><br><span class="line">        Thread.sleep(<span class="number">10000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这时 “New virtual thread” 永远不会输出。这是因为纯 CPU 循环没有阻塞点，虚拟线程永远不会主动让出执行权，从而独占载体线程。这就是非抢占式调度：虚拟线程之间需要 “ 协商 “ 何时释放资源，而协商的契机就是阻塞操作。</p><p>这种调度模式的<strong>好处</strong>是不需要 JVM 定期中断操作，避免了额外的性能开销。<strong>坏处</strong>是如果有 11 个完全不休息的任务（即 11 个虚拟线程）要运行在一个 10 线程的 CPU 上，其中一个任务就会持续无法被调度运行。</p><h2 id="载体线程池与工作窃取算法"><a href="#载体线程池与工作窃取算法" class="headerlink" title="载体线程池与工作窃取算法"></a>载体线程池与工作窃取算法</h2><p>虚拟线程默认由 JVM 全局的 <code>ForkJoinPool</code>（作为载体线程池）进行调度。</p><ul><li><strong>并行度</strong>：池中活跃载体线程数默认等于 CPU 核心数，可通过 <code>-Djdk.virtualThreadScheduler.parallelism</code> 调整。</li><li><strong>工作窃取</strong>：每个载体线程拥有一个本地任务队列。当自身队列为空时，它会从其他线程的队列尾部 “ 窃取 “ 任务，以此实现高效的负载均衡。</li><li><strong>挂载与卸载</strong>：就绪的虚拟线程被挂载到空闲载体线程上运行；遇到阻塞点时，虚拟线程被卸载，载体线程被释放回池。阻塞结束后，虚拟线程被重新排队等待调度。</li></ul><p><strong>重要边界</strong>：虚拟线程的总并发能力受限于载体线程池的规模。默认最大载体线程数为 <code>256</code>（可通过 <code>-Djdk.virtualThreadScheduler.maxPoolSize</code> 调整）。这意味着，如果同时有超过 256 个虚拟线程处于<strong>非阻塞</strong>运行状态，超出的部分将会等待。</p><h1 id="适用场景与使用边界"><a href="#适用场景与使用边界" class="headerlink" title="适用场景与使用边界"></a>适用场景与使用边界</h1><p>虚拟线程是 <strong>IO 密集型任务</strong>的利器，而非万能解药。</p><table><thead><tr><th align="left">推荐场景</th><th align="left">优势</th></tr></thead><tbody><tr><td align="left">Web 服务器 (Spring Boot&#x2F;Tomcat)</td><td align="left">支持海量并发连接，无需复杂线程池调优</td></tr><tr><td align="left">微服务 RPC 调用链</td><td align="left">每个调用可分配独立虚拟线程，避免线程池耗尽导致级联故障</td></tr><tr><td align="left">数据库&#x2F;缓存客户端</td><td align="left">IO 等待期间自动释放资源，提升系统整体吞吐量</td></tr><tr><td align="left">消息队列消费者</td><td align="left">轻松实现高并发消费</td></tr></tbody></table><p><strong>需谨慎或避免的场景</strong>：</p><ul><li><strong>CPU 密集型计算</strong>：无阻塞点，无法发挥调度优势，应用 <code>ForkJoinPool</code> 或固定线程池。</li><li><strong>虚拟线程池化</strong>：创建成本极低，池化反增复杂度。</li><li><strong>在 <code>synchronized</code> 块内阻塞</strong>：可能导致 <strong>Pinning</strong>（钉住），即虚拟线程无法从载体线程卸载，严重降低吞吐量。<strong>应优先使用 <code>ReentrantLock</code></strong>。（注：JDK 24 已优化此问题，但未完全根除）。</li><li><strong>未适配的 Native 方法阻塞</strong>：同样可能引发 Pinning。</li></ul><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><h3 id="Pinning-问题"><a href="#Pinning-问题" class="headerlink" title="Pinning 问题"></a>Pinning 问题</h3><p>什么是 Pinning？<br><strong>Pinning</strong> 是指虚拟线程在阻塞时无法从载体线程卸载，导致载体线程被 “ 钉住 “ 无法执行其他虚拟线程的现象。这会严重降低系统并发能力和吞吐量。</p><p>Pinning 的触发场景：</p><ol><li><strong>synchronized 同步块内阻塞</strong></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PinningExample</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">Object</span> <span class="variable">lock</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Object</span>();</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">blockingMethod</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">synchronized</span> (lock) &#123;  <span class="comment">// 虚拟线程进入synchronized块</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">// 模拟阻塞操作（如数据库查询、网络请求）</span></span><br><span class="line">                Thread.sleep(<span class="number">1000</span>);  <span class="comment">// 虚拟线程无法卸载！</span></span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                Thread.currentThread().interrupt();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li><strong>JNI&#x2F;Native 方法阻塞</strong></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NativePinning</span> &#123;</span><br><span class="line">    <span class="comment">// 加载未适配虚拟线程的本地库</span></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        System.loadLibrary(<span class="string">&quot;unadapted&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 本地方法声明</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title function_">blockingNativeMethod</span><span class="params">()</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">callNative</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 调用可能阻塞的本地方法</span></span><br><span class="line">        blockingNativeMethod();  <span class="comment">// 可能无法卸载</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>为什么 synchronized 会导致 Pinning？<br>Java 中的 <code>synchronized</code> 关键字基于监视器（monitors）实现，其设计存在历史局限性：</p><ol><li><p><strong>监视器绑定平台线程</strong>：Java 的监视器机制与平台线程深度耦合。每个对象都有一个关联的监视器，一次只能有一个线程持有对象的监视器。在 JVM 内部，监视器所有权是<strong>在平台线程（内核线程）层面跟踪的</strong>，而不是在虚拟线程层面。当虚拟线程进入 synchronized 块时，其<strong>载体线程</strong>（平台线程）被记录为监视器的所有者，而不是虚拟线程本身。</p></li><li><p><strong>卸载破坏互斥性</strong>：如果虚拟线程在 synchronized 块内被卸载，其载体线程会被释放回线程池，可能被分配给其他虚拟线程使用。但 JVM 仍然记录该载体线程持有监视器，这会导致：</p><ul><li>新的虚拟线程（使用同一载体线程）被错误地认为持有监视器</li><li>其他试图获取同一监视器的虚拟线程可能被不当阻塞</li><li>这破坏了 synchronized 的互斥语义，因此 JVM 必须阻止虚拟线程在持有监视器时卸载</li></ul></li><li><p><strong>wait&#x2F;notify 机制</strong>：<code>Object.wait()</code> 要求在同一线程上释放和重新获取监视器。如果虚拟线程在执行 synchronized 方法时调用了 <code>Object.wait()</code>，并且虚拟线程在等待期间卸载，当被 <code>notify()</code> 唤醒时，它可能被调度到不同的载体线程上，无法满足 “ 同一线程重新获取监视器 “ 的要求，因此也会被固定。</p></li></ol><p>解决方案：</p><ol><li><strong>使用 ReentrantLock 替代 synchronized</strong>：ReentrantLock 的锁状态通过 <code>AbstractQueuedSynchronizer</code> (AQS) 管理，不依赖线程标识，使用原子变量（<code>AtomicInteger</code>）跟踪锁状态，而不是线程引用。所以 JVM 并不会阻止虚拟线程的卸载。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">ReentrantLock</span> <span class="variable">lock</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ReentrantLock</span>();</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doWork</span><span class="params">()</span> &#123;</span><br><span class="line">    lock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 阻塞操作可以正常卸载</span></span><br><span class="line">        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li><p><strong>升级第三方库</strong>。确保使用的库已适配虚拟线程（支持可中断的阻塞操作）。</p></li><li><p><strong>监控与诊断</strong></p><ul><li>使用 JFR 监控 <code>jdk.VirtualThreadPinned</code> 事件</li><li>通过 <code>-Djdk.tracePinnedThreads=full</code> 参数追踪 Pinning</li></ul></li><li><p><strong>JDK 24+ 的改进</strong><br> JDK 24 通过 JEP 491 大幅减少了 synchronized 导致的 Pinning，但在递归锁等复杂场景下仍可能存在。</p></li></ol><h3 id="ThreadLocal-内存泄漏"><a href="#ThreadLocal-内存泄漏" class="headerlink" title="ThreadLocal 内存泄漏"></a>ThreadLocal 内存泄漏</h3><p>虚拟线程支持创建百万级实例，滥用 <code>ThreadLocal</code> 可能导致严重的内存泄漏。考虑使用 <code>ScopedValue</code>（JDK 21+ 预览，JDK 25 稳定）进行不可变数据传递。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ScopedValue&lt;String&gt; USER_ID = ScopedValue.newInstance();</span><br><span class="line"></span><br><span class="line">ScopedValue.where(USER_ID, <span class="string">&quot;user123&quot;</span>).run(() -&gt; &#123;</span><br><span class="line">    <span class="comment">// 在此作用域内，USER_ID.get() 返回 &quot;user123&quot;</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h1 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h1><h2 id="创建方式"><a href="#创建方式" class="headerlink" title="创建方式"></a>创建方式</h2><p><strong>简单启动</strong>：<code>Thread.startVirtualThread(Runnable task)</code></p><p><strong>构建器模式</strong>（支持命名、配置）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Thread</span> <span class="variable">vt</span> <span class="operator">=</span> Thread.ofVirtual().name(<span class="string">&quot;my-vt&quot;</span>).unstarted(task);</span><br><span class="line">vt.start();</span><br></pre></td></tr></table></figure><p><strong>执行器服务</strong>（推荐，便于管理）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">ExecutorService</span> <span class="variable">executor</span> <span class="operator">=</span> Executors.newVirtualThreadPerTaskExecutor();</span><br><span class="line">Future&lt;String&gt; future = executor.submit(() -&gt; <span class="string">&quot;Hello&quot;</span>);</span><br></pre></td></tr></table></figure><h2 id="结构化并发"><a href="#结构化并发" class="headerlink" title="结构化并发"></a>结构化并发</h2><p>对于有多个并发子任务的场景，使用 <code>StructuredTaskScope</code>（JDK 21+ 预览，JDK 23 稳定）可以极大地简化生命周期和错误处理。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> (<span class="type">var</span> <span class="variable">scope</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructuredTaskScope</span>.ShutdownOnFailure()) &#123;</span><br><span class="line">    Future&lt;String&gt; user = scope.fork(() -&gt; fetchUser());</span><br><span class="line">    Future&lt;Integer&gt; order = scope.fork(() -&gt; fetchOrder());</span><br><span class="line"></span><br><span class="line">    scope.join(); <span class="comment">// 等待所有子任务</span></span><br><span class="line">    scope.throwIfFailed(); <span class="comment">// 统一处理异常</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Result</span>(user.resultNow(), order.resultNow());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="监控与调优"><a href="#监控与调优" class="headerlink" title="监控与调优"></a>监控与调优</h2><ul><li>关注 <strong>Pinning 事件</strong>，可通过 JFR（<code>jdk.VirtualThreadPinned</code>）监控。</li><li>根据应用负载特性，考虑调整载体线程池的并行度（<code>parallelism</code>）和最大大小（<code>maxPoolSize</code>）。</li><li>使用以下 JVM 参数进行诊断：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-Djdk.tracePinnedThreads=full \</span><br><span class="line">-Djdk.virtualThreadScheduler.parallelism=32 \</span><br><span class="line">-Djdk.virtualThreadScheduler.maxPoolSize=512</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol><li><strong>虚拟线程本质</strong>：是 JVM 管理的轻量级用户态线程，通过 “ 阻塞即卸载 “ 的机制，用少量载体线程支撑海量并发。</li><li><strong>调度核心</strong>：采用<strong>非抢占式调度</strong>，依赖阻塞点让出执行权，因此<strong>只适用于包含阻塞操作的任务</strong>。</li><li><strong>正确使用</strong>：将其用于 IO 密集型服务；避免在 CPU 密集型任务和关键路径中使用 <code>synchronized</code>；优先采用 <code>Executors.newVirtualThreadPerTaskExecutor()</code> 和 <code>StructuredTaskScope</code> 进行管理。</li><li><strong>性能关键</strong>：警惕 Pinning 问题，优先使用 <code>ReentrantLock</code> 替代 <code>synchronized</code>，并做好监控。</li></ol><p>虚拟线程的引入不是对现有并发模型的颠覆，而是在特定场景下的极大增强。它让 Java 在高并发 IO 领域拥有了与 Go 等语言的协程相匹敌的能力，同时保持了对现有生态的最大兼容性。</p>]]></content>
      
      
      <categories>
          
          <category> 技术理论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java虚拟线程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux虚拟网络化与隔离技术</title>
      <link href="/086023a35dd3/"/>
      <url>/086023a35dd3/</url>
      
        <content type="html"><![CDATA[<p>参考：<br><a href="https://wiki.archlinux.org/title/Network_bridge">https://wiki.archlinux.org/title/Network_bridge</a><br><a href="https://zhuanlan.zhihu.com/p/549456494">https://zhuanlan.zhihu.com/p/549456494</a></p><p>Linux 的虚拟网络无需额外硬件，仅通过内核软件配置即可实现隔离、虚拟化等功能，是容器化、虚拟机部署的核心基础。<br>虚拟以太网（veth）、网桥（bridge）、macvlan 是最基础常用的三类技术，基于 Namespace、CGroup 和虚拟网络设备驱动实现，核心是在单物理主机上构建独立、可互通的网络环境，适配容器、虚拟机的网络需求。</p><h1 id="虚拟以太网-veth"><a href="#虚拟以太网-veth" class="headerlink" title="虚拟以太网 - veth"></a>虚拟以太网 - veth</h1><p>veth 是 Linux 内核提供的<strong>点对点虚拟网络设备</strong>，核心作用是打通两个独立的网络命名空间（Network Namespace）——网络命名空间是 Linux 实现网络隔离的基础，每个命名空间拥有独立的网卡、IP、路由表，相当于一个“独立的小网络”，而 veth 就是连接这些“小网络”的唯一链路。</p><p>veth 必须成对存在（称为 veth pair），无法单独使用，就像一根两端都有接头的网线，一端插入一个网络命名空间，另一端插入另一个网络命名空间，仅允许这两个命名空间通过该链路通信，与外部网络完全隔离。</p><p>当创建一对 veth 设备（如 veth0 和 veth1）时，内核会为两者建立双向数据通道：</p><ul><li>veth0 分配给主机命名空间，veth1 分配给容器命名空间；</li><li>容器数据包经 veth1 传至 veth0，由主机协议栈（如 NAT）处理后实现联网；</li><li>主机数据包经 veth0 传至 veth1，进入容器命名空间。</li></ul><p>注：veth 本身不具备路由、NAT、桥接能力，仅负责数据转发，容器要访问外网，必须依赖主机的网络协议栈做额外处理。</p><h1 id="网桥-bridge"><a href="#网桥-bridge" class="headerlink" title="网桥 - bridge"></a>网桥 - bridge</h1><p>网桥（又称虚拟网桥）是 Linux 内核提供的<strong>二层网络交换设备</strong>，本质是一个软件版的交换机。它的核心作用是将多个物理网卡、虚拟网卡（如 veth）桥接到同一个广播域，让所有连接到网桥上的设备，共享同一网络链路，相当于所有设备都插在同一个物理交换机上，可直接互通，无需经过路由转发。</p><p>与 veth 的点对点通信不同，网桥支持一对多通信，能够连接多个网络命名空间、物理设备，是构建多设备虚拟局域网（LAN）的核心技术。</p><p>网桥的工作机制与物理交换机类似，核心是 MAC 地址学习和数据包转发：</p><ul><li>当网桥启动后，会监听所有连接到它的网卡（物理网卡、veth 等）的数据包，记录每个网卡对应的设备 MAC 地址，形成一张 MAC 地址表；</li><li>当收到数据包时，网桥会查看数据包的目标 MAC 地址，根据 MAC 地址表，将数据包转发到对应的网卡（仅转发到目标设备，不广播到所有设备）；</li><li>若网桥未在 MAC 地址表中找到目标 MAC 地址，则会将数据包广播到所有连接的网卡，直到目标设备响应，再更新 MAC 地址表。</li></ul><p>在容器场景中，通常会将主机的物理网卡（如 wlan0、eth0）桥接到网桥上，再将容器的 veth 网卡也连接到网桥上——这样，容器、主机、局域网其他设备就处于同一个广播域，可直接互通，容器无需依赖主机 NAT 转发就能访问外网。</p><p>使用参考文档：<br><a href="https://segmentfault.com/a/1190000009491002#item-4">https://segmentfault.com/a/1190000009491002#item-4</a></p><h1 id="macvlan"><a href="#macvlan" class="headerlink" title="macvlan"></a>macvlan</h1><p>macvlan 是 Linux 内核提供的<strong>物理网卡虚拟化技术</strong>，核心作用是在单块物理网卡上，生成多个独立的虚拟网卡（称为 macvlan 子接口），每个子接口拥有独立的 MAC 地址——相当于给物理网卡分身，每个分身都能独立工作，直接共享物理网卡的网络链路，无需经过网桥、veth 等中间层。</p><p>与 veth、网桥不同，macvlan 无需依赖其他虚拟设备，直接让容器挂靠在物理网卡上，成为局域网内的独立设备，在路由器看来，容器与主机是平级的两个设备，均能通过 DHCP 获取局域网 IP。</p><p>macvlan 的工作原理非常简单，本质是 MAC 地址隔离与转发：</p><ul><li>在物理网卡（如 wlan0）上创建多个 macvlan 子接口（如 mv-wlan0、mv-wlan1），每个子接口分配独立的 MAC 地址；</li><li>将每个子接口分配给一个容器，容器将该子接口作为自身的默认网卡；</li><li>容器发送的数据包，会携带自身子接口的 MAC 地址，通过物理网卡直接发送到路由器，路由器根据 MAC 地址和 IP 地址，将数据包转发到目标设备；</li><li>外部设备发送给容器的数据包，路由器会根据容器的 MAC 地址，通过物理网卡转发到对应的 macvlan 子接口，再传递到容器内部。</li></ul><p>macvlan 支持多种模式（如 bridge、private、vepa 等），其中最常用的是 bridge 模式，允许同一物理网卡上的多个 macvlan 子接口之间互相通信，同时也能与局域网其他设备互通。</p><p>macvlan 适合容器需要独立局域网 IP、配置简单、高速互通的场景，<strong>是单机容器需获得局域网独立 IP 场景的最轻量高效方案</strong></p><p>关于 macvlan 的 bridge 模式与传统 Linux 网桥（bridge）：</p><ul><li>macvlan 的 <code>bridge</code>：是 macvlan 网卡虚拟化的一种工作模式，作用是让同一物理网卡上的多个 macvlan 子接口之间、子接口与局域网其他设备之间能互通，无任何虚拟交换机组件；</li><li>传统网桥（bridge）：本身就是虚拟二层交换机，「bridge」是其技术本质，所有桥接设备的流量都需经该虚拟交换机转发、寻址。</li></ul><p>所以 macvlan 的 bridge 模式更加节省 CPU、内存，同时网络延迟更低，吞吐率更高。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><table><thead><tr><th>对比维度</th><th>虚拟以太网（veth）</th><th>网桥（bridge）</th><th>macvlan</th></tr></thead><tbody><tr><td>技术本质</td><td>点对点虚拟链路，命名空间通信工具</td><td>虚拟二层交换机，多设备桥接组网</td><td>物理网卡虚拟化，单网卡分身扩容</td></tr><tr><td>网络隔离性</td><td>强隔离：仅两命名空间互通</td><td>弱隔离：同广播域，无隔离</td><td>中等隔离：容器独立，局域网互通</td></tr><tr><td>IP 网段</td><td>主机私有网段，与局域网无关</td><td>局域网网段，与主机同段</td><td>局域网网段，与主机同段</td></tr><tr><td>互通性</td><td>仅主机↔容器互通</td><td>全互通（主机、容器、局域网）</td><td>容器↔局域网互通，主机↔容器需经路由器回环</td></tr><tr><td>上网方式</td><td>依赖主机 NAT+iptables</td><td>直连路由器，无需 NAT</td><td>直连路由器，无需 NAT</td></tr><tr><td>配置复杂度</td><td>低，默认自动创建</td><td>高，需手动创建桥接</td><td>极低，仅指定物理网卡</td></tr><tr><td>MAC 地址</td><td>容器端有独立 MAC（宿主机内可见），对外部网络可见性取决于是否桥接&#x2F;NAT</td><td>无独立 MAC，复用 veth</td><td>有独立 MAC，子接口唯一</td></tr><tr><td>使用场景</td><td>容器仅需与主机通信</td><td>多设备组网，需全互通</td><td>容器需局域网 IP，配置简单</td></tr></tbody></table><h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><p>除三类基础技术外，以下 4 种进阶方案适配复杂场景：</p><h2 id="ipvlan"><a href="#ipvlan" class="headerlink" title="ipvlan"></a>ipvlan</h2><p>ipvlan 与 macvlan 同属物理网卡虚拟化技术，工作原理几乎一致，核心区别是：<strong>ipvlan 的所有子接口共享物理网卡的 MAC 地址，仅 IP 地址不同</strong>，而 macvlan 的每个子接口有独立的 MAC 地址。</p><p>适配场景：路由器限制 MAC 地址数量（如部分企业路由器仅允许单个 MAC 地址接入），此时使用 ipvlan，所有容器共享主机 MAC 地址，可正常获取局域网 IP；<br>不适用于需要独立 MAC 地址的场景（如路由器基于 MAC 地址分配固定 IP）。</p><h2 id="macvtap"><a href="#macvtap" class="headerlink" title="macvtap"></a>macvtap</h2><p>macvtap 是 macvlan 的衍生技术，专门为虚拟机（如 KVM、QEMU）设计，本质是将 macvlan 与 tap 设备（虚拟机与主机的网络接口）结合，实现虚拟机与物理网卡的直接连接。</p><p>与 macvlan 相比，macvtap 支持更多的虚拟化场景，能够更好地适配虚拟机的网络 IO，降低延迟，同时保留了 macvlan“直连局域网、配置简单”的优势。</p><p>适配场景：虚拟机需要直连局域网，获取独立 IP，追求高速网络 IO；<br>不适合容器场景（容器用 macvlan 更简洁）。</p><h2 id="Open-vSwitch"><a href="#Open-vSwitch" class="headerlink" title="Open vSwitch"></a>Open vSwitch</h2><p>Open vSwitch（简称 OVS）是一款开源的高级虚拟交换机，功能远超 Linux 原生网桥，支持 VLAN、VXLAN、GRE 等多种网络协议，能够实现跨主机组网、流量控制、端口镜像、网络隔离等高级功能。</p><p>与原生网桥相比，OVS 的优势在于可管理性和扩展性，支持通过命令行、API、Web 界面管理，能够适配大规模容器&#x2F;虚拟机集群（如跨主机的容器集群），是企业级部署的首选方案。</p><p>适配场景：多主机容器集群（如 K8s 集群）、企业级虚拟机部署，需要高级网络管理（如流量监控、访问控制）；<br>不适用于简单场景，配置复杂。</p><h2 id="VXLAN"><a href="#VXLAN" class="headerlink" title="VXLAN"></a>VXLAN</h2><p>VXLAN（虚拟可扩展局域网）是一种隧道技术，核心作用是突破物理网络限制，实现跨主机的虚拟网络互通——当容器部署在多台物理主机上时，VXLAN 可以在物理网络之上，构建一个虚拟的二层网络，让不同主机上的容器，仿佛处于同一个局域网，可直接互通。</p><p>VXLAN 通常与 OVS、Docker Swarm、K8s 等工具结合使用，解决跨主机容器通信的问题，是云原生场景下的核心网络技术。</p><p>适配场景：多主机容器集群、跨机房部署，需要容器之间跨主机直接通信；<br>不适用于单主机场景（无需隧道转发，徒增延迟）。</p>]]></content>
      
      
      <categories>
          
          <category> GNU/Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Raft阅读随记</title>
      <link href="/15c78de5d315/"/>
      <url>/15c78de5d315/</url>
      
        <content type="html"><![CDATA[<h1 id="Raft-特性总结"><a href="#Raft-特性总结" class="headerlink" title="Raft 特性总结"></a>Raft 特性总结</h1><p>集群任何时候，都将满足以下特性：</p><table><thead><tr><th>特性</th><th>解释</th></tr></thead><tbody><tr><td>选举安全特性</td><td>对于一个给定的任期号，最多只会有一个领导者被选举出来</td></tr><tr><td>领导者只附加原则</td><td>领导者绝对不会删除或者覆盖自己的日志，只会追加新条目</td></tr><tr><td>日志匹配原则</td><td>如果两个日志在相同索引位置包含一个具有相同任期号的条目，那么这两个日志在该索引位置之前的所有条目都完全相同</td></tr><tr><td>领导者完全特性</td><td>如果某个日志条目在某个任期号中已经被提交，那么这个条目必然出现在更大任期号的所有领导者中</td></tr><tr><td>状态机安全特性</td><td>如果某一服务器已将给定索引位置的日志条目应用至其状态机中，则其他任何服务器在该索引位置不会应用不同的日志条目</td></tr></tbody></table><h1 id="Raft-基础"><a href="#Raft-基础" class="headerlink" title="Raft 基础"></a>Raft 基础</h1><h2 id="复制状态机"><a href="#复制状态机" class="headerlink" title="复制状态机"></a>复制状态机</h2><p>复制状态机包括 共识算法，状态机，日志。多个服务器的这三者组成复制状态机，形成 raft group。</p><p>目的是为了让服务器形成一个单独的，高度可靠的状态机。</p><h2 id="拜占庭将军问题"><a href="#拜占庭将军问题" class="headerlink" title="拜占庭将军问题"></a>拜占庭将军问题</h2><p>拜占庭将军问题：<strong>在存在消息丢失的不可靠信道上试图通过消息传递的方式达到一致性是不可能的</strong>。<strong>拜占庭将军中可能存在叛徒，发送虚假的消息；即节点故意试图破坏系统，故意发送错误的或破坏性的响应</strong>。例如节点明明没有收到某条消息，但却对外声称收到了。这种行为称为拜占庭故障。在这样不信任的环境中需要达成共识的问题也被称为拜占庭将军问题。</p><p>Raft 算法不解决拜占庭将军问题，默认节点无恶意，仅可能出现崩溃故障。</p><h2 id="高可用而不是完全可用"><a href="#高可用而不是完全可用" class="headerlink" title="高可用而不是完全可用"></a>高可用而不是完全可用</h2><p>Raft 算法存在可用性限制，它实现的是高可用，而非完全可用。例如，5 个服务器组成的集群，最多允许 2 个服务器宕机，剩余 3 个正常节点可维持集群正常工作；若宕机节点数超过容错阈值，集群将无法提供服务。</p><h2 id="CAP-理论：CP"><a href="#CAP-理论：CP" class="headerlink" title="CAP 理论：CP"></a>CAP 理论：CP</h2><p>CAP 理论：P 一定成立，在 C 和 A 中只有一个能成立。<br>Raft 算法属于 CP 模型，优先保证一致性，且其一致性为强一致性（即线性一致性）——集群中所有节点对同一请求的响应，始终与“单节点处理该请求”的结果一致。</p><h1 id="Raft-算法核心"><a href="#Raft-算法核心" class="headerlink" title="Raft 算法核心"></a>Raft 算法核心</h1><h2 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h2><h3 id="提交之前任期内的日志条目"><a href="#提交之前任期内的日志条目" class="headerlink" title="提交之前任期内的日志条目"></a>提交之前任期内的日志条目</h3><p>Raft 中的所有讨论，提交都是一个单点的状态，而非集群的状态。</p><p>会不会出现这种情况：Leader 和 follower 提交之间必然会间隔一段时间，如果 Leader 提交之后直接返回客户端，在通知 follower 提交之前，也就是一个心跳的时间之内，在此时 Leader 宕机了，是不是就可能会出现返回 client 成功，但是提交状态在集群上没有被保留？</p><p>这个问题可以用 Raft 的两个机制解决：</p><ul><li>请求投票 RPC 中包含了候选人的日志信息，然后投票人会拒绝掉那些日志没有自己新的投票请求。判断方式是通过比较两份日志中最后一条日志条目的任期号、索引值和任期号比较谁的日志更新。</li><li>Raft 永远不会通过计算副本数目的方式去提交一个之前任期内的日志条目。只有领导人当前任期里的日志条目通过计算副本数目可以被提交；一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配特性，之前的日志条目也都会被间接的提交。</li></ul><p>客户端的成功响应是有效的，集群必然保留提交状态。</p><p>因为如果 Leader 未复制到半数以上节点就宕机了，那么即使一个未复制该条目的跟随者也能获得选举成为 Leader，因为完成复制该日志条目的节点只是少数派，该日志条目即使被下一个领导者覆盖掉也是合法的。</p><p>但是，若此时半数以上节点已经持久化复制了该日志，Leader 仅本地提交了日志、没来得及通知跟随者就宕机，那么下一个 Leader 只会从已复制该日志的跟随者选出，并且该日志最终会被提交。<br>因为即使有一个未复制该日志的节点率先选举超时发起投票，该节点的选举必然失败：因为该节点成为候选人后，仅会将<strong>竞选任期</strong>递增，即使其最后的日志条目任期与多数节点一致，但因少复制了一条日志导致日志最后索引更短，会被大部分节点拒绝投票，更别说有覆盖日志的能力了。<br>所以<strong>下一个 Leader 必然是拥有旧任期的日志条目</strong>。</p><p>要记得，Raft 中只有当前任期的日志条目才可直接通过计算副本数目确认提交；旧任期日志若被当前 Leader 提交，必然是通过当前任期的日志间接提交，这也意味着当前任期已有日志被复制到半数以上节点，半数以上节点的日志任期与长度必然是最新最长的。<br>而 Raft 通过当前任期的日志条目提交，之前的日志条目也都会被间接的提交的机制，不会被其他情况导致该之前任期已复制到多数派节点的日志条目被覆盖。</p><p>所以这个日志条目最终还是会被提交，并不会出现返回 client 成功，但是提交状态在集群上没有被保留的情况。</p><h3 id="可用性与时间依赖"><a href="#可用性与时间依赖" class="headerlink" title="可用性与时间依赖"></a>可用性与时间依赖</h3><blockquote><p>Raft 的安全性不能依赖时间；但可用性（系统可以及时的响应客户端）不可避免的要依赖于时间。如果消息交换比服务器故障间隔时间长，候选人将没有足够长的时间来赢得选举；没有一个稳定的领导人，Raft 将无法工作。</p></blockquote><p>先回顾一下 Raft 的选举流程：<br>超时的触发，严格以「节点收到上一次合法心跳（AppendEntries RPC）的时间」为基准；若超过选举超时时间未收到任何合法心跳（或有效 Candidate 的 RequestVote RPC），则该 Follower 转为 Candidate 并发起选举。</p><p>案例：节点瞬断瞬启，平均故障间隔时间 &lt; 选举超时时间，导致系统可用性问题。</p><p>集群状态：<br>5 节点集群（<code>S1~S5</code>），S1 是 Leader，选举超时配置 <code>150~300ms</code> 随机（假设 S5 一直是最短的选举超时时间）。Leader 发送心跳的时间间隔为 50ms，且只需要 5ms 内就能到达所有跟随者；跟随者节点期望下次收到心跳时间间隔在 <code>50+5ms容忍时间</code> 内。</p><p>集群动作：</p><table><thead><tr><th>时间</th><th>S1 状态</th><th>S5 上次收心跳</th><th>期望最晚接收</th><th>计时长</th><th>剩余超时</th><th>集群行为</th></tr></thead><tbody><tr><td>0ms</td><td>首次发心跳</td><td>-</td><td>-</td><td>0ms</td><td>150ms</td><td>集群初始化，S1 向全节点发送首次心跳</td></tr><tr><td>5ms</td><td>正常运行</td><td>5ms</td><td>60ms</td><td>0ms</td><td>150ms</td><td>全节点 5ms 收到心跳，首次更新收心跳时间，重置选举计时器，计算首次期望最晚 60ms</td></tr><tr><td>50ms</td><td>正常运行</td><td>5ms</td><td>60ms</td><td>0ms</td><td>150ms</td><td>S1 按 50ms 间隔发第 2 次心跳，符合配置</td></tr><tr><td>55ms</td><td>正常运行</td><td>55ms</td><td>110ms</td><td>0ms</td><td>150ms</td><td>全节点 55ms 收到心跳，更新收心跳时间，重置计时器，重新计算期望最晚 110ms</td></tr><tr><td>95ms</td><td>突发宕机</td><td>55ms</td><td>110ms</td><td>0ms</td><td>150ms</td><td>S1 停止发第 3 次心跳，跟随者暂未感知（未到 110ms 最晚时间）</td></tr><tr><td>110ms</td><td>宕机中</td><td>55ms</td><td>110ms</td><td>0ms</td><td>150ms</td><td>到达期望最晚接收时间，S5<strong>正式启动选举计时器</strong>，计时长从 0 开始累计</td></tr><tr><td>195ms</td><td>重启完成</td><td>55ms</td><td>110ms</td><td>85ms</td><td>65ms</td><td>S1 宕机 100ms 后重启，立即发送<strong>旧 Term 合法心跳</strong>（Term 未变，合法）</td></tr><tr><td>200ms</td><td>重启稳定</td><td>200ms</td><td>255ms</td><td>0ms</td><td>150ms</td><td>全节点 200ms 收到心跳（195+5），<strong>强制重置所有计时</strong>，更新收心跳时间 + 重新计算期望最晚 255ms</td></tr><tr><td>250ms</td><td>正常发心跳</td><td>200ms</td><td>255ms</td><td>0ms</td><td>150ms</td><td>S1 按 50ms 间隔发重启后第 1 次心跳</td></tr><tr><td>255ms</td><td>正常运行</td><td>255ms</td><td>310ms</td><td>0ms</td><td>150ms</td><td>全节点 255ms 收到心跳，更新收心跳时间，重置计时器，计算期望最晚 310ms</td></tr><tr><td>305ms</td><td>再次宕机</td><td>255ms</td><td>310ms</td><td>0ms</td><td>150ms</td><td>S1 停止发下一次心跳，跟随者暂未感知（未到 310ms 最晚时间）</td></tr><tr><td>310ms</td><td>宕机中</td><td>255ms</td><td>310ms</td><td>0ms</td><td>150ms</td><td>到达期望最晚接收时间，S5<strong>再次启动选举计时器</strong>，计时长从 0 开始累计</td></tr><tr><td>405ms</td><td>再次重启完成</td><td>255ms</td><td>310ms</td><td>95ms</td><td>55ms</td><td>S1 宕机 100ms 后重启，立即发送<strong>旧 Term 合法心跳</strong></td></tr><tr><td>410ms</td><td>重启稳定</td><td>410ms</td><td>465ms</td><td>0ms</td><td>150ms</td><td>全节点 410ms 收到心跳（405+5），强制重置所有计时，更新时间 + 计算新期望最晚 465ms</td></tr></tbody></table><p>所以，Raft 可以选举并维持一个稳定的领导人，只要系统满足下面的时间要求：</p><blockquote><p>广播时间（broadcastTime） &lt;&lt; 选举超时时间（electionTimeout） &lt;&lt; 平均故障间隔时间（MTBF）</p></blockquote><h1 id="集群成员变化"><a href="#集群成员变化" class="headerlink" title="集群成员变化"></a>集群成员变化</h1><h2 id="自动配置变更的流程"><a href="#自动配置变更的流程" class="headerlink" title="自动配置变更的流程"></a>自动配置变更的流程</h2><p>集群配置对每个节点来说，就是一份本地持久化的「集群有效成员白名单 + 规则表」，核心包含两个关键信息：</p><ul><li><strong>集群所有有效节点的唯一标识</strong>：通常是「节点 ID + 固定网络地址（IP + 端口）」；</li><li><strong>基于当前成员数量的共识规则</strong>：比如多少节点算多数派（3 节点需 2 票、4 节点需 3 票、5 节点需 3 票），这是节点自动根据成员数量计算的，无需手动配置。</li></ul><p><strong>每个节点一旦将新配置条目添加到自身的日志中，新配置便立即在该节点生效</strong>：C<sub>new</sub> 条目会被复制到新配置包含的所有节点，且系统会以新配置下的多数派节点为依据，判定该 C<sub>new</sub> 条目是否提交。这意味着节点无需等待配置条目完成提交，而是始终使用自身日志中最新的配置。</p><p>当 C<sub>new</sub>​ 条目完成提交时，本次配置变更即宣告完成。此时领导者能够确认：新配置 C<sub>new</sub> ​已被多数派的新配置节点采纳；同时也能确定，所有未切换至 C<sub>new</sub> ​的节点已无法构成集群的多数派，且未采纳 C<sub>new</sub> ​的节点也无法被选举为领导者。C<sub>new</sub>​ 的提交使得以下三类操作可以正常执行：</p><ol><li>领导者可向请求方确认配置变更已成功完成；</li><li>若本次配置变更涉及节点移除，则被移除的节点可被下线；</li><li>可启动后续的配置变更操作。在此之前，若叠加执行配置变更，可能会导致集群陷入图 10 所示的不安全状态。</li></ol><h2 id="配置不一致形成多个独立子集群"><a href="#配置不一致形成多个独立子集群" class="headerlink" title="配置不一致形成多个独立子集群"></a>配置不一致形成多个独立子集群</h2><p>形成过程（不使用联合共识机制，且一次性增减多个节点的结果）：</p><p><img src="/15c78de5d315/raft-%E5%9B%BE10.png" alt="图 10"></p><p>在上图例子中，集群配额从 3 台机器（排除 Leader）变成了 5 台。其中 S1&#x2F;S2&#x2F;S3 是老节点，S4&#x2F;S5 是新增节点。假设扩容前 C<sub>old</sub> 的 Leader 为 S3。</p><blockquote><p>S1&#x2F;S2 不会是老集群的 Leader，因为他们的日志都没有新配置，一个节点如果接收到新配置日志条目，会立即应用。</p></blockquote><p>可能存在某一个时间点（箭头处），S1&#x2F;S2 仍然是老配置，视为在老集群，S3&#x2F;S4&#x2F;S5 是新配置，视为已经在新集群。（节点的方框处在绿色意味老配置，蓝色为已切换为新配置。这个时间点，S3 已切换至新配置，但仍维持原 Leader 身份，向所有节点发送心跳。）</p><p>这时候 Leader 突然宕机了，那么节点们收不到心跳选举超时发起投票。<br>在这个时候，节点们因配置不同，可以看成两个集群：</p><ul><li>C<sub>old</sub> ：包含 S1&#x2F;S2&#x2F;S3，多数派阈值为 2；</li><li>C<sub>new</sub> ：包含 S1&#x2F;S2&#x2F;S3&#x2F;S4&#x2F;S5，多数派阈值为 3；</li></ul><p>C<sub>old</sub> 选举 Leader：S1 先达到选举超时时间，将自身任期加 1，并发起投票请求。这时 S3 无响应，但 S1 凭借自身与 S2 的投票成为 Leader。（S1&#x2F;S2 因老配置，会忽视 S4&#x2F;S5 的投票请求，也不会向 S4&#x2F;S5 发出投票请求）</p><p>与此同时，C<sub>new</sub> 的选举也在进行：S4 达到选举超时时间，发起投票请求。S4 基于新配置，向认知中的集群成员（S1&#x2F;S2&#x2F;S3&#x2F;S4&#x2F;S5）发送投票请求。其中 S1&#x2F;S2 已归属于老集群，收到请求后，并不认可新配置的集群成员范围，直接拒绝投票；S3 宕机无响应；仅 S5 收到请求。所以 S4 只能得到自身与 S5 的投票共 2 票。未达到新配置多数派阈值（3），选举暂时失败，进入下一轮超时倒计时。若此时刚好 S3 恢复，将直接改变新配置集群的选举格局。S3&#x2F;S4&#x2F;S5 必然能选出一个新的节点作为 Leader，因为投票已经可以满足多数派阈值，此时出现第二个 Leader。此处假设 S5 成为 Leader。</p><p>此时老配置集群中，S1（Leader）仍向 S2 发送心跳，维持自身 Leader 身份，但 S1、S2 仅认可老配置，不会响应 S5 的心跳或日志同步请求；S5 作为新配置集群 Leader，也不会认可 S1 的 Leader 身份，仅向新配置节点（S3、S4）同步日志、发送心跳，集群分裂状态暂时保留。最终形成了两个独立子集群各有一个 Leader，产生数据不一致的情况。</p><p>解决方案有两个：</p><ul><li>二阶段协议（联合共识）：先同步 “新旧配置共存” 的联合配置，所有决议需同时满足新旧配置多数派（老≥2 票、新≥3 票），阻断局部选举；待联合配置全量确认后，再切换至新配置，从根源避免双认知集群。</li><li>单节点变更机制：<strong>当仅向集群添加&#x2F;移除一个节点时，旧集群的任意多数派与新集群的任意多数派之间必然存在重叠，以此保证安全性</strong>。</li></ul><p>这里只说 Raft 论文推荐的是更易于理解、简单的单节点变更机制：</p><p><img src="/15c78de5d315/4_3.png" alt="图 4.3"></p><p>无论原集群是基&#x2F;偶数节点，单节点变更机制都是安全的。<br>假设这个机制是不安全的，反向推演，你会发现：如果要分裂出两个独立的集群，那么必须有一个节点既给 C<sub>old</sub> 的候选人投了票，又给了 C<sub>new</sub> 的候选人投了票。这个做法是有矛盾的：每一个节点都会持久化当前的任期和投票选择，只会给一个候选者投票。</p><p>如在 4 节点的原集群（多数派阈值为 3）加入一个节点成为 5 节点的集群（多数派阈值为 3），只有当集群有 6 个节点时（每个节点只能投一票）某一时刻新旧集群才能各自选出自己的 Leader，但此时是不可能的，因为整个集群只有 5 个节点。所以必须要有一个节点投出两票分别给新旧集群，而在上文已经论述了，这种情况也是不可能发生的。</p><p>当然，如果要添加新的 2 个节点成为新集群，那肯定要拆分为一个一个地添加，并且再次添加节点时，需要前一个添加请求被多数派节点复制、提交日志。否则依旧是不安全的更改集群配置。</p><h2 id="新节点日志追平"><a href="#新节点日志追平" class="headerlink" title="新节点日志追平"></a>新节点日志追平</h2><p>更新集群配置后，如加入新节点，新节点的日志是空白的。如果是个 4 节点集群 S1&#x2F;S2&#x2F;S3&#x2F;S4（原本为 3，S1 为 Leader，S4 是新加入的），此时 Leader 宕机了，假设 S2 先选举超时，他可以从自己、S3&#x2F;S4 获得 3 张投票成为 Leader。若现在客户端发送一条记录需要同步日志，则 S2 需要把日志条目复制到 S3&#x2F;S4 才能提交，S3 因为是老节点，日志没有落后太多所以不会出太大问题；但是 S4 是空日志&#x2F;日志大幅落后的新节点，其日志中根本没有领导者待追加条目对应的 “前一条目索引 + 任期” 记录（或记录不匹配），日志一致性检查未通过，因此会持续拒绝领导者的 AppendEntries RPC。直到 S2 让 S4 复制完历史日志条目，S4 才能接收最新的日志条目。<br>但如果 S4 缺失的日志非常多，达到一定的量之后，复制历史数据就成为了耗时操作，所以 S4 迟迟不能复制最新的日志条目，导致 S2、或者说整个集群无法提交这个新的日志条目，系统对外就不可用了。</p><p>Raft 选择的方案是：<br>新节点以<strong>非投票节点</strong>的身份加入集群。领导者会向其复制日志条目，但在投票和日志提交的多数派计算中，该节点暂不被纳入统计。待新节点的日志追平集群其他节点后，配置变更即可按前述流程执行。<br>复制的过程中，领导者向新节点的日志条目复制过程分轮次进行。每一轮的操作，领导者在本轮开始时日志中存在的所有条目，全部复制至新节点的日志。若以新节点可能会接收好几次的日志同步，耗时会一次比一次少（因为这个过程是 Leader 上一次的未复制日志，属于增量复制）。当某一次新节点复制耗时小于一个选举超时时间，则领导者可将新节点正式加入集群。</p><h2 id="干扰节点"><a href="#干扰节点" class="headerlink" title="干扰节点"></a>干扰节点</h2><p>以往的选举发生情况一般是原 Leader 宕机&#x2F;转交，但 Leader 权都不会被强行剥夺。<br>而如果无额外机制的情况下，在变更集群配置时可能会产生 Leader 权强行被非 Cnew 节点剥夺的情况，从而影响更改配置的流程。</p><p><strong>无额外机制</strong>：无心跳防护、无配置过滤、节点处理 <code>RequestVote</code> 仅按<strong>原生规则</strong>，且<strong>配置仅在提交后生效</strong>。</p><p><img src="/15c78de5d315/4_7.png" alt="图 4.7"></p><p>当然这是一个比较极端的情况，如图：<br>Cold：S1&#x2F;S2&#x2F;S3&#x2F;S4（4 节点），移除 S1 后 Cnew：S2&#x2F;S3&#x2F;S4（3 节点）<br>S4 为原 Leader，<strong>已在自身日志生成 Cnew 条目，但尚未向 S2&#x2F;S3 复制该条目</strong>（最易干扰的临界状态，也是分布式场景中极常见的瞬间）；<br>因为 S1 不是 Cnew 成员，所以 S4 停止向 S1 发心跳与日志，而 S2&#x2F;S3 还是 Cnew 成员所以发送了心跳再发送了 Cnew 配置条目。S1 因心跳中断，触发选举超时自身 <code>任期 +1</code>，向 Cold 发送 <code>RequestVote</code>。与此同时，S2&#x2F;S3 并未复制到 Cnew 配置到日志条目，并且未选举超时。那么 S2&#x2F;S3 是会给 S1 投票的，当然 S4 也会因为自身任期比 S1 更小而退化为跟随者（先比较的是自身任期而不是最后一条日志条目的任期，不过这已经不重要，拥有 <code>S2/S3 + 自身</code> 的投票已经满足多数派阈值）。</p><p>此时 S1 当选 Leader ，Cnew 配置条目完全无法同步到新集群节点，被永久丢失，集群中所有节点的日志均回到无 Cnew 的 Cold 状态。S1 作为 Leader，会以<strong>旧配置 Cold（S1&#x2F;S2&#x2F;S3&#x2F;S4）</strong> 管理集群，认定 S1 仍是合法节点，后续集群将持续以 4 节点旧配置运行，直到管理员（客户端）重新发起移除 S1 的配置变更操作。</p><p>Raft 最终采用的解决方案是：<strong>通过心跳包判断集群是否存在有效的领导者</strong>。</p><blockquote><p>在 Raft 中，若领导者能持续向跟随者发送心跳包，则认为该领导者处于活跃状态（否则其他节点会发起选举）。因此，对于能正常接收领导者心跳包的集群，其他节点不应能对其造成干扰。我们通过修改 <code>RequestVote</code> RPC 实现这一逻辑：若节点在<strong>最小选举超时时间</strong>内收到过现任领导者的心跳包，当它再接收到 <code>RequestVote</code> 请求时，不会更新自身的任期号，也不会投出选票。该节点可直接丢弃请求、回复拒绝投票，或延迟处理请求，三种方式的实际效果基本一致。这一修改不会影响正常的选举流程 —— 因为正常情况下，每个节点都会等待至少一个最小选举超时时间后，才会发起选举。但它能有效避免未被纳入 Cnew 的节点造成的干扰：只要领导者能持续向其配置内的节点发送心跳包，就不会因其他节点的更大任期号而被废黜。</p></blockquote><p>简单来说就是通过心跳机制，跟随者在心跳有效期前收到任何的 <code>RequestVote</code> RPC 都将被拒绝；只有最小选举时间到期都没有收到心跳，才接受 <code>RequestVote</code> RPC 。</p><p>该修改会与前文描述的领导者移交机制产生冲突 —— 在<strong>领导者移交</strong>过程中，节点可无需等待选举超时，合法发起选举。针对该场景，其他节点即使感知到集群存在现任领导者，也仍需处理该 <code>RequestVote</code> 请求。解决方案是：在这类 <code>RequestVote</code> 请求中添加一个<strong>特殊标记</strong>，用于标识该选举的合法性（即 “我获得了干扰领导者的许可 —— 是它让我发起的选举！”）。</p><p>当然，<strong>心跳机制无法 100% 保证不被干扰</strong>，该心跳防护机制仅能<strong>大幅降低非新配置节点当选 Leader 的概率</strong>，但因分布式系统<strong>异步性（网络丢包、节点时钟漂移、RPC 延迟）</strong> 的底层不可控性，仍有较小的时间空档或 Leader 直接宕机等原因，不存在能 100% 杜绝该问题的单一机制。</p><h1 id="日志压缩"><a href="#日志压缩" class="headerlink" title="日志压缩"></a>日志压缩</h1><p>Raft 节点是个<strong>键值对状态机</strong>，核心就是执行「增 &#x2F; 删 &#x2F; 改」的日志指令，日志是<strong>一条条操作记录</strong>，状态机执行日志时会实时合并操作，只留<strong>最终的键值结果</strong>；<br>也就是说状态机始终记录着此时键值的最终结果，其体积随业务有效数据和集群元数据缓慢变化；而日志会因为对任意键值对的任意操作持续膨胀，远快于状态机。<br>当日志足够大时，会产生一系列性能问题导致集群不可用，所以我们要对日志压缩。</p><p>日志压缩前，必须先<strong>创建快照</strong>，快照是<strong>当前状态机的全量键值结果 + 日志锚点元数据</strong>序列化后存储，避免压缩时出现故障导致数据丢失。<br>然后执行日志压缩，可以安全地把快照锚点（lastIndex）之前的所有日志直接删除，大幅减少日志的体积。</p><p>虽然状态机的存储结果本质是键值对，但是实际上工业级实现中（比如 LogCabin），为了适配实际业务需求，会把基础键值对扩展为 “树状分层的键值对结构”，采用<strong>多叉树</strong>作为核心数据结构，而非简单的扁平集合。但<strong>核心还是键值映射，只是键有了 “层级路径”，节点间有了 “父子依赖”</strong>，就像电脑中目录和文件的层级关系一样。为了保证应用快照时能完整、正确地重建整个树状状态机，不能仅备份叶子节点的键值对，必须保证父节点实体先存在。因此要遵循前序深度优先遍历的规则，先访问并记录当前父节点的创建信息，再依次深度遍历其所有子节点，记录内部子节点的创建信息和叶子子节点的完整键值对信息。</p><h2 id="基于内存状态机的快照实现"><a href="#基于内存状态机的快照实现" class="headerlink" title="基于内存状态机的快照实现"></a>基于内存状态机的快照实现</h2><h3 id="并发快照"><a href="#并发快照" class="headerlink" title="并发快照"></a>并发快照</h3><p>并发快照过程中，若有新日志条目修改数据，如何保证快照数据的一致性（不被新修改干扰）？</p><ol><li>状态机可基于不可变（函数式）数据结构构建，以此支持并发快照。</li><li>亦可借助操作系统提供的写时复制支持（前提是编程环境支持该特性）。</li></ol><h3 id="快照触发时机"><a href="#快照触发时机" class="headerlink" title="快照触发时机"></a>快照触发时机</h3><p>当日志文件大小超过上一次快照大小与可配置扩展系数的乘积时，触发新的快照。该扩展系数的取值本质是在磁盘带宽开销与存储利用率之间做权衡。</p><h1 id="客户端交互"><a href="#客户端交互" class="headerlink" title="客户端交互"></a>客户端交互</h1><p>规则上说，主节点处理所有请求以保证强一致性，从节点核心为高可用与容灾，工程优化中可合规处理只读请求、分担主节点负载。</p><h2 id="如何保证线性化一致性"><a href="#如何保证线性化一致性" class="headerlink" title="如何保证线性化一致性"></a>如何保证线性化一致性</h2><p>实现线性化语义：<br>说白了就是让客户端的所有命令具备幂等性。具体通过「客户端唯一标识 + 命令唯一序列号」的组合实现：为每个客户端分配全局唯一标识，客户端为自身发起的每条命令按递增规则分配唯一序列号（如 1、2、3……）。<br>状态机在执行并提交完某条日志条目后，会将该客户端的唯一标识、本次执行命令的序列号及对应执行结果，作为客户端会话数据持久化记录（<code>指令-结果</code> 的键值对集合）；若后续再次收到该客户端小于&#x2F;相同序列号的命令，状态机会直接返回已有执行结果，不再重新执行，以此保证命令仅执行一次，从底层实现线性化语义要求。<br>当然这个会话记录不会永久留存，否则会造成服务器资源无限占用，他只是一个类似缓存的东西，只不过是运行在分布式集群上。因此 Raft 在记录客户端会话数据的同时，带上<strong>提交时的时间戳</strong>（划重点，是集群共识后的统一时间戳），并基于该统一时间戳制定过期规则完成集群的同步淘汰（和 Redis 缓存太像了）。</p><h2 id="高效只读查询"><a href="#高效只读查询" class="headerlink" title="高效只读查询"></a>高效只读查询</h2><p>客户端的<strong>只读命令</strong>仅对复制<strong>状态机</strong>进行查询，不会对其做出修改。因此<strong>绕开 Raft 日志处理只读查询</strong>的收益是非常可观的（如果不绕开日志，那么读取数据的请求也会被写成日志条目同步到多数派集群）。但是如果没有额外的机制，绕开日志会导致只读查询返回<strong>过期结果</strong>，且<strong>不满足线性一致性</strong>（因为没有获得多数派节点的确认 - 通过日志复制提交）。</p><blockquote><p>线性一致性要求，读操作的结果必须反映出该读操作发起后某个时刻的系统状态；每一次读操作，至少要返回最新已提交写操作的执行结果</p></blockquote><p>例如，某任领导者若与集群其他节点发生网络分区，集群剩余节点可能会选举出新的领导者，并向 Raft 日志提交新的条目。如果这个被分区的领导者在未与其他节点交互的情况下响应只读查询，返回的结果就是过期的，且不满足线性一致性。</p><p>还有一种场景：“上一任领导提交了部分条目，当前领导虽持有，但未标记为自身任期的已提交”。<br>比如上任 Leader 复制日志到了多数派节点并让多数派节点提交了就宕机，导致现在有一个节点虽然已经复制到日志条目，但是因为 Leader 的宕机导致没有接到提交到状态机的指令，他是不知道这个条目是否被多数派节点提交的，也不敢贸然提交到状态机。他会向其他节点复制之前任期的日志条目，然后在自己任期产生的日志条目提交时顺带把之前的任期条目提交了——具体回顾《提交之前的任期条目》内容（这个节点虽然没有提交日志条目到状态机，但是选举获得投票不是看状态机的条目，而是看当前任期以及历史日志条目的 <code>lastindex</code> 大小长度）<br>但是这个时候，作为新的 Leader 如果长时间没有接到写操作的命令，那么之前任期的日志条目也是长时间不会被再次提交，导致 Leader 节点和少数节点状态机一直缺少这个日志条目的结果。此时如果客户端发送只读命令，那么在不同节点获取到的数据是不一样的（Raft 的设计允许让跟随者返回只读查询的结果，所以同一个请求可以由不同的节点响应，但是这个并未在 LogCabin 实现），比如现在的 Leader 的状态机就没有上任期提交的日志条目结果，产生数据不一致的结果。</p><p>所以当新 Leader 任期时，立马提交一条<strong>空操作（no-op）条目</strong>的机制很有用。但仅让 Leader 拥有了自身任期确认的、集群全局最新的 commitIndex。</p><p>对于绕开日志的只读查询而言这是不够的，还存在三个问题：</p><ol><li>no-op 完成后，<code>commitIndex</code> 依然是<strong>动态变化</strong>的，无法直接作为查询基准</li><li>no-op 无法验证 Leader 的<strong>实时领导权</strong>，可能出现「Leader 已失效但自身不知情」（场景一）</li><li>no-op 仅保证<strong>日志提交层面</strong>的 commitIndex 更新，不保证<strong>状态机应用层面</strong>的同步落地</li></ol><blockquote><p>关于第 1、3 个问题可能有点疑问：<br>领导者将当前的 commitIndex 保存至本地变量 readIndex 有啥用？提交 no-op 空条目后 commitIndex 不是等于 readIndex？都提交到状态机了吧，为啥有“待自身的状态机推进至至少与 readIndex 对应的位置”这种说法？</p><p>关于提交日志条目到状态机，就像交给一个消息队列一样，队列里面的日志条目最终会应用到状态机，但不是立即应用，状态机的实际运行进度，只由另一个独立指标决定 —— 最后应用索引（Last Applied Index）。<br>所以一个只读查询到达时，状态机里面会存在这样一段时间窗口：日志条目已经复制到多数派集群并且完成提交（commitIndex 更新），但是这个提交的日志条目可能还没有在状态机应用（Last Applied Index &lt; commitIndex），如果直接返回结果的话会导致客户端接收到 Raft 集群已提交的消息却查不到对应数据；但如果无限制延迟查询的话，若此时集群又接收到新的写操作日志条目并提交，会导致 commitIndex 不断增大，若以动态的 commitIndex 为基准等待，执行查询时获取到的并不是查询发起时的状态结果，而可能是被新的日志条目覆盖后的结果。<br>因此不能立即执行查询返回结果，也不能没有限制地延后执行查询。</p></blockquote><p>对于上述问题：<br>Raft 的方案是处理客户端只读查询请求时，Leader 接收请求后，不会立即执行查询，而是先暂存该请求（<strong>新 Leader 则需要先完成本任期 no-op 空条目提交</strong>，以确保 commitIndex 为集群全局可靠值）；<br>在处理该请求的这一刻，给每个只读查询分配一个局部变量 readIndex，记录当前的 readIndex &#x3D; commitIndex（冻结固定的状态基准，让等待有明确终止条件），随后先<strong>通过心跳包确认 Leader 仍为合法主节点</strong>，保证 <code>readIndex</code> 对应的日志已在集群共识提交；返回状态允许包含后续已应用日志。<br>再<strong>等待 Last Applied Index 达到 readIndex</strong>；当 Last Applied Index 达到 readIndex 后，通过读写锁互斥让应用日志的线程短暂阻塞，原子性执行查询并拿到结果（可同步 &#x2F; 异步返回给客户端），锁释放后应用线程立刻继续异步应用后续的日志条目。<br>期间集群运行不受任何影响，系统依旧可以接受新的日志条目并完成提交，让 commitIndex 持续增大。</p><p><strong>跟随者也可协助分担只读查询的处理工作</strong>。这不仅能提升系统的读吞吐量，还能将负载从领导者转移，让领导者可以处理更多的读写请求。但若无额外防护措施，这些由跟随者处理的读操作，同样存在返回过期数据的风险。例如，与集群发生分区的跟随者，可能长时间无法从领导者处接收新的日志条目；即便跟随者收到了领导者的心跳，该领导者也可能已被取代，只是自身尚未知晓。要安全处理读请求，跟随者可向领导者发起请求，仅获取当前的 readIndex（领导者会执行完备性检验，即提交 no-op；记录 readIndex；发送心跳向集群确认自己领导者身份）；随后，跟随者可针对自身的状态机等待 Last Applied Index 同步至 readIndex 然后获取结果，处理所有已累积的只读查询。（LogCabin 未实现该方案）</p>]]></content>
      
      
      <categories>
          
          <category> 技术理论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式系统 </tag>
            
            <tag> Raft </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅读Raft算法</title>
      <link href="/9a0e6259ac11/"/>
      <url>/9a0e6259ac11/</url>
      
        <content type="html"><![CDATA[<p>参考：</p><p><a href="https://raft.github.io/raft.pdf">In Search of an Understandable Consensus Algorithm(Extended Version)</a><br><a href="https://github.com/ongardie/dissertation/blob/master/stanford.pdf">ongardie&#x2F;dissertation&#x2F;stanford.pdf</a><br><a href="https://raft.github.io/">raft.github.io</a></p><p><a href="https://blog.csdn.net/dw147258dw/article/details/134026228#:~:text=%E6%9C%AC%E6%96%87%E5%88%86%E6%9E%90%E4%BA%86%20Raft%20%E5%8D%8F%E8%AE%AE%E7%9A%84%20Figure%208%20%E5%9B%BE%E4%B8%AD%E4%B8%BA%E4%BD%95%E4%B8%8D%E8%83%BD%E8%AE%A9%20Leader,%E7%9B%B4%E6%8E%A5%E6%8F%90%E4%BA%A4%E4%B9%8B%E5%89%8D%E4%BB%BB%E6%9C%9F%E7%9A%84%E6%97%A5%E5%BF%97%EF%BC%8C%E8%A7%A3%E9%87%8A%E4%BA%86%E8%BF%99%E5%8F%AF%E8%83%BD%E5%AF%BC%E8%87%B4%E7%9A%84%E6%97%A5%E5%BF%97%E9%87%8D%E5%A4%8D%E6%8F%90%E4%BA%A4%E9%97%AE%E9%A2%98%E3%80%82%20%E4%B8%BA%E4%BA%86%E8%A7%A3%E5%86%B3%E8%BF%99%E4%B8%AA%E9%97%AE%E9%A2%98%EF%BC%8C%E5%BC%95%E5%85%A5%E4%BA%86%20no-op%20%E6%97%A5%E5%BF%97%EF%BC%8C%E5%BD%93%20Leader%20%E9%80%89%E4%B8%BE%E6%88%90%E5%8A%9F%E5%90%8E%EF%BC%8C%E9%80%9A%E8%BF%87%E6%B7%BB%E5%8A%A0%20no-op%20%E6%97%A5%E5%BF%97%E5%B9%B6%E5%BF%AB%E9%80%9F%E5%A4%8D%E5%88%B6%EF%BC%8C%E7%A1%AE%E4%BF%9D%E6%9C%AA%E6%8F%90%E4%BA%A4%E7%9A%84%E6%97%A5%E5%BF%97%E8%83%BD%E5%A4%9F%E9%97%B4%E6%8E%A5%E6%8F%90%E4%BA%A4%EF%BC%8C%E9%81%BF%E5%85%8D%E9%98%BB%E5%A1%9E%E7%B3%BB%E7%BB%9F%E5%B9%B6%E4%BF%9D%E8%AF%81%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7%E3%80%82">Raft 的 Figure 8 讲了什么问题？为什么需要 no-op 日志？</a><br><a href="https://www.codedump.info/post/20211011-raft-propose-prev-term/">为什么Raft协议不能提交之前任期的日志？</a><br><a href="https://jameywoo.github.io/post/raft%E5%8D%9A%E5%A3%AB%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/">Raft博士论文总结</a></p><h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h1><p>Raft 是一种为了管理日志复制的一致性算法，旨在实现<strong>多节点状态机的高可靠一致性</strong>。<br>相比 Paxos，Raft 将算法分解为<strong>领导者选举、日志复制、安全性</strong>三大模块，使用随机超时避免选票分裂，并引入<strong>共同一致</strong>机制实现集群成员动态变更。</p><p>Raft 通过选举一个杰出的领导者（也叫 Leader 节点），然后给予他全部的管理日志复制的责任来实现一致性。Leader 节点接收来自客户端的请求日志数据，然后同步到集群中其它节点进行复制，当日志已经同步到超过半数以上节点的时候，Leader 节点再通知集群中其它节点哪些日志已经被复制成功，可以提交到 Raft 状态机中执行。</p><p>通过以上方式，Raft 算法将一致性问题分为了几个子问题：</p><ul><li><strong>Leader 选举</strong>：集群中必须存在一个 Leader 节点。当现存的 Leader 节点发生故障的时候, 一个新的领导者需要被选举出来。</li><li><strong>日志复制</strong>：Leader 节点接收来自客户端的请求然后将这些请求序列化成日志数据再同步到集群中其它节点，强制要求其他节点的日志和自己保持一致。</li><li><strong>安全性</strong>：如果有任何的服务器节点已经应用了一个确定的日志条目到它的状态机中，那么其他服务器节点不能在同一个日志索引位置应用一个不同的指令。这个解决方案涉及到选举机制上的一个额外限制。</li></ul><h1 id="2-Raft-基础"><a href="#2-Raft-基础" class="headerlink" title="2 Raft 基础"></a>2 Raft 基础</h1><p>一个 Raft 集群包含若干个服务器节点。5 个服务器节点是一个典型的例子，这允许整个系统容忍 2 个节点失效。</p><p>角色：<br>在任何时刻，每一个服务器节点都处于这三个状态之一：领导者（Leader）、跟随者（Follower）和候选人（Candidate）。</p><ul><li><strong>跟随者</strong>：是被动的，他们不会发送任何请求，只是简单的响应来自领导者或者候选人的请求。</li><li><strong>领导者</strong>：处理所有的客户端请求（如果一个客户端和跟随者联系，那么跟随者会把请求重定向给领导者）。</li><li><strong>候选人</strong>：是用来在选举新领导者时使用。</li></ul><p>在通常情况下，系统中只有一个领导者并且其他的节点全部都是跟随者。</p><p>任期：<br>Raft 把时间分割成任意长度的<strong>任期</strong>。任期用连续的整数标记。每一段任期从一次<strong>选举</strong>开始，每个领导者的领导周期称为一个任期（Term），任期号是单调递增的。<br>在某些情况下，一次选举过程会造成选票的瓜分。在这种情况下，这一任期会以没有领导者结束；一个新的任期（和一次新的选举）会很快重新开始。Raft 保证了在一个给定的任期内，最多只有一个领导者。</p><p>不同的服务器节点可能多次观察到任期之间的转换，但在某些情况下，一个节点也可能观察不到任何一次选举或者整个任期全程。<strong>任期在 Raft 算法中充当逻辑时钟的作用，任期使得服务器可以检测一些过期的信息</strong>。<br>比如过期的领导者。每个节点存储一个当前领导者的任期号，这一编号在整个时期内单调递增。每当服务器之间通信的时候都会交换当前任期号；如果一个服务器的当前任期号比其他人小，那么他会更新自己的任期号到较大的任期号值。如果一个候选人或者领导者发现自己的任期号过期了，那么他会立即恢复成跟随者状态。如果一个节点接收到一个包含过期的任期号的请求，那么他会直接拒绝这个请求。</p><p>Raft 算法中服务器节点之间通信使用远程过程调用（RPCs），并且基本的一致性算法只需要两种类型的 RPCs。</p><ul><li>请求投票（RequestVote） RPCs 由候选人在选举期间发起；</li><li>附加条目（AppendEntries）RPCs 由领导者发起，用来复制日志和提供一种心跳机制。<br>后面为了在服务器之间传输快照增加了第三种 RPC。当服务器没有及时的收到 RPC 的响应时，会进行重试，并且他们能够并行的发起 RPCs 来获得最佳的性能。</li></ul><blockquote><p>一个关于 Raft 一致性算法的浓缩总结（不包括成员变换和日志压缩）<br>原文：<br>Election Safety: at most one leader can be elected in a given term. §5.2<br>Leader Append-Only: a leader never overwrites or deletes entries in its log; it only appends new entries. §5.3<br>Log Matching: if two logs contain an entry with the same index and term, then the logs are identical in all entries up through the given index. §5.3<br>Leader Completeness: if a log entry is committed in a given term, then that entry will be present in the logs of the leaders for all higher-numbered terms. §5.4<br>State Machine Safety: if a server has applied a log entry at a given index to its state machine, no other server will ever apply a different log entry for the same index.§5.4.3</p></blockquote><p>总结：</p><table><thead><tr><th>特性</th><th>解释</th></tr></thead><tbody><tr><td>选举安全特性</td><td>对于一个给定的任期号，最多只会有一个领导者被选举出来</td></tr><tr><td>领导者只附加原则</td><td>领导者绝对不会删除或者覆盖自己的日志，只会追加新条目</td></tr><tr><td>日志匹配原则</td><td>如果两个日志在相同索引位置包含一个具有相同任期号的条目，那么这两个日志在该索引位置之前的所有条目都完全相同</td></tr><tr><td>领导者完全特性</td><td>如果某个日志条目在某个任期号中已经被提交，那么这个条目必然出现在更大任期号的所有领导者中</td></tr><tr><td>状态机安全特性</td><td>如果某一服务器已将给定索引位置的日志条目应用至其状态机中，则其他任何服务器在该索引位置不会应用不同的日志条目</td></tr></tbody></table><h2 id="2-2-复制状态机"><a href="#2-2-复制状态机" class="headerlink" title="2.2 复制状态机"></a>2.2 复制状态机</h2><p>一致性算法是从复制状态机的背景下提出的（参考英文原文引用 37）。在这种方法中，一组服务器上的状态机产生相同状态的副本，并且在一些机器宕掉的情况下也可以继续运行。复制状态机在分布式系统中被用于解决很多容错的问题。例如，大规模的系统中通常都有一个集群领导人，像 GFS、HDFS 和 RAMCloud，典型应用就是一个独立的复制状态机去管理领导选举和存储配置信息并且在领导人宕机的情况下也要存活下来。比如 Chubby 和 ZooKeeper。</p><p><img src="/9a0e6259ac11/raft-%E5%9B%BE1.png" alt="图 1 "></p><blockquote><p>图 1 ：复制状态机的结构。一致性算法管理着来自客户端指令的复制日志。状态机从日志中处理相同顺序的相同指令，所以产生的结果也是相同的。</p></blockquote><p>复制状态机通常都是基于复制日志实现的，如图 1。每一个服务器存储一个包含一系列指令的日志，并且按照日志的顺序进行执行。每一个日志都按照相同的顺序包含相同的指令，所以每一个服务器都执行相同的指令序列。因为每个状态机都是确定的，每一次执行操作都产生相同的状态和同样的序列。</p><p>一致性算法的任务是保证复制日志的一致性。服务器上的一致性模块接收客户端发送的指令然后添加到自己的日志中。它和其他服务器上的一致性模块进行通信来保证每一个服务器上的日志最终都以相同的顺序包含相同的请求，即使有些服务器发生故障。一旦指令被正确的复制，每一个服务器的状态机按照日志顺序处理他们，然后输出结果被返回给客户端。因此，服务器集群看起来形成了一个高可靠的状态机。</p><p>实际系统中使用的一致性算法通常含有以下特性：</p><ul><li>安全性保证（绝对不会返回一个错误的结果）：在非拜占庭错误情况下，包括网络延迟、分区、丢包、重复和乱序等错误都可以保证正确。</li><li>可用性：集群中只要有大多数的机器可运行并且能够相互通信、和客户端通信，就可以保证可用。因此，一个典型的包含 5 个节点的集群可以容忍两个节点的失败。服务器被停止就认为是失败。它们稍后可能会从可靠存储的状态中恢复并重新加入集群。</li><li>不依赖时序来保证一致性：物理时钟错误或者极端的消息延迟只有在最坏情况下才会导致可用性问题。</li><li>通常情况下，一条指令可以尽可能快的在集群中大多数节点响应一轮远程过程调用时完成。小部分比较慢的节点不会影响系统整体的性能。</li></ul><h1 id="3-Raft-算法核心"><a href="#3-Raft-算法核心" class="headerlink" title="3 Raft 算法核心"></a>3 Raft 算法核心</h1><h2 id="3-1-领导者选举"><a href="#3-1-领导者选举" class="headerlink" title="3.1 领导者选举"></a>3.1 领导者选举</h2><p>拥有一个领导者大大简化了对复制日志的管理。例如，领导者可以决定新的日志条目需要放在日志中的什么位置而不需要和其他服务器商议，并且数据都从领导者流向其他服务器。一个领导者可能会发生故障，或者和其他服务器失去连接，在这种情况下一个新的领导者会被选举出来。</p><p>系统启动时，所有节点都是跟随者。领导者周期性的向所有跟随者发送心跳包（即不包含日志项内容的附加条目 AppendEntries RPCs）以维持自己的领导地位。如果一个跟随者在一段时间里没有接收到任何消息，也就是<strong>选举超时</strong>，那么它就会认为系统中没有可用的领导者，它会转变为候选人，发起新一轮的选举。</p><p>要开始一次选举过程，跟随者先要<strong>增加自己的当前任期号</strong>并且转换到候选人状态。然后他会并行地向集群中的其他服务器节点发送请求投票的 RPCs 来给自己投票。候选人会继续保持着当前状态直到以下三件事情之一发生：</p><ol><li><p>他自己赢得了这次的选举：<br> 当一个候选人从整个集群获得了超过半数（多数派）节点的针对同一个任期号的选票，那么他就赢得了这次选举并成为领导者。每一个服务器最多会对一个任期号投出一张选票，按照先来先服务的原则（注意：后面 <a href="#3.3.1%20%E9%80%89%E4%B8%BE%E9%99%90%E5%88%B6">3.3.1 选举限制</a> 章节在投票上增加了一点额外的限制）。要求大多数选票的规则确保了最多只会有一个候选人赢得此次选举。一旦候选人赢得选举，他就立即成为领导者。然后他会向其他的服务器发送心跳消息来建立自己的权威并且阻止发起新的选举。</p></li><li><p>其他的服务器成为领导者<br> 在等待投票的时候，候选人可能会从其他的服务器接收到声明它是领导者的附加条目 AppendEntries RPC。如果这个领导者的任期号（包含在此次的 RPC 中）不小于候选人当前的任期号，那么候选人会承认领导者合法并回到跟随者状态。如果此次 RPC 中的任期号比自己小，那么候选人就会拒绝这次的 RPC 并且继续保持候选人状态。</p></li><li><p>一段时间之后没有任何一个获胜的人。<br> 第三种可能的结果是候选人既没有赢得选举也没有输：如果有多个跟随者同时成为候选人，那么选票可能会被瓜分以至于没有候选人可以赢得大多数人的支持。当这种情况发生的时候，每一个候选人都会超时，然后通过增加当前任期号来开始一轮新的选举。然而，没有其他机制的话，选票可能会被无限的重复瓜分。</p></li></ol><p><strong>利用随机选举超时机制避免重复选票瓜分</strong>：<br>Raft 算法使用随机选举超时时间的方法来确保很少会发生选票瓜分的情况，就算发生也能很快的解决。为了阻止选票起初就被瓜分，选举超时时间是从一个固定的区间（例如 150-300 毫秒）随机选择。<br><strong>在大多数情况下，只有一个服务器会首先触发选举超时</strong>，然后他赢得选举并在其他服务器超时之前发送心跳包。<br>同样的机制被用在选票瓜分的情况下。每一个候选人在开始一次选举的时候会重置一个随机的选举超时时间，然后在超时时间内等待投票的结果；这样减少了在新的选举中另外的选票瓜分的可能性。这种方案能够快速的选出一个领导者。</p><p><img src="/9a0e6259ac11/Raft-Election-Process.png"></p><h2 id="3-2-日志复制"><a href="#3-2-日志复制" class="headerlink" title="3.2 日志复制"></a>3.2 日志复制</h2><p>一旦一个领导者被选举出来，他就开始为客户端提供服务。客户端的每一个请求都包含一条被复制状态机执行的指令。领导者把这条指令作为一条新的日志条目附加到日志中去，然后并行地发起附加条目 RPCs 给其他的服务器，让他们复制这条日志条目。当领导者得知某个日志条目已经被大多数节点复制时，领导者会应用这条日志条目到它的状态机中然后把执行的结果返回给客户端。如果跟随者崩溃或者运行缓慢，再或者网络丢包，领导者会不断的重复尝试附加日志条目 RPCs （尽管已经回复了客户端）直到所有的跟随者都最终存储了所有的日志条目。</p><p><img src="/9a0e6259ac11/raft-%E5%9B%BE6.png" alt="图 6"></p><blockquote><p>图 6：日志由有序序号标记的条目组成。每个条目都包含创建时的任期号（图中框中的数字），和一个状态机需要执行的指令。一个条目当可以安全地被应用到状态机中去的时候，就认为是可以提交了。</p></blockquote><p>日志以上图展示的方式组织。每一个日志条目存储一条状态机指令和从领导者收到这条指令时的任期号。日志中的任期号用来检查是否出现不一致的情况，同时也用来保证 <a href="#2%20Raft%20%E5%9F%BA%E7%A1%80">2 Raft 基础</a> 章节中的某些性质。每一条日志条目同时也都有一个整数索引值来表明它在日志中的位置。</p><p>领导者来决定什么时候把日志条目应用到状态机中是安全的，这种日志条目被称为<strong>已提交</strong>。Raft 算法保证所有已提交的日志条目都是持久化的并且最终会被所有可用的状态机执行：</p><ol><li>在领导者将创建的日志条目复制到超过半数节点上的时候，日志条目就会被提交（例如在上图中共 5 个节点，3 个节点已经拥有日志条目 7）。</li><li>同时，领导者的日志中之前的所有日志条目也都会被提交，包括由其他领导者创建的条目。<a href="#3.3%20%E5%AE%89%E5%85%A8%E6%80%A7">3.3 安全性</a> 章节会讨论某些当在领导者改变之后应用这条规则的隐晦内容，同时他也展示了这种提交的定义是安全的。</li></ol><p>领导者跟踪了最大的将会被提交的日志项的索引，并且索引值会被包含在未来的所有附加日志 RPCs （包括心跳包），这样其他的服务器才能最终知道领导者的提交位置。一旦跟随者知道一条日志条目已经被提交，那么他也会将这个日志条目应用到本地的状态机中（按照日志的顺序）。</p><p>我们设计了 Raft 的日志机制来维护不同服务器日志之间的高层次的一致性。这么做不仅简化了系统的行为也使其更具有可预测性，同时它也是安全性保证的一个重要组件。Raft 维护着以下的特性，这些特性共同组成了 <a href="#2%20Raft%20%E5%9F%BA%E7%A1%80">2 Raft 基础</a> 中说的<strong>日志匹配特性（Log Matching Property）</strong>：</p><ul><li>如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们存储了相同的指令。</li><li>如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们之前的所有日志条目也全部相同。</li></ul><p>第一个特性来自这样的一个事实，领导者最多在一个任期里在指定的一个日志索引位置创建一条日志条目，同时日志条目在日志中的位置也从来不会改变。<br>第二个特性由附加日志 RPC 的一个简单的一致性检查所保证。在发送附加日志 RPC 的时候，领导者会把新的日志条目前紧挨着的条目的索引位置和任期号包含在日志内。如果跟随者在它的日志中找不到包含相同索引位置和任期号的条目，那么他就会拒绝接收新的日志条目。<br>一致性检查就像一个归纳步骤：一开始空的日志状态肯定是满足日志匹配特性的，然后一致性检查在日志扩展的时候保护了日志匹配特性。因此，每当附加日志 RPC 返回成功时，领导者就知道跟随者的日志一定是和自己相同的了。</p><p>在正常的操作中，领导者和跟随者的日志保持一致性，所以附加日志 RPC 的一致性检查从来不会失败。然而，领导者崩溃的情况会使得日志处于不一致的状态（老的领导者可能还没有完全复制所有的日志条目）。这种不一致问题会在领导者和跟随者的一系列崩溃下加剧。图 7 展示了跟随者的日志可能和新的领导者不同。跟随者可能会丢失一些在新的领导者中存在的日志条目，他也可能拥有一些领导者没有的日志条目，或者两者都发生。丢失或者多出日志条目可能会持续多个任期。</p><p><img src="/9a0e6259ac11/raft-%E5%9B%BE7.png" alt="图 7"></p><blockquote><p>图 7：当一个领导者成功当选时，跟随者可能是任何情况（a-f）。每一个盒子表示是一个日志条目；里面的数字表示任期号。跟随者可能会缺少一些日志条目（a-b），可能会有一些未被提交的日志条目（c-d），或者两种情况都存在（e-f）。<br>例如，场景 f 可能会这样发生，该服务器在任期 2 的时候是领导者，已附加了一些日志条目到自己的日志中，但在提交之前就崩溃了；很快这个机器就被重启了，在任期 3 重新被选为领导者，并且又增加了一些日志条目到自己的日志中；在任期 2 和任期 3 的日志被提交之前，这个服务器又宕机了，并且在接下来的几个任期里一直处于宕机状态。</p></blockquote><p>在 Raft 算法中，领导者是通过强制跟随者直接复制自己的日志来处理不一致问题的。这意味着在跟随者中的冲突的日志条目会被领导者的日志覆盖。<a href="#3.3%20%E5%AE%89%E5%85%A8%E6%80%A7">3.3 安全性</a> 章节会阐述如何通过增加一些限制来使得这样的操作是安全的。</p><p>要使得跟随者的日志进入和自己一致的状态，领导者必须找到最后两者达成一致的地方，然后删除跟随者从那个点之后的所有日志条目，并发送自己在那个点之后的日志给跟随者。所有的这些操作都在进行附加日志 RPCs 的一致性检查时完成。领导者针对每一个跟随者维护了一个 <strong>nextIndex</strong>，这表示下一个需要发送给跟随者的日志条目的索引地址。当一个领导者刚获得权力的时候，他初始化所有的 nextIndex 值为自己的最后一条日志的 index 加 1（图 7 中的第 11 索引）。如果一个跟随者的日志和领导者不一致，那么在下一次的附加日志 RPC 时的一致性检查就会失败。在被跟随者拒绝之后，领导者就会减小 nextIndex 值并进行重试。最终 nextIndex 会在某个位置使得领导者和跟随者的日志达成一致。当这种情况发生，附加日志 RPC 就会成功，这时就会把跟随者冲突的日志条目全部删除并且加上领导者的日志。一旦附加日志 RPC 成功，那么跟随者的日志就会和领导者保持一致，并且在接下来的任期里一直继续保持。</p><blockquote><p>如果需要的话，算法可以通过减少被拒绝的附加日志 RPCs 的次数来优化。例如，当附加日志 RPC 的请求被拒绝的时候，跟随者可以 (返回) 冲突条目的任期号和该任期号对应的最小索引地址。借助这些信息，领导者可以减小 nextIndex 一次性越过该冲突任期的所有日志条目；这样就变成每个任期需要一次附加条目 RPC 而不是每个条目一次。在实践中，我们十分怀疑这种优化是否是必要的，因为失败是很少发生的并且也不大可能会有这么多不一致的日志。</p></blockquote><p>通过这种机制，领导者在获得权力的时候就不需要任何特殊的操作来恢复一致性。他只需要进行正常的操作，然后日志就能在回复附加日志 RPC 的一致性检查失败的时候自动趋于一致。领导者从来不会覆盖或者删除自己的日志 (<a href="#2%20Raft%20%E5%9F%BA%E7%A1%80">2 Raft 基础</a> 中说过的领导者只附加特性）。</p><p>日志复制机制展示一致性特性：Raft 能够接受，复制并应用新的日志条目只要大部分的机器是工作的；在通常的情况下，新的日志条目可以在一次 RPC 中被复制给集群中的大多数机器；并且单个的缓慢的跟随者不会影响整体的性能。</p><h2 id="3-3-安全性"><a href="#3-3-安全性" class="headerlink" title="3.3 安全性"></a>3.3 安全性</h2><p>前面的章节里描述了 Raft 算法是如何选举和复制日志的。然而，到目前为止描述的机制并不能充分的保证每一个状态机会按照相同的顺序执行相同的指令。例如，一个跟随者可能会进入不可用状态同时领导者已经提交了若干的日志条目，然后这个跟随者可能会被选举为领导者并且覆盖这些日志条目（坏的节点好了，但此时如果他成为了领导者，那些理应被安全提交到状态机的日志条目，这个节点是没有的，然后会试图找到他们最后一个相同提交条目的索引，删除跟随者后面的提交条目，这违反了前面说的状态机日志索引一致性特性）；因此，这种设计会导致不同的状态机可能会执行不同的指令序列。</p><p>这一节通过在领导选举的时候增加一些限制来完善 Raft 算法。这一限制保证了任何的领导者对于给定的任期号，都拥有了之前任期的所有被提交的日志条目（ <a href="#2%20Raft%20%E5%9F%BA%E7%A1%80">2 Raft 基础</a> 中的领导者完整特性）。增加这一选举时的限制，我们对于提交时的规则也更加清晰。最终，我们将展示对于<strong>领导者完整特性（Leader Completeness Property）</strong> 的简要证明，并且说明该特性是如何引导复制状态机做出正确行为的。</p><h3 id="3-3-1-选举限制"><a href="#3-3-1-选举限制" class="headerlink" title="3.3.1 选举限制"></a>3.3.1 选举限制</h3><p>在任何基于领导者的一致性算法中，领导者都必须存储所有已经提交的日志条目。在某些一致性算法中，例如 Viewstamped Replication，某个节点即使是一开始并没有包含所有已经提交的日志条目，它也能被选为领导者。这些算法都包含一些额外的机制来识别丢失的日志条目并把他们传送给新的领导者，要么是在选举阶段要么在之后很快进行。不幸的是，这种方法会导致相当大的额外的机制和复杂性。Raft 使用了一种更加简单的方法，它可以保证在选举的时候新的领导者拥有所有之前任期中已经提交的日志条目，而不需要传送这些日志条目给领导者。这意味着日志条目的传送是单向的，只从领导者传给跟随者，并且领导者从不会覆盖自身本地日志中已经存在的条目。</p><p><strong>Raft 使用投票的方式来阻止一个候选人赢得选举，除非这个候选人包含了所有已经提交的日志条目</strong>。候选人为了赢得选举必须联系集群中的大部分节点，这意味着每一个已经提交的日志条目在这些服务器节点中肯定存在于至少一个节点上。如果候选人的日志至少和大多数的服务器节点一样新（这个新的定义会在下面讨论），那么他一定持有了所有已经提交的日志条目。请求投票（RequestVote） RPC 实现了这样的限制：RPC 中包含了候选人的日志信息，然后投票人会拒绝掉那些日志没有自己新的投票请求。</p><p>Raft 通过比较两份日志中最后一条日志条目的索引值和任期号定义谁的日志比较新，<strong>且按优先级执行，先比 <code>lastLogTerm</code>，再比 <code>lastLogIndex</code>（任期相同情况下）</strong>：</p><ol><li><strong>如果两份日志最后的条目的任期号不同，那么任期号大的日志更加新。</strong>（优先级最高）</li><li><strong>如果两份日志最后的条目任期号相同，那么日志比较长的那个就更加新。</strong></li></ol><p>注：<strong>日志新鲜度判定依据的是“节点本地日志中最后一条日志条目（无论是否已提交）的索引 + 任期”</strong></p><h3 id="3-3-2-提交之前任期内的日志条目"><a href="#3-3-2-提交之前任期内的日志条目" class="headerlink" title="3.3.2 提交之前任期内的日志条目"></a>3.3.2 提交之前任期内的日志条目</h3><p>如同 <a href="#3.2%20%E6%97%A5%E5%BF%97%E5%A4%8D%E5%88%B6">3.2 日志复制</a> 章节介绍的那样，领导者知道一条当前任期内的日志记录是可以被提交的，只要它被存储到了大多数的服务器上。如果一个领导者在提交日志条目之前崩溃了，未来后续的领导者会继续尝试复制这条日志记录。然而，一个领导者不能断定一个之前任期里的日志条目被保存到大多数服务器上的时候就一定已经提交了。所以提交老任期日志存在一个致命漏洞 —— <strong>一条已经被存储到大多数节点上的老日志条目，也依然有可能会被未来的领导者覆盖掉</strong>，图 3.7 就是这个漏洞的典型场景：</p><p><img src="/9a0e6259ac11/3_7.png" alt="图 3.7"></p><blockquote><p>图 3.7：如图的时间序列展示了领导者无法决定对老任期号的日志条目进行提交的原因，否则存在安全问题。</p><ul><li>在 (a) 中，S1 是领导人，只有少部分的 (跟随者) 复制了索引位置 2 的日志条目。</li><li>在 (b) 中，S1 崩溃了，然后 S5 在任期 3 里通过 S3、S4 和自己的选票赢得选举，然后从客户端接收了一条不一样的日志条目放在了索引 2 处。</li><li>然后到 (c)，S5 又崩溃了；S1 重新启动，选举成功，开始复制日志。在这时，来自任期 2 的那条日志已经被复制到了集群中的大多数机器上，<strong>但是还没有被提交</strong>。此时会产生两个分支：</li><li><strong>在允许提交之前任期的日志规则下</strong>，如果 S1 在 (d) 中又崩溃了，S5 可以重新被选举成功（通过来自 S2，S3 和 S4 的选票），然后覆盖了他们在索引 2 处的日志。</li><li><strong>在不允许提交之前任期的日志规则下</strong>，如果在崩溃之前，S1 把自己主导的新任期里产生的日志条目复制到了大多数机器上，就如 (e) 中那样，那么在后面任期里面这些新的日志条目就会被提交（因为 S5 就不可能选举成功）。 这样在同一时刻就同时保证了，之前的所有老的日志条目就会被提交。</li></ul></blockquote><blockquote><p>再次强调，这里图示想演示的是 “如果允许提交之前任期的日志，将导致什么问题”。</p></blockquote><p>为了消除图 3.7 里描述的情况，<strong>Raft 永远不会通过计算副本数目的方式去提交一个之前任期内的日志条目。只有领导人当前任期里的日志条目通过计算副本数目可以被提交；一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配特性，之前的日志条目也都会被间接的提交</strong>。在某些情况下，领导人可以安全的知道一个老的日志条目是否已经被提交（例如，该条目是否存储到所有服务器上），但是 Raft 为了简化问题使用一种更加保守的方法。</p><p>当领导人复制之前任期里的日志时，Raft 会为所有日志保留原始的任期号, 这在提交规则上产生了额外的复杂性。在其他的一致性算法中，如果一个新的领导人要重新复制之前的任期里的日志时，它必须使用当前新的任期号。Raft 使用的方法更加容易辨别出日志，因为它可以随着时间和日志的变化对日志维护着同一个任期编号。另外，和其他的算法相比，Raft 中的新领导人只需要发送更少日志条目（其他算法中必须在他们被提交之前发送更多的冗余日志条目来为他们重新编号）。但是，这在实践中可能并不十分重要，因为领导者更换很少发生。</p><p>举例：<br>如一个节点有之前任期的条目 2 和当前自己任期创建的条目 4 均未提交，那么他会向其他节点复制条目 2 和 4，但是条目 2 永远不能通过被超过半数节点复制来提交，只有当前任期的条目 4 才使用被超过半数节点复制则提交的方案。条目 2 的提交时机在于条目 4 的提交时机，一旦条目 4 被提交，条目 2 也会被间接提交。若条目 4 没被提交，就算所有节点都存在条目 2 ，条目 2 也不会提交。</p><h3 id="3-3-3-安全性论证"><a href="#3-3-3-安全性论证" class="headerlink" title="3.3.3 安全性论证"></a>3.3.3 安全性论证</h3><p>在给定了完整的 Raft 算法之后，我们现在可以更加精确的讨论领导者完整性特性（这一讨论基于 9.2 节的安全性证明）。我们假设领导者完全性特性是不存在的，然后我们推出矛盾来。假设任期 T 的领导者（领导者 T）在任期内提交了一条日志条目，但是这条日志条目没有被存储到未来某个任期的领导者的日志中。设大于 T 的最小任期 U 的领导者 U 没有这条日志条目。</p><p><img src="/9a0e6259ac11/raft-%E5%9B%BE9.png" alt="图 9"></p><blockquote><p>图 9：如果 S1 （任期 T 的领导者）在它的任期里提交了一条新的日志，然后 S5 在之后的任期 U 里被选举为领导者，那么至少会有一个机器，如 S3，既拥有来自 S1 的日志，也给 S5 投票了。</p></blockquote><ol><li>在领导者 U 选举的时候一定没有那条被提交的日志条目（领导者从不会删除或者覆盖任何条目）。</li><li>领导者 T 复制这条日志条目给集群中的大多数节点，同时，领导者 U 从集群中的大多数节点赢得了选票。因此，至少有一个节点（投票者、选民）同时接受了来自领导者 T 的日志条目，并且给领导者 U 投票了，如图 9。这个投票者是产生这个矛盾的关键。</li><li>这个投票者必须在给领导者 U 投票之前先接受了从领导者 T 发来的已经被提交的日志条目；否则他就会拒绝来自领导者 T 的附加日志请求（因为此时他的任期号会比 T 大）。</li><li>投票者在给领导者 U 投票时依然保存有这条日志条目，因为任何中间的领导者都包含该日志条目（根据上述的假设），领导者从不会删除条目，并且跟随者只有在和领导者冲突的时候才会删除条目。</li><li>投票者把自己选票投给领导者 U 时，领导者 U 的日志必须和投票者自己一样新。这就导致了两者矛盾之一。</li><li>首先，如果投票者和领导者 U 的最后一条日志的任期号相同，那么领导者 U 的日志至少和投票者一样长，所以领导者 U 的日志一定包含所有投票者的日志。这是另一处矛盾，因为投票者包含了那条已经被提交的日志条目，但是在上述的假设里，领导者 U 是不包含的。</li><li>除此之外，领导者 U 的最后一条日志的任期号就必须比投票人大了。此外，他也比 T 大，因为投票人的最后一条日志的任期号至少和 T 一样大（他包含了来自任期 T 的已提交的日志）。创建了领导者 U 最后一条日志的之前领导者一定已经包含了那条被提交的日志（根据上述假设，领导者 U 是第一个不包含该日志条目的领导者）。所以，根据日志匹配特性，领导者 U 一定也包含那条被提交的日志，这里产生矛盾。</li><li>这里完成了矛盾。因此，所有比 T 大的领导者一定包含了所有来自 T 的已经被提交的日志。</li><li>日志匹配原则保证了未来的领导者也同时会包含被间接提交的条目，例如图 8 (e) 中的索引 2。</li></ol><p>通过领导者完全特性，我们就能证明图 3 中的状态机安全特性，即如果服务器已经在某个给定的索引值应用了日志条目到自己的状态机里，那么其他的服务器不会应用一个不一样的日志到同一个索引值上。在一个服务器应用一条日志条目到他自己的状态机中时，他的日志必须和领导者的日志，在该条目和之前的条目上相同，并且已经被提交。现在我们来考虑在任何一个服务器应用一个指定索引位置的日志的最小任期；日志完全特性保证拥有更高任期号的领导者会存储相同的日志条目，所以之后的任期里应用某个索引位置的日志条目也会是相同的值。因此，状态机安全特性是成立的。</p><p>最后，Raft 要求服务器按照日志中索引位置顺序应用日志条目。和状态机安全特性结合起来看，这就意味着所有的服务器会应用相同的日志序列集到自己的状态机中，并且是按照相同的顺序。</p><h2 id="3-4-跟随者和候选人崩溃"><a href="#3-4-跟随者和候选人崩溃" class="headerlink" title="3.4 跟随者和候选人崩溃"></a>3.4 跟随者和候选人崩溃</h2><p>到目前为止，我们都只关注了领导人崩溃的情况。跟随者和候选人崩溃后的处理方式比领导人要简单的多，并且他们的处理方式是相同的。如果跟随者或者候选人崩溃了，那么后续发送给他们的 RPCs 都会失败。Raft 中处理这种失败就是简单地通过无限的重试；如果崩溃的机器重启了，那么这些 RPC 就会完整的成功。如果一个服务器在完成了一个 RPC，但是还没有响应的时候崩溃了，那么在他重新启动之后就会再次收到同样的请求。Raft 的 RPCs 都是幂等的，所以这样重试不会造成任何问题。例如一个跟随者如果收到附加日志请求但是他已经包含了这一日志，那么他就会直接忽略这个新的请求。</p><h2 id="3-5-持久化状态与节点重启"><a href="#3-5-持久化状态与节点重启" class="headerlink" title="3.5 持久化状态与节点重启"></a>3.5 持久化状态与节点重启</h2><p>Raft 节点必须将足够的信息持久化至稳定存储，以实现节点重启后的安全恢复。其中，<strong>每个节点都需持久化自身的当前任期与投票记录</strong>；这一步是必要的，可防止节点在同一任期内重复投票，或用已被废黜领导者的日志条目覆盖新任领导者的日志条目。每个节点还需在日志条目被纳入提交统计前，完成新日志条目的持久化；这能避免节点重启时，已提交的日志条目丢失或被撤销提交。</p><p>其他状态变量在节点重启时丢失并无安全风险，因为这类变量均可重新生成。最具代表性的例子是 commitIndex —— 节点重启时，可将其安全地重新初始化为 0。即便集群中所有节点同时重启，commitIndex 也只会暂时滞后于其实际值。一旦领导者选举产生并能提交新的日志条目，其 commitIndex 便会向前推进，并迅速将该 commitIndex 同步至所有跟随者节点。</p><p>状态机可分为易失性和持久化两种类型。易失性状态机在节点重启后，必须通过重新应用日志条目完成恢复（需先应用最新的快照，详见第 5 章）。而持久化状态机在重启后，多数日志条目其实已完成应用；为避免重复应用这些条目，节点必须同时持久化自身的最后应用索引。</p><p>若节点丢失任意持久化状态，便无法以原有身份安全重新加入集群。此类节点通常可通过发起集群成员变更操作，以新身份重新加入集群（详见 <a href="#4%20%E9%9B%86%E7%BE%A4%E6%88%90%E5%91%98%E5%8F%98%E5%8C%96">4 集群成员变化</a>）。但如果集群中多数派节点均丢失了持久化状态，日志条目可能发生丢失，且集群成员变更操作也将无法推进；若要继续运行集群，系统管理员需接受数据丢失的可能性。</p><h2 id="3-6-时间和可用性"><a href="#3-6-时间和可用性" class="headerlink" title="3.6 时间和可用性"></a>3.6 时间和可用性</h2><p>Raft 的要求之一就是安全性不能依赖时间：整个系统不能因为某些事件运行的比预期快一点或者慢一点就产生了错误的结果。但是，可用性（系统可以及时的响应客户端）不可避免的要依赖于时间。例如，如果消息交换比服务器故障间隔时间长，候选人将没有足够长的时间来赢得选举；没有一个稳定的领导人，Raft 将无法工作。</p><p>领导人选举是 Raft 中对时间要求最为关键的方面。Raft 可以选举并维持一个稳定的领导人,只要系统满足下面的时间要求：</p><blockquote><p>广播时间（broadcastTime） &lt;&lt; 选举超时时间（electionTimeout） &lt;&lt; 平均故障间隔时间（MTBF）</p></blockquote><p>在这个不等式中，广播时间指的是从一个服务器并行的发送 RPCs 给集群中的其他服务器并接收响应的平均时间；选举超时时间就是在 <a href="#3.1%20%E9%A2%86%E5%AF%BC%E8%80%85%E9%80%89%E4%B8%BE">3.1 领导者选举</a> 中介绍的选举的超时时间限制；然后平均故障间隔时间就是对于一台服务器而言，两次故障之间的平均时间。广播时间必须比选举超时时间小一个量级，这样领导人才能够发送稳定的心跳消息来阻止跟随者开始进入选举状态；通过随机化选举超时时间的方法，这个不等式也使得选票瓜分的情况变得不可能。选举超时时间应该要比平均故障间隔时间小上几个数量级，这样整个系统才能稳定的运行。当领导人崩溃后，整个系统会大约相当于选举超时的时间里不可用；我们希望这种情况在整个系统的运行中很少出现。</p><p>广播时间和平均故障间隔时间是由系统决定的，但是选举超时时间是我们自己选择的。Raft 的 RPCs 需要接收方将信息持久化的保存到稳定存储中去，所以广播时间大约是 0.5 毫秒到 20 毫秒，取决于存储的技术。因此，选举超时时间可能需要在 10 毫秒到 500 毫秒之间。大多数的服务器的平均故障间隔时间都在几个月甚至更长，很容易满足时间的需求。</p><h2 id="3-7-领导者移交扩展"><a href="#3-7-领导者移交扩展" class="headerlink" title="3.7 领导者移交扩展"></a>3.7 领导者移交扩展</h2><p>本节介绍 Raft 的一项<strong>可选扩展机制</strong>，支持将集群中某一节点的领导权移交至另一节点。该领导者移交机制主要适用于两类场景：</p><ol><li>领导者需主动退位的情况。例如，节点可能因维护需要重启，或即将被移出集群（详见 <a href="#4%20%E9%9B%86%E7%BE%A4%E6%88%90%E5%91%98%E5%8F%98%E5%8C%96">4 集群成员变化</a>）。若领导者直接退位，集群会在一个选举超时时间内处于空闲状态，直至其他节点因选举超时发起选举并胜出。而如果领导者在退位前将领导权主动移交至其他节点，便可避免这一短暂的不可用状态。</li><li>部分节点比其他节点更适合担任领导者的情况。例如，高负载的节点并非领导者的合适人选；在广域网部署架构中，为最小化客户端与领导者之间的网络延迟，通常更倾向于由主数据中心内的节点担任领导者。其他共识算法或许能在领导者选举阶段直接适配这类偏好，但 Raft 要求领导者必须是<strong>日志足够新</strong>的节点，而这类节点未必是最优选择。对此，Raft 中的现任领导者可定期检查可用的跟随者节点，判断是否存在更适合担任领导者的节点；若存在，则将领导权移交至该节点。（倘若人类中的领导者也能如此从容让位就好了。）</li></ol><p>在 Raft 中执行领导者移交时，<strong>前任领导者</strong>会先将自身的日志条目同步至目标节点，随后让目标节点无需等待选举超时时间结束，直接发起选举。通过这一方式，前任领导者能确保目标节点在其任期开始时，已拥有集群中所有的已提交日志条目；同时，与正常选举流程一致，<strong>多数派投票机制</strong>会保障 Raft 各项安全属性（如领导者完备性原则）始终得以维持。以下是该移交过程的详细执行步骤：</p><ol><li>前任领导者停止接收新的客户端请求；</li><li>当前领导者完整更新目标服务器的日志以使其与自己的日志匹配，使用前文描述的 <a href="#3.2%20%E6%97%A5%E5%BF%97%E5%A4%8D%E5%88%B6">3.2 日志复制</a>。</li><li>前任领导者向目标节点发送 <strong>TimeoutNow 请求</strong>，该请求的效果等同于目标节点的<strong>选举计时器触发</strong>：目标节点立即启动一次新的选举（增加自身任期号并成为候选节点）。</li></ol><p>目标节点接收到 TimeoutNow 请求后，大概率会先于集群中其他节点发起选举，并在新一任期内当选领导者。其向现任领导者发送的第一条消息会包含新的任期号，这一信息会触发前任领导者正式退位，至此领导者移交操作完成。</p><p>该机制也需考虑异常场景：若目标节点发生故障，集群必须恢复正常的客户端业务处理。如果在约一个选举超时时间后，领导者移交仍未完成，前任领导者会<strong>终止此次移交操作</strong>，并恢复接收客户端请求。即便前任领导者判断失误、目标节点实际处于可用状态，该失误造成的最坏结果也只是触发一次额外的选举，选举结束后集群的客户端业务处理便会恢复正常。</p><p>这一移交方案完全遵循 Raft 集群的<strong>正常状态转换规则</strong>，因此能保障共识安全性。例如，Raft 本身已保证，即便节点时钟以任意速度运行，集群的安全性也不会受影响；而目标节点接收 TimeoutNow 请求，其效果等同于该节点的时钟快速向前跳变，这一情况在 Raft 的安全设计范围内。不过，目前我们尚未对该领导者移交方案开展工程实现与效果评估。</p><h1 id="4-集群成员变化"><a href="#4-集群成员变化" class="headerlink" title="4 集群成员变化"></a>4 集群成员变化</h1><p>到目前为止，我们始终假设集群配置（即参与共识算法的服务器节点集合）是固定不变的。但在实际应用中，我们偶尔需要对配置进行变更 —— 例如替换故障节点，或是调整副本的复制规模。这项操作可通过手动方式完成，具体有两种实现思路：</p><ol><li>先将整个集群下线，完成配置文件的更新后再重启集群，以此实现配置变更。但这种方式会导致集群在配置变更过程中完全不可用。</li><li>让新节点接管某一集群成员的网络地址，以此完成节点替换。但这种方式要求管理员必须确保被替换的节点永不重新上线，否则系统的安全性属性将遭到破坏（例如，集群中会出现额外的投票权，引发投票异常）。</li></ol><p>上述两种集群成员变更的方式均存在明显弊端，且只要涉及手动操作步骤，就必然存在人为操作失误的风险。</p><p>为规避这些问题，我们决定将配置变更流程自动化，并将其整合至 Raft 共识算法中。基于 Raft 的集群成员变更机制，集群在配置变更期间仍能保持正常运行，且该机制仅需对基础共识算法做少量扩展即可实现。图 4.1 总结了用于执行集群成员变更的远程过程调用（RPC）相关接口，其具体设计细节将在本章后续内容中展开说明。</p><p><img src="/9a0e6259ac11/4_1.png"></p><blockquote><p>图 4.1 用于执行集群成员变更的远程过程调用（RPC）<br>添加节点远程过程调用（AddServer RPC）用于将新节点添加至当前集群配置，移除节点远程过程调用（RemoveServer RPC）用于将某一节点从当前集群配置中移除。§4.1 这类章节编号，标识了各特性的具体论述位置；4.4 节则阐述了在完整的系统中，如何使用这些远程过程调用的具体方法。</p></blockquote><h2 id="4-1-安全性"><a href="#4-1-安全性" class="headerlink" title="4.1 安全性"></a>4.1 安全性</h2><p>保障安全性是集群配置变更面临的首要挑战。要让该配置变更机制具备安全性，就必须保证<strong>在配置变更的过渡阶段，绝对不会出现同一任期内选举出两位领导者的情况</strong>。若一次配置变更操作添加或移除多个节点，直接将集群从旧配置切换至新配置的方式存在安全风险：我们无法让所有节点同时完成原子性的配置切换，因此集群在过渡阶段有可能分裂为两个相互独立的多数派（见图 4.2）。</p><p><img src="/9a0e6259ac11/raft-%E5%9B%BE10.png" alt="图 10"></p><blockquote><p>图 10：直接从一种配置转到新的配置是十分不安全的，因为各个机器可能在任何的时候进行转换。在这个例子中，集群配额从 3 台机器变成了 5 台。不幸的是，存在这样的一个时间点，两个不同的领导人在同一个任期里都可以被选举成功。一个是通过旧的配置，一个通过新的配置。</p></blockquote><p>大多数成员更改算法都引入了其他机制来处理这种问题。这是我们最初为 Raft 所做的，但后来我们发现了一个更简单的方法，<strong>即禁止会导致多数成员不相交的成员更改</strong>。因此，Raft 限制了允许的更改类型：一次只能从集群中添加或删除一个服务器。成员更改中更复杂的更改是通过一系列单服务器更改实现的。本章的大部分内容描述了单服务器方法，它比我们原来的方法更容易理解。为了完整起见，第 4.3 节描述了原始的方法，它增加了处理任意配置更改的复杂性。在发现更简单的单服务器更改方法之前，我们在 LogCabin 中实现了更复杂的方法；在撰写本文时，它仍然使用更复杂的方法。</p><p><strong>当仅向集群添加&#x2F;移除一个节点时，旧集群的任意多数派与新集群的任意多数派之间必然存在重叠</strong>（见图 4.3）。这种重叠特性可防止集群分裂为两个相互独立的多数派；在 <a href="#3.3.3%20%E5%AE%89%E5%85%A8%E6%80%A7%E8%AE%BA%E8%AF%81">3.3.3 安全性论证</a> 中，这一特性保证了「投票者（the voter）」的存在。因此，仅增删单个节点时，直接切换至新配置的操作具备安全性。Raft 正是利用这一特性，仅通过少量额外机制就实现了集群成员的安全变更。</p><p><img src="/9a0e6259ac11/4_3.png"></p><blockquote><p>图 4.3：从偶数和奇数大小的集群中添加和删除单个服务器。<br>在每个图中，蓝色矩形显示旧集群的大部分，红色矩形显示新集群的大部分。在每个单服务器成员更改中，旧集群的任意多数派与新集群的任意多数派之间的重叠性均能得到保持，这用来保证安全性。例如在子图 (b) 中，旧集群的多数派需包含左侧 3 个节点中的至少 2 个；新集群的多数派需包含新集群全部节点中的至少 3 个，且这 3 个节点里至少有 2 个必须来自旧集群。</p></blockquote><p>集群配置信息通过复制日志中的专用日志条目进行存储和传播。这一设计借助 Raft 已有的机制来实现配置信息的复制与持久化；同时，通过为配置变更和客户端请求设定执行顺序（允许两者在管道或批处理被并发复制），集群在配置变更过程中仍可持续响应客户端请求。</p><p>当领导者收到从当前配置（C<sub>old</sub>）中增删节点的请求时，它将新配置（C<sub>new</sub>）作为一条日志条目追加到自身日志中，并通过 Raft 的常规机制复制该条目。<br><strong>每个节点一旦将新配置条目添加到自身的日志中，新配置便立即在该节点生效</strong>：C<sub>new</sub> 条目会被复制到新配置包含的所有节点，且系统会以新配置下的多数派节点为依据，判定该 C<sub>new</sub> 条目是否提交。这意味着节点无需等待配置条目完成提交，而是始终使用自身日志中最新的配置。</p><p>当 C<sub>new</sub>​ 条目完成提交时，本次配置变更即宣告完成。此时领导者能够确认：新配置 C<sub>new</sub> ​已被多数派的新配置节点采纳；同时也能确定，所有未切换至 C<sub>new</sub> ​的节点已无法构成集群的多数派，且未采纳 C<sub>new</sub> ​的节点也无法被选举为领导者。C<sub>new</sub>​ 的提交使得以下三类操作可以正常执行：</p><ol><li>领导者可向请求方确认配置变更已成功完成；</li><li>若本次配置变更涉及节点移除，则被移除的节点可被下线；</li><li>可启动后续的配置变更操作。在此之前，若叠加执行配置变更，可能会导致集群陷入图 4.2 所示的不安全状态。</li></ol><p>如前文所述，无论配置条目是否已提交，节点始终使用自身日志中最新的配置。这一设计让领导者可轻松避免配置变更的叠加执行（即上述第三点）—— 只需在前置变更的日志条目提交前，不启动新的变更操作即可。只有当旧配置下的多数派节点均已按 C<sub>new</sub> ​的规则运行时，启动新的成员变更操作才是安全的。若节点仅在确认 C<sub>new</sub> ​已提交后才采纳该配置，Raft 领导者将难以判断旧配置下的多数派节点是否已完成配置切换：领导者需要追踪哪些节点知晓该条目已提交，且节点需将自身的提交索引持久化至磁盘 —— 而这两种机制均非 Raft 的必需设计。相反，每个节点在 C<sub>new</sub> ​条目写入自身日志后立即采纳该配置，且领导者只需确认 C<sub>new</sub> ​条目已提交，即可判定启动后续配置变更操作是安全的。但需注意，这一设计也意味着：配置变更的日志条目可能被移除（例如领导者发生变更时）；在此情况下，节点必须能够回退到自身日志中前一版的配置。</p><p>在 Raft 中，达成共识的过程（包括投票和日志复制）均遵循<strong>请求发起方的配置规则</strong>，具体规则如下：</p><ul><li>节点会接受来自「非自身最新配置成员」的领导者的 AppendEntries 请求。否则，新节点将永远无法被加入集群（因为它不会接受任何「添加该节点的配置条目」之前的日志条目）；</li><li>节点也会将选票投给「非自身最新配置成员」的候选人（前提是该候选人的日志足够新，且任期号为当前有效任期）。这类投票有时是保障集群可用性的必要操作。例如：向一个 3 节点集群中添加第 4 个节点后，若其中一个原有节点故障，就需要新节点的投票才能形成多数派、选举出领导者。</li></ul><p>因此，节点处理入站 RPC 请求时，无需查阅自身当前的配置。</p><h2 id="4-2-可用性"><a href="#4-2-可用性" class="headerlink" title="4.2 可用性"></a>4.2 可用性</h2><p>集群成员变更会引发多项影响集群可用性保障的问题。4.2.1 节阐述了新节点加入集群前的日志追平机制，避免其阻塞新日志条目的提交流程；4.2.2 节说明若现任领导者被移出集群，应如何对其完成逐步下线操作；4.2.3 节则介绍了如何防止已被移除的节点干扰新集群的领导者。最后，4.2.4 节阐明了为何这一设计成型的成员变更算法，足以在任意集群成员变更过程中保障集群的可用性。</p><h3 id="4-2-1-新节点的日志追平"><a href="#4-2-1-新节点的日志追平" class="headerlink" title="4.2.1 新节点的日志追平"></a>4.2.1 新节点的日志追平</h3><p>当新节点被加入集群时，其通常未存储任何日志条目。若节点以该状态加入集群，其日志可能需要较长时间才能追平领导者的日志，而在此期间，集群会更容易陷入不可用状态。例如，一个三节点集群在正常情况下可容忍单节点故障且不损失可用性；但如果为该集群新增一个空日志的第四节点，且原有三个节点中有一个发生故障，集群将暂时无法提交新的日志条目（见图 4.4（a））。若短时间内向集群批量新增多个节点，且这些新节点需参与集群多数派共识，也会引发可用性问题（见图 4.4（b））。上述两种情况中，除非新节点的日志追平领导者的日志，否则集群将一直处于不可用状态。</p><p><img src="/9a0e6259ac11/4_4.png"></p><blockquote><p>图 4.4 新增空日志节点危及集群可用性的示例<br>本图展示了两个不同集群中的节点日志状态。每个集群初始均包含 3 个节点，即 S1 至 S3。<br>场景（a）中，新增节点 S4 后，节点 S3 发生故障。集群本应在单节点故障后保持正常运行，却因此丧失了可用性：此时提交新日志条目需要 4 个节点中的 3 个参与共识，但 S3 已发生故障，且 S4 的日志落后过多，无法追加新日志条目。<br>场景（b）中，节点 S4、S5、S6 被接连新增至集群。提交新增 S6（第三个新节点）的配置日志条目时，需要 4 个节点的日志均完成该条目的存储，而 S4 至 S6 的日志均大幅落后于集群最新状态。<br>除非新节点完成日志追平，否则上述两个集群均无法恢复可用状态。</p></blockquote><p>为避免出现可用性空档，Raft 在配置变更前新增了一个阶段：新节点以<strong>非投票节点</strong>的身份加入集群。领导者会向其复制日志条目，但在投票和日志提交的多数派计算中，该节点暂不被纳入统计。待新节点的日志追平集群其他节点后，配置变更即可按前述流程执行。（这套支持非投票节点的机制在其他场景中同样适用，例如可通过该机制将集群状态复制至大量节点，由这些节点处理一致性要求较低的只读请求。）</p><p>领导者需要判断新节点的日志何时达到足够同步的状态，才能继续执行配置变更。这一判断过程需谨慎处理以保障可用性：若过早将新节点纳入投票节点，集群的可用性仍会面临前述的风险。我们的设计目标是，让任何临时性的不可用时长都不超过<strong>选举超时时间</strong> —— 因为客户端本就需要能够容忍这种时长的偶发不可用（如领导者故障时的情况）。此外，在条件允许的情况下，我们会尽可能让新节点的日志更贴近领导者的日志，进一步缩短不可用的时间。</p><p>若新节点处于不可用状态，或同步速度过慢、始终无法完成日志追平，领导者应终止此次配置变更。这一检查步骤至关重要：Lamport 所设想的早期 Paxon（早期 Paxos）共识机制之所以会失效，正是因为缺少了该步骤 —— 其集群成员被意外修改为全部是已遇难的船员，导致集群彻底无法推进任何操作。尝试加入不可用或同步缓慢的节点，往往是操作失误所致。事实上，我们在首次测试配置变更请求时，曾因网络端口号的拼写错误导致新节点无法连接，而系统也正确终止了此次变更并返回了错误信息。</p><p>我们提出以下算法，用于判断新节点的日志是否达到足够同步的状态、可被正式加入集群：领导者向新节点的日志条目复制过程<strong>分轮次进行</strong>（见图 4.5）。每一轮的操作，是将领导者在本轮开始时日志中存在的所有条目，全部复制至新节点的日志。在复制当前轮次条目期间，领导者可能会接收到新的日志条目，这些条目将在后续轮次中完成复制。随着同步的推进，每一轮次的耗时会逐步缩短。该算法会等待固定的轮次数（如 10 轮），若最后一轮的耗时小于一个选举超时时间，则领导者可将新节点正式加入集群 —— 此时可认为未完成复制的日志条目数量极少，不会造成显著的可用性空档。反之，领导者则终止此次配置变更并返回错误，调用方可重新发起请求（由于新节点的日志已完成部分同步，后续请求的成功率会更高）。</p><p><img src="/9a0e6259ac11/4_5.png"></p><blockquote><p>图 4.5 新节点日志追平的轮次复制机制<br>为实现新节点的日志追平，领导者向新节点的日志条目复制过程采用<strong>分轮次执行</strong>的方式。当新节点同步完领导者在<strong>本轮开始时</strong>日志中的所有条目后，本轮复制即完成；但在此期间，领导者可能已接收到新的日志条目，这类条目将在<strong>下一轮次</strong>中完成复制。</p></blockquote><p>新节点日志追平的第一步，是领导者发现新节点的日志为空。对于全新节点，<code>AppendEntries</code>（追加日志）RPC 的一致性检查会反复失败，直到领导者为该节点维护的 <code>nextIndex</code>（下一个日志索引）最终降至 1。这一反复交互的过程，可能成为新节点加入集群时的主要性能瓶颈（完成该阶段后，可通过<strong>批量传输</strong>的方式，以更少的 RPC 请求向跟随者同步日志条目）。可通过多种方式让 <code>nextIndex</code> 更快收敛至正确值，包括第 3 章中提及的方法。而针对新节点加入这一特定场景，最简单的解决方案是：让跟随者在 <code>AppendEntries</code> 的响应中返回自身的日志长度，领导者即可据此为跟随者的 <code>nextIndex</code> 设置上限。</p><h3 id="4-2-2-移除现任领导者"><a href="#4-2-2-移除现任领导者" class="headerlink" title="4.2.2 移除现任领导者"></a>4.2.2 移除现任领导者</h3><p>若要求现任领导者将自身从集群中移除，其必须在某个时间点<strong>退位</strong>。一种直接的解决方案是使用 <a href="#3.7%20%E9%A2%86%E5%AF%BC%E8%80%85%E7%A7%BB%E4%BA%A4%E6%89%A9%E5%B1%95">3.7 领导者移交扩展</a> 扩展机制：接收到自移除指令的领导者，会将领导权移交至其他节点，再由新的领导者正常执行集群成员变更操作。</p><p>我们最初为 Raft 设计了另一种方案：由现任领导者自行执行移除自身的成员变更操作，完成后再退位。该方案会让 Raft 进入一种稍显特殊的运行模式 —— 领导者会临时管理一个自身并非成员的集群配置。我们最初在设计<strong>任意配置变更</strong>（见 <a href="#4.4%20%E5%9F%BA%E4%BA%8E%E8%81%94%E5%90%88%E5%85%B1%E8%AF%86%E7%9A%84%E4%BB%BB%E6%84%8F%E9%85%8D%E7%BD%AE%E5%8F%98%E6%9B%B4">4.4 基于联合共识的任意配置变更</a>）时必须采用该方案，因为旧配置和新配置可能不存在任何公共节点，导致领导权无法完成移交。对于未实现领导者移交机制的系统，该方案同样适用。</p><p>在该方案中，被移出配置的领导者会在<strong>新配置条目（Cnew）</strong> 提交后正式退位。若领导者在 Cnew 提交前退位，其仍可能因选举超时重新当选领导者，进而导致集群进度停滞。在双节点集群中移除领导者的极端场景下，该节点甚至可能需要重新当选领导者，集群才能继续推进操作（见图 4.6）。因此，领导者会等待 Cnew 提交后再退位 —— 这是新配置无需被移除领导者参与、即可独立正常运行的首个时间节点：此时新配置（Cnew）的成员必然能在内部选举出一位新的领导者。被移除的领导者退位后，Cnew 中的某个节点会因选举超时发起选举并胜出。这一短暂的可用性空档是可容忍的，因为领导者故障时也会出现类似的情况。</p><p><img src="/9a0e6259ac11/4_6.png"></p><blockquote><p>图 4.6 新配置条目提交前，被移除的节点仍需担任领导者以推进集群操作<br>本图展示了双节点集群中移除节点 S1 的场景。S1 为集群当前的领导者，此时暂不应退位 —— 集群仍需要由其担任领导者。S2 在从 S1 处接收新配置条目（Cnew）前，无法当选为新领导者（原因在于：S2 仍需获得 S1 的选票，才能构成旧配置（Cold）的多数派；而 S1 会因 S2 的日志未同步至最新状态，拒绝为其投出选票）。</p></blockquote><p>该方案会带来两个关于集群决策的推论，这些推论并无明显弊端，但可能与直觉不符：第一，在 Cnew 的提交阶段，领导者会在一段时间内管理一个自身并非成员的集群 —— 其仍会向集群复制日志条目，但在多数派计算中不再将自身纳入统计；第二，若某个节点并非自身最新配置的成员，其仍应发起新的选举，因为在 Cnew 提交前，集群可能仍需要该节点发挥作用（见图 4.6）。除非该节点属于自身的最新配置，否则其在选举中不会将自身的选票纳入统计。</p><h3 id="4-2-3-干扰性节点"><a href="#4-2-3-干扰性节点" class="headerlink" title="4.2.3 干扰性节点"></a>4.2.3 干扰性节点</h3><p>若缺少额外的机制，未被纳入新配置（Cnew）的节点会干扰集群的正常运行。一旦集群领导者生成 Cnew 条目，未被纳入 Cnew 的节点将不再收到心跳包，进而因选举超时发起新的选举。此外，这些节点无法接收 Cnew 条目，也无法感知该条目的提交，因此始终不会知晓自身已被移出集群。它们会携带<strong>更大的任期号</strong>发送 <code>RequestVote</code>（请求投票）RPC，这会导致当前的领导者退化为跟随者状态。尽管 Cnew 中的节点最终会选举出新的领导者，但这些干扰性节点会再次因选举超时发起选举，上述过程将不断重复，最终导致集群可用性大幅下降。若多个节点被移出集群，该情况会进一步恶化。</p><p>我们最初为解决该干扰问题提出的方案是：节点在发起选举前，应先检查自身是否有机会赢得选举，避免浪费其他节点的资源。这一设计为选举流程新增了一个阶段，即<strong>预投票（Pre-Vote）阶段</strong>：候选节点会先向其他节点询问，自身的日志是否足够新、能否获得它们的选票；只有当候选节点确认自身能获得集群多数派的选票时，才会增加自身的任期号并发起正式的选举。</p><p>遗憾的是，预投票阶段无法解决干扰性节点的问题：在某些场景下，干扰性节点的日志足够新，但其发起的选举仍会对集群造成干扰。令人意外的是，这类情况甚至会在配置变更完成前发生。例如，图 4.7 展示了一个节点被移出四节点集群的场景：一旦领导者生成 Cnew 日志条目，待移除的节点就会成为干扰性节点。此时预投票检查无法发挥作用，因为该待移除节点的日志，比旧配置和新配置中多数派节点的日志都更新。（尽管预投票阶段无法解决干扰性节点的问题，但该设计能有效提升领导者选举的整体鲁棒性，具体见第 9 章。）</p><p><img src="/9a0e6259ac11/4_7.png"></p><blockquote><p>图 4.7 新配置条目提交前节点即可产生干扰且预投票阶段无法发挥作用的示例<br>本图展示了四节点集群中移除节点 S1 的场景。S4 为新配置的领导者，已在自身日志中生成新配置条目（Cnew），但尚未将该条目复制至集群其他节点；旧配置中的节点也不再收到 S4 发送的心跳包。即便在 Cnew 完成提交前，S1 就会因选举超时递增自身任期号，并将该更大的任期号发送至新配置中的节点，最终迫使 S4 退位。预投票算法在此场景下无法发挥作用，原因是 S1 的日志新鲜度，与新旧任一配置中多数派节点的日志持平。</p></blockquote><p>基于这一场景我们得出结论：<strong>仅通过日志对比的方案</strong>（如预投票检查），无法判断一次选举是否会对集群造成干扰。我们无法要求节点在发起选举前，检查 Cnew 中所有节点的日志 —— 因为 Raft 必须始终能容忍节点故障。同时，我们也不愿假设领导者能以足够快的速度复制日志条目，快速脱离图 4.7 所示的场景：这一假设在实际中可能成立，但它依赖于更强的性能前提（日志分歧的检测性能、日志条目的复制性能），而我们更倾向于避免这类假设。</p><p>Raft 最终采用的解决方案是：<strong>通过心跳包判断集群是否存在有效的领导者</strong>。在 Raft 中，若领导者能持续向跟随者发送心跳包，则认为该领导者处于活跃状态（否则其他节点会发起选举）。因此，对于能正常接收领导者心跳包的集群，其他节点不应能对其造成干扰。我们通过修改 <code>RequestVote</code> RPC 实现这一逻辑：若节点在<strong>最小选举超时时间</strong>内收到过现任领导者的心跳包，当它再接收到 <code>RequestVote</code> 请求时，不会更新自身的任期号，也不会投出选票。该节点可直接丢弃请求、回复拒绝投票，或延迟处理请求，三种方式的实际效果基本一致。这一修改不会影响正常的选举流程 —— 因为正常情况下，每个节点都会等待至少一个最小选举超时时间后，才会发起选举。但它能有效避免未被纳入 Cnew 的节点造成的干扰：只要领导者能持续向其配置内的节点发送心跳包，就不会因其他节点的更大任期号而被废黜。</p><p>该修改会与前文描述的领导者移交机制产生冲突 —— 在领导者移交过程中，节点可无需等待选举超时，合法发起选举。针对该场景，其他节点即使感知到集群存在现任领导者，也仍需处理该 <code>RequestVote</code> 请求。解决方案是：在这类 <code>RequestVote</code> 请求中添加一个<strong>特殊标记</strong>，用于标识该选举的合法性（即 “我获得了干扰领导者的许可 —— 是它让我发起的选举！”）。</p><h3 id="4-2-3-可用性论证"><a href="#4-2-3-可用性论证" class="headerlink" title="4.2.3 可用性论证"></a>4.2.3 可用性论证</h3><p>本节将论证，上述解决方案足以在集群成员变更的全过程中维持集群的可用性。由于 Raft 的成员变更操作由领导者主导，我们将从以下方面展开论证：该算法能在成员变更过程中持续维护领导者的存在、并在需要时完成领导者替换；且变更过程中的领导者能够正常处理客户端请求，并完成配置变更操作。本论证的前提包括：旧配置（Cold）的多数派节点保持可用（至少直至 Cnew 提交），且新配置（Cnew）的多数派节点同样保持可用。</p><ol><li><p><strong>配置变更的所有阶段，集群均能选举出领导者</strong></p><ul><li>若新配置中日志最新的可用节点已包含 Cnew 条目，则该节点可收集 Cnew 多数派的选票，成为新的领导者。</li><li>若上述节点未包含 Cnew 条目，则说明 Cnew 尚未提交。此时，在旧配置和新配置的所有节点中，日志最新的可用节点能同时收集到 Cold 多数派和 Cnew 多数派的选票，因此无论基于哪种配置，该节点都能当选领导者。</li></ul></li><li><p><strong>领导者当选后将持续维持领导权</strong>（假设其能向自身所属配置的节点正常发送心跳包），仅当一种情况会主动退位：自身并非 Cnew 的成员，且已完成 Cnew 的提交。</p><ul><li>若领导者能稳定地向自身所属配置的节点发送心跳包，则其自身及所有跟随者都不会接受更大的任期号：这些节点不会因选举超时发起新的选举，且会忽略其他节点携带更大任期号的 <code>RequestVote</code> 请求，因此领导者不会被强制退位。</li><li>若未被纳入 Cnew 的节点完成 Cnew 的提交并退位，Raft 会随即选举出新的领导者，该领导者大概率属于 Cnew，进而推动配置变更完成。当然，该退位节点仍有极小概率重新当选领导者；若其再次当选，会先确认 Cnew 的提交状态，随后迅速退位，而下一次选举的胜出者大概率会是 Cnew 中的节点。</li></ul></li><li><p><strong>配置变更的全过程中，领导者始终能处理客户端请求</strong></p><ul><li>变更过程中，领导者可持续将客户端请求追加至自身的日志。</li><li>由于新节点在被正式加入集群前已完成日志追平，领导者能及时推进自身的<strong>提交索引（commit index）</strong>，并向客户端返回响应。</li></ul></li><li><p><strong>领导者会持续推进直至完成配置变更</strong>：通过提交 Cnew 条目完成配置变更，必要时会主动退位，让 Cnew 中的节点当选新领导者。</p></li></ol><h2 id="4-3-基于联合共识的任意配置变更"><a href="#4-3-基于联合共识的任意配置变更" class="headerlink" title="4.3 基于联合共识的任意配置变更"></a>4.3 基于联合共识的任意配置变更</h2><p>本节提出一种更复杂的集群成员变更方案，可一次性处理集群配置的任意变更。例如，可向集群一次性新增两个节点，也可一次性替换五节点集群中的所有节点。这是我们最早提出的成员变更方案，在此仅作完整说明。如今我们已掌握更简洁的单节点变更方案，因此更推荐采用该方案 —— 因为处理任意配置变更需要引入额外的实现复杂度。文献中探讨成员变更时，通常默认其为一次性的任意变更，但我们认为，实际系统中无需这种灵活性：通过一系列单节点变更操作，即可将集群成员调整为任意期望的配置。</p><p>为确保任意配置变更全过程的安全性，集群会先切换至一种名为<strong>联合共识</strong>的过渡配置；待联合共识配置提交完成后，系统再正式切换至新配置。联合共识配置融合了旧配置与新配置的所有规则，具体如下：</p><ul><li>日志条目会同步复制至新旧两种配置包含的<strong>所有节点</strong>；</li><li>新旧配置中的任意节点均有资格担任集群领导者；</li><li>共识达成（包括领导者选举和日志条目提交），需<strong>同时获得旧配置和新配置各自的多数派认可</strong>。例如，将 3 节点集群变更为另一组 9 节点集群时，共识达成需同时满足：旧配置 3 节点中的 2 个节点认可，且新配置 9 节点中的 5 个节点认可。</li></ul><p>联合共识机制允许集群中的各个节点在<strong>不同时间点完成配置切换</strong>，且不会损害共识安全性。此外，该机制能让集群在配置变更的全过程中，持续处理客户端的请求。</p><p>该方案在单节点成员变更算法的基础上做了扩展，新增了一条用于存储联合共识配置的中间日志条目，图 4.8 展示了这一完整过程。当领导者接收到将配置从旧配置（Cold​）变更为新配置（Cnew​）的请求时，会将联合共识配置（图中记为 Cold,new​）作为一条日志条目存入自身日志，并通过 Raft 的常规机制将该条目复制至集群其他节点。与单节点配置变更算法的规则一致，各节点在将配置条目存入自身日志后，会<strong>立即启用该配置</strong>。这意味着，领导者会依据 Cold,new​的规则，判断该联合共识配置的日志条目是否完成提交。若此时领导者发生故障，新的领导者可能基于 Cold​或 Cold,new​选举产生，具体取决于胜出的候选节点是否已接收并存储 Cold,new​配置条目。无论何种情况，此阶段的 Cnew​都<strong>无法单独作出任何共识决策</strong>。</p><p>待 Cold,new​配置条目提交完成后，Cold​和 Cnew​均无法脱离对方的认可单独作出共识决策；同时，<strong>领导者完备性原则</strong>会保证，只有存储了 Cold,new​日志条目的节点，才有资格被选举为领导者。此时，领导者即可安全地创建一条描述 Cnew​的配置日志条目，并将其复制至整个集群。同样，各节点在接收到该 Cnew​配置条目后，会立即启用新配置。当 Cnew​的配置条目依据其自身的规则完成提交后，旧配置便不再具备任何效力，未被纳入新配置的节点即可下线。如图 11 所示，整个配置变更过程中，不存在 Cold​和 Cnew​能同时单独作出共识决策的时间点，这一设计从根本上保障了配置变更的安全性。</p><p><img src="/9a0e6259ac11/raft-%E5%9B%BE11.png" alt="图 11"></p><blockquote><p>图 11：一个配置切换的时间线。虚线表示已经被创建但是还没有被提交的配置日志条目，实线表示最后被提交的配置日志条目。领导人首先创建了 Cold,new 的配置条目在自己的日志中，并提交到 Cold,new 中（Cold 的大多数和 Cnew 的大多数）。然后他创建 Cnew 条目并提交到 Cnew 中的大多数。这样就不存在 Cnew 和 Cold 可以同时做出决定的时间点。</p></blockquote><p>联合共识方案可进一步泛化，支持在前一次配置变更尚未完成时发起新的配置变更，但这一泛化设计并无实际应用价值。因此我们采用了更简洁的设计：当集群正在执行配置变更时（即领导者的最新配置尚未提交，或当前生效的是联合共识这类非简单多数派配置），领导者会直接拒绝新的配置变更请求。被拒绝的变更请求只需稍作等待，后续重新发起即可。</p><p>联合共识方案之所以比单节点变更方案更复杂，核心原因在于其需要完成<strong>向过渡配置的切换</strong>，以及<strong>从过渡配置向新配置的回切</strong>。同时，联合共识配置还需要修改所有与投票、日志提交相关的共识决策逻辑：领导者不再是简单统计参与共识的节点数量，而是需要分别检查这些节点是否构成旧配置的多数派，<strong>且</strong>同时构成新配置的多数派。在我们的 Raft 工程实现中，仅需找到并修改约六处相关的数量对比逻辑，即可完成该机制的落地。</p><h2 id="4-4-系统集成"><a href="#4-4-系统集成" class="headerlink" title="4.4 系统集成"></a>4.4 系统集成</h2><p>Raft 的各实现可通过不同方式，对外提供本章所述的集群成员变更机制。例如，图 4.1 中的 <code>AddServer</code> 和 <code>RemoveServer</code> 远程过程调用（RPC），可由管理员直接发起，也可由脚本调用 —— 该脚本通过一系列单节点变更步骤，实现任意形式的集群配置调整。</p><p><img src="/9a0e6259ac11/4_1.png"></p><p>实践中，或许可以根据节点故障这类事件自动触发集群成员变更操作，但这一操作必须遵循合理的策略执行。例如，集群若自动移除故障节点会存在风险，这可能导致集群副本数量过少，无法满足预设的持久性和容错性要求。一种合理的方案是，由系统管理员配置集群的<strong>目标规模</strong>，在该规模限制下，让可用节点自动替换故障节点。</p><p>在执行需要多步单节点变更的集群成员变更操作时，<strong>建议遵循先增后删的原则</strong>。例如，在三节点集群中替换某一节点时，先新增一个节点再移除目标节点，能让系统在变更的全过程中，始终保持单节点故障的容忍能力；但如果先移除节点再新增，系统会暂时丧失故障屏蔽能力 —— 因为双节点集群要求两个节点均处于可用状态，才能完成共识决策。</p><p>集群成员变更机制，促使我们采用一种全新的<strong>集群引导</strong>方式。无动态成员管理能力时，各节点仅需通过静态配置文件记录集群配置；而支持动态成员变更后，便不再需要该静态配置文件 —— 因为系统会将集群配置纳入 Raft 日志进行统一管理，同时静态配置文件也存在潜在的配置错误风险（例如，新节点应使用哪一版集群配置完成初始化？）。因此，我们建议集群首次创建时按如下方式操作：先对单个节点完成初始化，将一条集群配置条目作为其日志的第一条条目，该配置条目仅包含该节点自身；由于该节点可单独构成其所属配置的多数派，因此能直接认定该配置已完成提交。此后，其他节点均以空日志状态完成初始化，通过集群成员变更机制被加入集群，并同步获取当前的集群配置。</p><p>集群成员变更还要求为客户端设计<strong>动态的集群发现机制</strong>，相关实现细节将在第 6 章展开论述。</p><h2 id="4-5-结论"><a href="#4-5-结论" class="headerlink" title="4.5 结论"></a>4.5 结论</h2><p>本章阐述了 Raft 的一项扩展机制，用于实现集群成员变更的自动化处理。这是完整共识类系统的重要组成部分 —— 因为系统的容错性需求会随时间发生变化，且故障节点最终也需完成替换。</p><p>共识算法从根本上必须参与到配置变更全过程的安全性保障中，原因在于新的集群配置会改变 “多数派” 的判定内涵。本章提出了一种简洁的实现方案，支持单次新增或移除单个节点。这类操作以简洁的方式保障了共识安全性，核心原因是变更过程中，任意两个不同的多数派集合间至少存在一个公共节点。通过组合多次单节点变更操作，可实现更复杂的集群配置调整。同时，Raft 机制能让集群在成员变更的全过程中保持正常运行。</p><p>保障配置变更过程中的集群可用性，需要解决若干非基础性问题。其中，尤为值得注意的是，未被纳入新配置的节点干扰集群合法领导者这一问题，具有出乎意料的隐蔽性；我们曾尝试过多种基于日志对比的解决方案，但均存在缺陷，最终才确定了基于心跳包的可行解决方案。</p><h1 id="5-日志压缩"><a href="#5-日志压缩" class="headerlink" title="5 日志压缩"></a>5 日志压缩</h1><p>Raft 日志在正常运行过程中，会随客户端请求的持续写入不断增长。日志体积越大，占用的存储空间就越多，日志重放的耗时也越长。若未采取任何日志压缩手段，最终将引发可用性问题：节点要么因存储空间耗尽无法运行，要么启动耗时过长。因此，任何实际的分布式系统都需实现某种形式的日志压缩。</p><p>日志压缩的核心思路是，日志中的大量信息会随时间推移失效，可直接舍弃。例如，若某条操作将变量 x 赋值为 2，后续另有操作将 x 赋值为 3，那么前者便失去效用。当日志条目完成提交并应用至状态机后，用于达成当前状态的各类中间状态和操作便无保留必要，可通过压缩对其进行清理。</p><p>与 Raft 核心算法、集群成员变更不同，不同系统对日志压缩的需求各有差异，目前尚无适用于所有场景的日志压缩解决方案，原因有二。其一，不同系统会在实现简洁性与运行性能之间，做出不同程度的取舍。其二，日志压缩的实现需要状态机深度参与，而各类状态机在规模上差异显著，且底层存储介质也分为磁盘型和易失性内存型两类。</p><p>本章旨在探讨多种日志压缩的实现方案。在各类方案中，日志压缩的主要工作均由状态机承担 —— 状态机负责将自身状态写入磁盘并完成状态压缩。状态机可通过多种方式实现这一需求，相关细节将在本章逐一阐述，并在图 5.1 中进行汇总说明：</p><p><img src="/9a0e6259ac11/5_1.png"></p><blockquote><p>图 5.1 展示了各类日志压缩方案在 Raft 中的具体应用方式。图中日志结构合并树的相关细节以 LevelDB 为参考，日志清理的细节以 RAMCloud 为参考，其中删去了删除操作的管理规则。</p></blockquote><ul><li>从概念上讲，为基于内存的状态机创建快照最为简单。执行快照时，将当前完整的系统状态写入稳定存储的快照文件，随后舍弃截至该时间点的全部日志。Chubby 和 ZooKeeper 均采用了该机制，我们也在 LogCabin 中实现了快照机制。本章 5.1 节将对这一方案展开最深入的阐述。</li><li>对于基于磁盘的状态机，系统会在常规运行过程中，将最新的系统状态副本持久化至磁盘。因此，一旦状态机将写入操作落地磁盘，即可舍弃对应的 Raft 日志；仅在向其他节点发送一致性磁盘镜像时，才会启用快照机制（详见 5.2 节）。</li><li>日志压缩的增量式实现方案（如日志清理、日志结构合并树）将在 5.3 节介绍。这类方案能高效完成磁盘写入，且可在系统运行期间均衡利用各类资源。</li><li>最后，5.4 节将探讨一种日志压缩方案：通过将快照直接存储在日志中，最大限度简化其实现所需的机制。该方案虽更易落地，但仅适用于规模极小的状态机。</li></ul><p>LogCabin 目前仅实现了基于内存的快照方案（其内置了一个基于内存的状态机）。</p><p>各类日志压缩方案存在若干核心共性。其一，日志压缩的决策并非由领导者集中执行，而是由各节点独立对自身日志的已提交前缀完成压缩。这一设计避免了领导者向本地日志已存有相关数据的跟随者重复传输数据，同时也提升了系统的模块化程度：日志压缩的大部分复杂逻辑均封装在状态机内部，与 Raft 核心逻辑的交互极少。这有助于将系统整体复杂度控制在最低水平——Raft 的复杂度与日志压缩的复杂度为叠加关系，而非乘积关系。将压缩职责集中于领导者的替代方案将在 5.4 节进一步探讨（对于规模极小的状态机，基于领导者的方案或许更优）。</p><p>其二，状态机与 Raft 的基础交互，核心是将日志前缀的管理职责从 Raft 移交至状态机。状态机在应用日志条目后，终将通过特定方式将这些条目对应的状态落地磁盘，以支持当前系统状态的恢复。一旦完成落地，状态机会通知 Raft 舍弃对应的日志前缀。Raft 在移交该日志前缀的管理职责前，必须留存用于描述该前缀的部分自身状态。具体而言，Raft 会记录最后一条舍弃日志条目的索引与任期；该信息能在状态机完成状态落地后，为日志的后续部分提供锚定基准，确保追加日志的一致性检查可正常执行（该检查需要日志首条条目前一记录的索引与任期）。Raft 还会从已舍弃的日志前缀中留存最新的集群配置，以支持集群成员变更操作。</p><p>其三，当 Raft 舍弃某一日志前缀后，状态机将承担两项新的职责。若节点发生重启，状态机需先从磁盘加载与已舍弃日志条目对应的状态，之后才能应用 Raft 日志中的后续条目。此外，状态机还需生成一致性的状态镜像，用以发送至日志大幅落后于领导者的慢跟随者节点。无法将日志压缩推迟至日志条目“全量复制”到集群所有节点后再执行，因为少数慢跟随者不能影响集群的整体可用性，且集群可随时新增节点。因此，慢跟随者或新节点有时需要通过网络获取其初始状态。当领导者发现，追加日志操作所需的下一条目已从自身日志中舍弃时，便会触发该流程。此时，状态机需生成一致性的状态镜像，由领导者发送至该跟随者节点。</p><h2 id="5-1-基于内存状态机的快照实现"><a href="#5-1-基于内存状态机的快照实现" class="headerlink" title="5.1 基于内存状态机的快照实现"></a>5.1 基于内存状态机的快照实现</h2><p>快照机制的首个实现方案，适用于状态机数据结构全程驻留内存的场景。对于数据集规模达千兆或数十千兆字节的状态机而言，这一选择十分合理：该方案能让操作快速完成，因全程无需从磁盘读取数据；同时实现难度更低，可灵活使用复杂的富数据结构，且每个操作均可完整执行（无需为 I&#x2F;O 操作阻塞）。</p><p>图 12 展示了状态机驻留内存时，Raft 中快照机制的核心实现思路。集群中各节点独立执行快照操作，仅对自身日志内的已提交条目进行快照处理。快照的核心工作是序列化状态机的当前状态，这一过程与状态机的具体实现强相关。例如，LogCabin 的状态机以树结构作为核心数据结构，其通过<strong>前序深度优先遍历</strong>完成树的序列化（确保应用快照时，父节点先于子节点创建）。此外，状态机还需序列化其为向客户端提供<strong>线性一致性</strong>所维护的相关信息（详见第 6 章）。</p><p><img src="/9a0e6259ac11/raft-%E5%9B%BE12.png" alt="图 12"></p><blockquote><p>图 12：节点将其日志中已提交的条目（索引 1 至 5）替换为一份新快照，该快照仅存储当前系统状态（本示例中为变量 x 和 y）。在舍弃索引 1 至 5 的条目前，Raft 会保存该快照的最后包含索引（5）与最后包含任期（3），为快照在日志中完成定位，使其处于条目 6 之前的位置。</p></blockquote><p>状态机完成快照写入后，即可对日志执行截断操作。Raft 首先持久化节点重启所需的状态信息：快照中包含的最后一条日志条目的索引与任期、以及该索引对应的最新集群配置。随后，Raft 舍弃截至该索引的全部日志前缀，所有旧快照也可一并删除，因其已无使用价值。</p><p>如前文所述，领导者有时需要向日志大幅落后的慢跟随者、以及新加入集群的节点同步自身状态。在快照机制中，该同步状态即为集群最新快照，领导者通过一种全新的 RPC——<strong>安装快照</strong>完成快照传输，具体见图 5.3。<br>当跟随者通过该 RPC 接收快照后，需决定如何处理本地已有的日志条目：通常情况下，快照会包含跟随者本地日志中未有的新信息，此时跟随者需舍弃全部本地日志 —— 这些日志已被快照完全取代，且其中可能存在与快照冲突的未提交条目；若跟随者接收的快照仅对应其本地日志的某一前缀（因重传或操作失误导致），则仅删除快照所覆盖的日志条目，快照之后的条目仍有效，需予以保留。</p><p><img src="/9a0e6259ac11/5_3.png"></p><blockquote><p>图 5.3：领导者调用安装快照远程过程调用，向日志落后的跟随者发送快照。<br>仅当领导者已舍弃通过追加日志操作向该跟随者复制条目所需的下一条日志条目时，才会选择发送快照。<br>领导者将快照切分为数据块进行传输。此举除带来其他益处外，还能通过每个数据块向跟随者发送存活信号，使其得以重置选举计时器。所有数据块均按序发送，这一设计简化了快照文件的磁盘写入流程。<br>该远程过程调用携带有 Raft 节点重启时加载快照所需的状态信息：快照覆盖的最后一条日志条目对应的索引与任期，以及该时间点的最新集群配置。</p></blockquote><p>本节后续内容将探讨基于内存状态机实现快照的若干次要问题：</p><ul><li>5.1.1 节阐述如何让快照操作与系统正常业务操作并行执行，最大限度降低其对客户端的影响；</li><li>5.1.2 节探讨快照的执行时机选择，平衡存储空间占用与快照操作的性能开销；</li><li>5.1.3 节探讨快照实际实现过程中遇到的各类问题。</li></ul><h3 id="5-1-1-并发快照"><a href="#5-1-1-并发快照" class="headerlink" title="5.1.1 并发快照"></a>5.1.1 并发快照</h3><p>创建快照的过程耗时较长，核心耗时点集中在状态序列化与磁盘写入两个环节。<br>例如，当前服务器中复制 10GB 内存约需 1 秒，而对该数据进行序列化的耗时通常会远长于此；即便是固态硬盘，每秒的写入量也仅约 500MB。因此，快照的序列化与写入操作必须与节点的常规业务操作并发执行，避免系统出现可用性中断。</p><p>所幸写时复制技术可在不影响快照写入的前提下，处理新的状态更新请求。实现这一目标主要有两种方式：</p><ol><li>状态机可基于不可变（函数式）数据结构构建，以此支持并发快照。<br> 由于状态机的指令不会就地修改状态，快照任务可保留对某一历史状态的引用，并将该状态一致性地写入快照文件。</li><li>亦可借助操作系统提供的写时复制支持（前提是编程环境支持该特性）。<br> 以 Linux 系统为例，驻留内存的状态机可通过 fork 系统调用复制服务器的整个地址空间。子进程负责将状态机数据写入磁盘并退出，而父进程可继续处理业务请求。LogCabin 的现有实现采用的正是这种方式。</li></ol><p>节点执行并发快照时需要额外的内存资源，这一点需提前规划并做好管理。状态机必须为快照文件提供流式接口，避免快照数据在生成过程中全量驻留于内存。但即便如此，写时复制仍会产生额外的内存开销，且开销规模与快照过程中状态机被修改的数据占比成正比。此外，依赖操作系统实现写时复制通常会消耗更多内存，这一问题由伪共享导致——例如，若两个不相关的数据项恰好位于同一内存页，即便仅修改其中一项，另一项也会被连带复制。</p><p>若快照过程中出现内存耗尽的极端情况，节点应停止接收新的日志条目，直至快照生成完成；这一操作会暂时降低节点的可用性（但集群整体仍可能保持可用），但至少能让节点完成恢复。此时不应中断快照并延后重试，因为后续的快照尝试大概率仍会遭遇相同的内存问题。（LogCabin 虽为磁盘写入实现了流式接口，但目前尚未能优雅处理内存耗尽的场景。）</p><h3 id="5-1-2-快照触发时机"><a href="#5-1-2-快照触发时机" class="headerlink" title="5.1.2 快照触发时机"></a>5.1.2 快照触发时机</h3><p>节点需合理决策快照的触发时机。若快照触发过于频繁，会造成磁盘带宽及其他资源的浪费；若触发过于稀疏，则可能导致节点存储资源耗尽，同时也会增加节点重启时的日志重放耗时。</p><p>一种简单的策略是：当日志文件的字节大小达到固定阈值时触发快照。若将该阈值设置为显著大于快照的预期大小，快照操作带来的磁盘带宽开销会相对较小。但这种方式对于小型状态机而言，可能会产生不必要的大体积日志文件。</p><p>更优的方式是对比快照文件与日志文件的大小：若快照文件的体积远小于日志文件，此时触发快照通常是值得的。但快照生成前，其文件大小难以精准计算，且计算过程本身开销较高——要么会给状态机带来繁重的元数据管理负担，要么动态计算的耗时几乎与实际生成快照相当。对快照文件进行压缩虽能节省存储空间与传输带宽，但压缩后的文件大小同样难以预测。</p><p>所幸的是，以<strong>上一次快照</strong>的大小而非<strong>下一次快照</strong>的预估大小为参考，能让快照触发的决策效果趋于合理。具体策略为：当日志文件大小超过上一次快照大小与可配置扩展系数的乘积时，触发新的快照。该扩展系数的取值本质是在磁盘带宽开销与存储利用率之间做权衡。例如，将扩展系数设为 4 时，节点约 20% 的磁盘带宽会用于快照操作（每生成 1 字节的快照数据，对应会写入 4 字节的日志条目），且此时节点所需的磁盘容量约为存储单份状态数据的 6 倍（包含旧快照、4 倍于旧快照的日志文件，以及正在写入的新快照）。</p><p>快照操作仍会造成 CPU 与磁盘带宽的突发占用，可能影响客户端的请求处理性能。这一问题可通过硬件扩容缓解，例如新增一块磁盘以提供额外的磁盘带宽。</p><p>此外，也可通过合理的调度策略，让客户端请求无需等待正执行快照的节点。具体而言，集群内的节点可相互协调，确保任意时刻仅有少数节点执行快照（在条件允许的情况下）。由于 Raft 协议仅要求集群中多数节点完成日志条目提交即可，因此少数节点执行快照通常不会对客户端的业务请求造成负面影响。若领导者需要执行快照，可先主动退位，让其他节点临时接管集群的管理工作。若该调度策略的可靠性足够高，甚至可无需实现并发快照——节点执行快照期间可暂时下线（但该节点仍会被计入集群的故障屏蔽能力评估）。</p><p>这一策略是未来的重要优化方向，因其有望在提升系统整体性能的同时，简化快照的实现机制。</p><h3 id="5-1-3-实现注意事项"><a href="#5-1-3-实现注意事项" class="headerlink" title="5.1.3 实现注意事项"></a>5.1.3 实现注意事项</h3><p>本节梳理快照功能实现所需的核心组件，并探讨各组件的落地难点：</p><ol><li><p>快照的保存与加载：保存快照即把状态机的状态序列化后写入文件，加载则是其逆过程。我们发现这一过程实现起来相对简单，仅需将各类数据对象从其原生表示形式序列化为指定格式，只是该序列化操作略显繁琐。为避免状态机的全量数据在内存中缓冲，为状态机设计面向磁盘文件的流式接口十分必要；同时，对序列化的数据流进行压缩并添加校验和，也能带来实际收益。LogCabin 会先将每个快照写入临时文件，待写入完成并刷盘后，再对文件进行重命名；这一机制能确保服务器启动时，不会加载未写入完成的快照。</p></li><li><p>快照的传输：实现快照传输，需要完成 <code>InstallSnapshot</code> 远程过程调用（RPC）中领导者与跟随者两端的逻辑开发。这部分实现同样相对简单，且可复用一部分快照本地保存与加载的代码。快照传输的性能通常无需重点优化——需要接收快照的跟随者，本就未参与日志条目的提交流程，因此其同步进度的紧迫性较低；当然，若集群发生更多节点故障，快速完成该跟随者的快照同步，对恢复集群可用性会有重要意义。</p></li><li><p>消除不安全的日志访问与日志条目丢弃：LogCabin 的初始设计未考虑日志压缩场景，因此代码中存在一个默认假设：若日志中存在条目 <code>i</code>，那么条目 <code>1</code> 至 <code>i-1</code> 也必然存在。但开启日志压缩后，该假设不再成立；例如，在 <code>AppendEntries</code> RPC 中查询前一条日志条目的任期时，该条目可能已被丢弃。要在代码中彻底移除这一假设，需要严谨的逻辑梳理与充分的测试验证。若能借助功能更强大的类型系统，让编译器强制约束所有日志访问操作都处理索引越界的情况，这一工作的难度会大幅降低。当所有日志访问操作都被改造为安全实现后，丢弃日志的前缀部分就变得十分简单。在此之前，我们只能对快照的保存、加载和传输功能做独立测试；而实现安全的日志丢弃后，这些功能便能在全系统测试中得到完整的场景验证。</p></li><li><p>基于写时复制的并发快照：实现并发快照，要么需要重构状态机的设计，要么需要借助操作系统的 <code>fork</code> 操作。LogCabin 目前采用 <code>fork</code> 实现该特性，而 <code>fork</code> 与线程、C++ 析构函数的兼容性较差，要实现该逻辑的正确运行曾面临不少难点。但该方案的代码量极少，且完全无需修改状态机的数据结构，因此我们认为这是最优实现方案。</p></li><li><p>快照触发时机的决策：我们建议在开发阶段，设置为每应用一条日志条目后即触发一次快照，这一方式能帮助开发人员快速发现程序漏洞。待快照功能完整实现后，再接入更贴合实际业务的触发策略即可（例如，基于 Raft 日志的大小、上一次快照的大小等统计信息动态决策）。</p></li></ol><p>我们发现，快照功能的分步开发与测试具有一定挑战性。上述大部分组件必须全部实现后，才能落地日志条目的丢弃逻辑；而唯有完成日志丢弃的开发，这些新编写的代码路径，才能在全系统测试中得到充分的场景覆盖。因此，开发人员需要谨慎规划各组件的实现与测试顺序。</p><h2 id="5-2-磁盘型状态机的快照处理"><a href="#5-2-磁盘型状态机的快照处理" class="headerlink" title="5.2 磁盘型状态机的快照处理"></a>5.2 磁盘型状态机的快照处理</h2><p>本节探讨面向大型磁盘型状态机（数据量达数十乃至数百吉字节）的快照处理方案，这类状态机以磁盘作为主要的持久化存储介质。其工作特性存在特殊性：为应对故障恢复，磁盘中始终留存有一份可用的状态副本。每执行一条 Raft 日志条目，都会修改磁盘上的状态，最终实际生成一个新的快照。因此，日志条目一经执行，即可从 Raft 日志中删除。（状态机也可将写操作缓存在内存中，以提升磁盘写入效率；待这些写操作落盘后，对应的日志条目即可从 Raft 日志中删除。）</p><p>磁盘型状态机的核心问题，在于直接修改磁盘状态会造成性能损耗。若未启用写缓冲，每执行一条命令都需要进行一次或多次磁盘随机写操作，这会限制系统的整体写入吞吐量（而写缓冲对此的优化效果可能十分有限）。5.3 节将探讨日志压缩的增量处理方案，该方案通过大粒度的顺序写操作实现更高效的磁盘写入。</p><p>为向同步速度较慢的从节点传输快照，磁盘型状态机必须能够生成一份一致性的磁盘快照。尽管其磁盘中始终存在快照，但该快照会被持续修改。因此，这类状态机仍需借助写时复制技术，将一份一致性快照保留足够长的时间，以完成传输过程。所幸的是，磁盘格式几乎均按逻辑块划分，因此在状态机中实现写时复制的逻辑会较为简便。</p><p>磁盘型状态机也可依托操作系统的原生支持实现快照功能。例如，Linux 系统中的逻辑卷管理（LVM）可用于创建整个磁盘分区的快照，而部分新一代文件系统也支持对单个目录创建快照。</p><p>复制磁盘镜像快照的过程可能耗时良久，且随着磁盘修改操作的不断累积，保留该快照所需的额外磁盘空间也会随之增加。尽管我们尚未实现磁盘型快照的相关功能，但推测磁盘型状态机可通过下述算法传输磁盘内容，从而规避上述大部分开销：</p><ol><li>为每个磁盘逻辑块记录其最后一次的修改时间。</li><li>主节点在维持正常业务运行的同时，将全部磁盘内容按逻辑块逐一传输至目标从节点；此过程中，主节点不会占用额外的磁盘空间。由于传输过程中磁盘块会被并发修改，从节点接收到的磁盘镜像大概率是不一致的。主节点在传输每个磁盘块时，需记录其当前的最后修改时间。</li><li>对磁盘内容创建写时复制快照。快照创建完成后，主节点将持有一份一致性的磁盘内容副本；但后续客户端的持续操作会引发磁盘修改，这将导致主节点产生额外的磁盘空间占用。</li><li>仅重传那些在步骤 2 首次传输后、步骤 3 快照创建前发生修改的磁盘逻辑块。</li></ol><p>理想情况下，在步骤 3 完成一致性快照创建时，该快照的大部分磁盘块已完成传输。若能达成此状态，步骤 4 的传输过程将高效完成：主节点在步骤 4 中为保留快照所占用的额外磁盘空间会极少，而步骤 4 中为重传修改块所消耗的额外网络带宽也会极低。</p><h2 id="5-3-增量清理方案"><a href="#5-3-增量清理方案" class="headerlink" title="5.3 增量清理方案"></a>5.3 增量清理方案</h2><p>日志压缩的增量实现方案（如日志清理与日志结构合并树，即 LSM 树）同样具备可行性。这类方案虽比快照机制更为复杂，但拥有多项优势特性：</p><ul><li>每次仅对部分数据执行操作，可将日志压缩的负载均匀分摊至系统全运行周期。</li><li>无论常规运行还是日志压缩阶段，均能实现高效磁盘写入，且两种场景下均采用大粒度顺序写方式。增量方案还会针对性地对磁盘中可回收空间最大的区域执行压缩，因此相较于基于内存的状态机所采用的快照机制（每次创建快照都会重写全部磁盘数据），增量方案向磁盘写入的数据量更少。</li><li>因不会对磁盘区域执行原地修改，故而能较为便捷地传输一致性的状态快照。</li></ul><p>5.3.1 节与 5.3.2 节将首先阐述日志清理与 LSM 树的通用基础原理，5.3.3 节则进一步探讨其在 Raft 算法中的具体应用方式。</p><h3 id="5-3-1-日志清理的基础"><a href="#5-3-1-日志清理的基础" class="headerlink" title="5.3.1 日志清理的基础"></a>5.3.1 日志清理的基础</h3><p>日志清理最初应用于日志结构文件系统领域，近期也被提出用于 RAMCloud 这类内存存储系统。从理论上讲，日志清理可适配任意类型的数据结构，只是部分结构的高效实现难度更高。</p><p>日志清理将日志作为系统状态的持久化存储载体，其存储布局针对顺序写做了优化，但这也导致读操作实际为随机访问，因此需要通过索引结构定位待读取的数据项。</p><p>在日志清理机制中，日志会被划分为若干连续的区域，称为<strong>段</strong>。日志清理器的每次清理过程，均通过三步算法完成日志压缩：</p><ol><li>首先筛选出累计失效条目占比高的段，作为本次清理的对象；</li><li>随后将这些段中的<strong>有效条目</strong>（即对当前系统状态有实际贡献的条目）复制至日志头部；</li><li>最后释放这些被清理段的存储空间，将其预留为新段的可用空间。</li></ol><p>为最大限度降低对系统常规运行的影响，该清理过程可与业务操作并行执行。</p><p>由于有效条目被向前复制至日志头部，日志重放时的条目顺序会被打乱。因此可在日志条目中嵌入额外信息（如版本号），确保日志执行时能恢复正确的条目顺序。</p><p>清理段的选择策略对系统性能影响显著，已有研究提出了一种<strong>成本收益策略</strong>，该策略不仅会考量有效条目占用的存储空间，还会评估这些条目预计的有效存续时长。</p><p>判定日志条目是否为有效条目是状态机的核心职责。例如在键值存储系统中，若某个键存在且当前值与日志条目中的设定值一致，那么将该键设为指定值的日志条目即为有效条目。而判定删除某个键的日志条目是否有效则更为复杂：只要日志中仍保留该键此前的赋值条目，该删除条目就始终为有效条目。RAMCloud 会根据实际需要保留删除指令（这类指令被称为<strong>墓碑记录</strong>），另一种实现方案则是定期导出当前系统状态中所有存在的键的汇总信息，此后所有与未列入该汇总的键相关的日志条目，均判定为失效条目。键值存储是一类相对简单的应用场景，日志清理也可适用于其他类型的状态机，但遗憾的是，不同状态机的条目有效性判定逻辑均存在差异。</p><h3 id="5-3-2-日志结构合并树的基础"><a href="#5-3-2-日志结构合并树的基础" class="headerlink" title="5.3.2 日志结构合并树的基础"></a>5.3.2 日志结构合并树的基础</h3><p>日志结构合并树（LSM 树）由奥尼尔首次提出，后经 BigTable 系统的应用，在分布式领域得到广泛普及。目前该结构已被 Apache Cassandra、HyperDex 等系统采用，也有 LevelDB 及其衍生版本（如 RocksDB、HyperLevelDB）这类开源库实现了该机制。</p><p>LSM 树是一种存储有序键值对的类树型数据结构。从整体设计来看，其磁盘使用方式与日志清理方案相近：均采用大粒度顺序写，且不会对磁盘上的数据执行原地修改。二者的核心区别在于，LSM 树不会将所有系统状态都保存在日志中，而是会对状态进行重新组织，以优化随机访问的性能。</p><p>典型的 LSM 树会将近期写入的键值对暂存于磁盘上的小型日志中。当该日志达到固定容量阈值时，系统会将其中的内容按键排序，并以有序形式写入一个名为 <strong>有序段（run）</strong> 的文件。有序段一旦生成便不会被原地修改，而系统会通过定期的压缩过程，将多个有序段合并为新的有序段，并丢弃原有的旧段。该合并过程与归并排序的原理相似：若同一键出现在多个待合并的有序段中，仅保留其最新版本，因此合并后生成的有序段数据会更紧凑。LevelDB 采用的压缩策略如图 5.1 所示，该策略按生成时间对有序段进行分层管理以提升处理效率，这一点与日志清理机制的设计思路相近。</p><p><img src="/9a0e6259ac11/5_4.png"></p><p>在系统常规运行过程中，状态机可直接对 LSM 树中的数据进行操作。读取某个键时，会先检查小型日志中是否有该键的近期修改记录，再依次检索各个有序段。为避免每次键查找都遍历所有有序段，部分系统会为每个有序段创建<strong>布隆过滤器</strong>—— 这是一种紧凑的数据结构，可在部分场景下精准判定某个键不存在于某一有序段中；当然该结构也存在局限性，有时即便键实际不存在，仍需对有序段进行一次检索验证。</p><h3 id="5-3-3-Raft-中的日志清理与日志结构合并树"><a href="#5-3-3-Raft-中的日志清理与日志结构合并树" class="headerlink" title="5.3.3 Raft 中的日志清理与日志结构合并树"></a>5.3.3 Raft 中的日志清理与日志结构合并树</h3><p>我们尚未尝试在 Raft 中实现日志清理或日志结构合并树机制，但推测二者均可在此场景下良好运行。将日志结构合并树应用于 Raft 的实现方式相对直观：由于 Raft 日志已将近期条目持久化存储在磁盘中，日志结构合并树可在内存中以更易操作的树型结构存储近期数据，这能提升查询请求的处理效率；当 Raft 日志达到固定容量阈值时，该树型结构已完成排序，可直接作为新的有序段写入磁盘。</p><p>将主节点的状态传输至同步速度较慢的从节点时，只需将所有有序段发送至从节点（而非内存中的树型结构）；所幸有序段具备不可变性，无需担心其在传输过程中被修改。</p><p>而将日志清理应用于 Raft 则并非如此直观。我们最初考虑的方案是将 Raft 日志直接划分为若干段并执行清理操作（见图 5.4 (a)）。但该方案存在明显弊端：清理操作会在日志中被释放段的位置形成大量空闲空洞，这就需要对日志复制机制做相应改造。我们认为该方案可通过改造实现运行，但会为 Raft 本身及其与状态机的交互过程带来极大的复杂度。此外，由于仅有主节点可向 Raft 日志追加条目，日志清理需基于主节点执行，这会造成主节点网络带宽的浪费（相关内容将在 5.4 节进一步探讨）。</p><p>一种更优的方案是采用与日志结构合并树相近的方式处理日志清理：Raft 为近期的状态变更维护一份连续的日志，状态机则将自身状态以日志形式独立存储，二者的日志在逻辑上相互独立（见图 5.4 (b)）。当 Raft 日志达到固定容量阈值时，其新条目会作为新的段写入状态机的日志，而 Raft 日志中对应的前缀部分则会被删除。状态机中的段由集群各节点独立执行清理操作，Raft 日志则完全不受此过程的影响。</p><p>相较于直接清理 Raft 日志，我们更倾向于该方案，原因有二：一是日志清理的复杂度被完全封装在状态机内部，状态机与 Raft 之间的接口仍保持简洁；二是集群各节点可独立执行清理操作，无需依赖主节点。</p><p>如前所述，该方案要求状态机将 Raft 的所有日志条目写入自身日志（不过可通过大批次的方式执行该操作）。这一额外的复制操作可通过优化省去：直接迁移 Raft 日志中由日志条目组成的文件，并将该文件整合至状态机的数据结构中。该优化手段对性能要求严苛的系统而言十分实用，但遗憾的是，这会使状态机与 Raft 模块的耦合程度大幅提高 —— 因为状态机需要理解 Raft 日志的磁盘存储格式。</p><h2 id="5-4-替代方案：基于主节点的实现方式"><a href="#5-4-替代方案：基于主节点的实现方式" class="headerlink" title="5.4 替代方案：基于主节点的实现方式"></a>5.4 替代方案：基于主节点的实现方式</h2><p>本章提出的日志压缩方案偏离了 Raft 的<strong>强主节点原则</strong>，原因是集群各节点可在主节点不知情的情况下自行执行日志压缩操作。但我们认为这一设计偏差具备合理性：主节点的核心作用是避免共识达成过程中出现决策冲突，而快照处理与日志压缩均发生在共识达成之后，因此不会产生任何决策冲突。数据的流转方向仍保持为主节点至从节点，唯一的变化是从节点如今可独立对自身数据进行重组。</p><p>我们也曾探讨过基于主节点的日志压缩方案，但这类方案的些许优势，通常会被性能层面的问题完全抵消。若让主节点先完成自身日志的压缩，再将压缩结果传输至各从节点，而非让从节点独立执行压缩操作，这一做法本身就存在资源浪费。向每个从节点传输冗余的状态数据，不仅会耗费大量网络带宽，还会拖慢整体的日志压缩进程。各从节点本身已具备执行本地状态压缩所需的全部信息，而主节点的<strong>下行网络带宽</strong>向来是 Raft 集群中最稀缺的资源，也是核心的性能瓶颈。</p><p>对于基于内存的快照机制而言，节点从本地状态生成快照的开销，通常远低于通过网络发送和接收快照的开销。而对于增量压缩方案，其开销对比结果会稍受硬件配置的影响，但我们依然认为，让各节点独立执行压缩的方式综合成本更低。</p><h3 id="5-4-1-将快照存储于日志中"><a href="#5-4-1-将快照存储于日志中" class="headerlink" title="5.4.1 将快照存储于日志中"></a>5.4.1 将快照存储于日志中</h3><p>基于主节点的实现方案存在一项潜在优势：若能将所有系统状态均存储于日志中，就无需为状态的复制与持久化设计新机制。为此，我们设计了一种基于主节点的快照实现方案，具体逻辑如图 5.5 所示 —— 由主节点创建快照，并将快照封装为日志条目存储至 Raft 日志中，再通过 AppendEntries 远程过程调用（RPC）将该快照发送至所有从节点。为尽可能降低对系统常规运行的干扰，可将单个快照拆分为多个日志条目，在日志中与常规客户端命令交错写入。</p><p><img src="/9a0e6259ac11/5_5.png"></p><blockquote><p>图 5.5 基于主节点的快照存储方案：将快照分块存入日志并与客户端请求交错排布<br>该方案将快照分块存储于 Raft 日志中，且快照分块条目与客户端请求条目交错写入。快照创建过程从<strong>开始条目</strong>启动，至<strong>结束条目</strong>完成，快照数据则存储在开始条目与结束条目之间的若干日志条目中。为使客户端请求能与快照创建过程并行执行，方案会对单个快照分块条目的大小做限制，同时限制日志的条目追加速率：主节点仅在确认前一个快照分块条目已提交后，才会将下一个快照分块条目追加至日志。<br>当集群各节点确认结束条目已提交后，即可删除自身日志中<strong>截至对应开始条目前</strong>的所有日志条目。该方案下的日志重放需采用<strong>双遍执行算法</strong>：先执行日志中最新的完整快照，再执行该快照开始条目之后的所有客户端请求条目。</p></blockquote><p>相较于将快照存储在日志外部的方案，该方式能实现更优的<strong>机制简洁性</strong>：节点无需为快照的传输和持久化设计独立机制，快照的复制与持久化流程可与普通日志条目完全一致。但除了会向原本可独立生成快照的从节点传输数据、造成网络带宽浪费外，该方案还存在一个严重缺陷：若主节点在创建快照的过程中发生故障，会在各节点的日志中遗留<strong>部分快照</strong>数据。理论上，这种故障情况可能反复发生，由多次快照尝试失败产生的垃圾数据会持续累积，最终耗尽节点的存储容量。因此，我们认为该机制不具备实际落地的可行性。</p><h3 id="5-4-2-面向超小型状态机的基于主节点方案"><a href="#5-4-2-面向超小型状态机的基于主节点方案" class="headerlink" title="5.4.2 面向超小型状态机的基于主节点方案"></a>5.4.2 面向超小型状态机的基于主节点方案</h3><p>对于超小型状态机而言，将快照存储于日志中不仅具备实际可行性，还能大幅简化实现流程。若快照体积足够小（约 1 兆字节以内），便可完整存入单个日志条目，且不会对系统常规运行造成过长时间的中断。主节点若采用该方式完成集群节点的日志压缩，需执行以下步骤：</p><ol><li>停止接收新的客户端请求；</li><li>等待自身日志中的所有条目完成提交，且自身状态机执行完所有日志条目；</li><li>同步创建快照；</li><li>将该快照作为单个日志条目追加至自身日志末尾；</li><li>恢复接收新的客户端请求。</li></ol><p>当各节点确认该快照条目已完成提交后，即可删除自身日志中该快照条目之前的所有条目。在停止接收客户端请求并传输该快照条目的过程中，该方案会造成短暂的服务可用性中断，但对于超小型状态机而言，其影响程度有限。</p><p>这一简化方案省去了多项实现工作：无需将快照持久化至日志外部，无需通过新的远程过程调用（RPC）传输快照，也无需实现快照的并发创建机制。但实际场景中，成功的系统其使用规模往往会超出设计者最初的预期，因此该方案无法适配规模更大的状态机。</p><h2 id="5-5-结论"><a href="#5-5-结论" class="headerlink" title="5.5 结论"></a>5.5 结论</h2><p>本章探讨了 Raft 算法中多种日志压缩方案，相关方案汇总如图 5.1 所示。<br>不同方案适用于不同的系统，具体选型取决于状态机的规模、系统对性能的要求以及可投入的实现复杂度。Raft 支持各类日志压缩方案的实现，且这些方案均遵循一套统一的概念框架，核心共性如下：</p><ul><li>集群各节点独立对自身日志的<strong>已提交前缀部分</strong>执行压缩操作；</li><li>状态机与 Raft 的基础交互，核心是将日志前缀的管理职责从 Raft 移交至状态机。当状态机将日志中的命令落地至磁盘后，会通知 Raft 删除对应的日志前缀；Raft 则会留存最后一条被删除日志条目的索引与任期，以及该索引对应的最新集群配置；</li><li>当 Raft 完成日志前缀的删除后，状态机将承担两项新职责：一是在节点重启时加载系统状态，二是生成一致性的状态镜像并传输至同步速度较慢的从节点。</li></ul><p>面向基于内存的状态机的快照机制，已在 Chubby、ZooKeeper 等多款生产级系统中得到成功落地，我们也在 LogCabin 系统中实现了该方案。</p><p>尽管对内存数据结构执行各类操作的速度均较为可观，但快照创建过程中，系统性能可能受到显著影响。并发创建快照有助于掩盖资源占用带来的性能损耗；未来若对集群内所有节点做快照时间调度，让各节点错峰执行快照操作，或可实现快照处理完全不影响客户端业务。</p><p>采用原地修改状态的磁盘型状态机，在设计理念上更为简洁。为向其他节点传输一致性的磁盘镜像，这类状态机仍需借助写时复制技术，但磁盘本身天然按块划分，因此该技术的实现开销相对较低。但常规运行过程中的磁盘随机写操作速度通常较慢，因此该方案会限制系统的写入吞吐量。</p><p>从整体来看，增量方案是效率最优的日志压缩方式。这类方案每次仅对少量状态数据执行操作，可有效抑制资源占用的突发波动（且同样支持并发压缩）；同时还能避免同一数据被反复写入磁盘，稳定的数据最终会被存储至磁盘中极少被压缩的区域。尽管增量压缩的实现存在一定复杂度，但可将该部分复杂度剥离至 LevelDB 这类第三方库中实现。此外，通过将数据结构驻留内存，并将更多磁盘数据缓存至内存中，采用增量压缩方案的系统，其客户端操作性能可接近基于内存的状态机的水平。</p><h1 id="6-客户端交互"><a href="#6-客户端交互" class="headerlink" title="6 客户端交互"></a>6 客户端交互</h1><p>本章阐述客户端与基于 Raft 的复制状态机交互过程中的若干关键问题：</p><ul><li>6.1 节说明客户端如何发现集群（即便集群的节点组成会随时间动态变化）；</li><li>6.2 节说明客户端的请求如何路由至集群主节点进行处理；</li><li>6.3 节说明 Raft 如何实现线性一致性；</li><li>6.4 节说明 Raft 如何更高效地处理只读查询。</li></ul><p>图 6.1 展示了客户端与复制状态机交互所使用的远程过程调用（RPC），本章将对这些 RPC 的核心要素展开逐一探讨。上述问题适用于所有基于共识的分布式系统，Raft 所采用的解决方案与其他同类系统相近。</p><p><img src="/9a0e6259ac11/6_1.png"></p><p>本章默认基于 Raft 的复制状态机以<strong>网络服务</strong>的形式直接向客户端提供访问。当然，Raft 也可直接集成至客户端应用程序中。在此种部署方式下，部分客户端交互相关问题会向上转移至该嵌入式应用的<strong>网络客户端层</strong>。例如，该嵌入式应用的网络客户端在发现应用集群时，会遇到与 Raft 网络服务的客户端发现 Raft 集群完全相同的问题。</p><h2 id="6-1-集群发现"><a href="#6-1-集群发现" class="headerlink" title="6.1 集群发现"></a>6.1 集群发现</h2><p>当 Raft 以网络服务形式对外提供能力时，客户端必须先定位到集群，才能与复制状态机进行交互。对于节点组成固定的集群，这一操作十分简便，比如可将集群节点的网络地址静态配置在配置文件中。但当集群的节点组成会随时间动态变化时（如第 4 章所述），集群发现就成为了更大的挑战。现有两种通用实现方案：</p><ol><li>客户端通过<strong>网络广播或组播</strong>机制发现集群内所有节点，该方案仅适用于支持这两种网络特性的特定部署环境。</li><li>客户端通过部署在<strong>公知访问地址的外部目录服务</strong>（<strong>如域名系统 DNS</strong>）发现集群节点。该外部系统中的节点列表无需保证强一致性，但需满足完备性要求：客户端必须能通过该列表找到集群的所有节点，即便列表中包含少量当前非集群成员的节点，也不会产生任何影响。因此在执行集群节点变更操作时，需先更新该外部节点目录，将待加入集群的节点纳入其中；待节点变更操作完成后，再对该目录进行二次更新，移除已退出集群的节点。</li></ol><p>LogCabin 的客户端目前采用 DNS 实现集群发现，该系统暂未实现节点成员变更前后 DNS 记录的自动更新功能（此操作现阶段由管理脚本完成）。</p><h2 id="6-2-将请求路由至主节点"><a href="#6-2-将请求路由至主节点" class="headerlink" title="6.2 将请求路由至主节点"></a>6.2 将请求路由至主节点</h2><p>Raft 中的客户端请求是通过领导者处理的，因此客户端需要一种主节点发现机制。客户端首次启动时，会随机连接集群中的一个节点；若所选节点并非主节点，该节点会直接拒绝此次请求。此时最直接的处理方式，是让客户端继续随机选择其他节点重试，直至找到主节点。若客户端采用<strong>无放回随机选择</strong>的策略，在包含 n 个节点的集群中，这种简单方案平均需要 $\frac{n+1}{2}$ 次尝试即可定位到主节点，该效率对小型集群而言已能满足需求。</p><p>通过简单的优化手段，可进一步提升请求路由至主节点的效率。集群节点通常能获取当前主节点的网络地址 —— 因 AppendEntries 请求的报文会携带主节点的身份信息。当非主节点接收到客户端请求时，可选择以下两种处理方式之一：</p><ol><li>我们推荐的方案（LogCabin 亦采用此方案）：该节点拒绝请求，若已获知主节点地址，则将其返回给客户端。客户端可基于该地址直接重新连接主节点，后续请求便能以最优效率执行。该方案的实现仅需编写少量额外代码，因为客户端原本就需在主节点故障时，重新连接集群中的其他节点。</li><li>备选方案：该节点将客户端的请求<strong>代理</strong>至主节点。该方案在部分场景下实现更简便，例如，若客户端可连接任意节点执行读请求（见 6.4 节），那么由节点代理客户端的写请求，可避免客户端为仅有的写操作，单独维护一条至主节点的专属连接。</li></ol><p>Raft 还必须防止<strong>过期的主节点信息</strong>造成客户端请求的无限期阻塞。系统中的主节点信息可能在主节点、从节点及客户端侧全部失效，具体情况如下：</p><ul><li><strong>主节点侧</strong>：某一节点可能仍处于主节点状态，但若其并非集群当前的有效主节点，就可能无意义地阻塞客户端请求。例如，某主节点与集群其他节点发生<strong>网络分区</strong>，但仍能与特定客户端保持通信；若无额外机制，该节点因无法将日志条目复制至其他任何节点，会永久阻塞该客户端的请求。而此时集群中，可能已存在一个更高任期的新主节点，该节点能与集群多数节点通信，且可完成客户端请求的提交。因此 Raft 规定：若主节点在<strong>选举超时</strong>时间内，未能向集群多数节点完成一轮成功的心跳交互，便会主动<strong>退位</strong>；此举可让客户端重新选择其他节点进行请求重试。</li><li><strong>从节点侧</strong>：从节点会记录主节点的身份信息，以便为客户端执行请求重定向或代理操作。当从节点发起新的选举，或集群的任期发生变更时，必须立即丢弃该过期的主节点信息；否则可能造成客户端请求的无意义阻塞（例如，两个节点可能互相向对方重定向客户端请求，导致客户端陷入<strong>无限循环</strong>）。</li><li><strong>客户端侧</strong>：若客户端与主节点（或任意特定节点）的连接中断，只需随机选择集群中的其他节点重试即可。若执意尝试连接最后一次记录的主节点，一旦该节点发生故障，会造成不必要的请求延迟。</li></ul><h2 id="6-3-实现线性化语义"><a href="#6-3-实现线性化语义" class="headerlink" title="6.3 实现线性化语义"></a>6.3 实现线性化语义</h2><p>截至目前的实现中，Raft 为客户端提供<strong>至少一次语义</strong>：复制状态机可能会多次执行同一命令。例如，客户端向主节点提交某条命令，主节点将该命令追加至自身日志并完成条目提交，却在向客户端返回响应前发生故障。由于客户端未收到任何确认信息，会将该命令重新提交给新的主节点；而新主节点又会将此命令作为新条目追加至日志并完成提交。如此一来，即便客户端仅希望命令执行一次，实际却会被执行两次。即便无客户端主动重提交，若网络层出现客户端请求的重复转发，命令同样可能被多次执行。</p><p>该问题并非 Raft 所独有，绝大多数<strong>有状态分布式系统</strong>都会遇到。但至少一次语义对共识类系统而言尤为不适，因为这类系统的客户端通常需要更强的一致性保证。命令重复执行引发的问题往往表现得较为隐蔽，客户端难以自行恢复，最终会导致计算结果错误、系统状态异常，或二者同时发生。图 6.2 展示了结果错误的典型场景：某状态机提供分布式锁服务，客户端发起加锁请求后未收到确认，再次请求时却无法获取锁，原因是其第一次的加锁请求实际已执行成功。状态异常的典型场景则是自增操作：客户端期望某值自增 1，实际却自增了 2 次及以上。而网络层面的请求重排与客户端并发操作，还可能引发更为意外的结果。</p><p><img src="/9a0e6259ac11/6_2.png"></p><blockquote><p>图 6.2 命令重复执行引发错误结果的示例<br>客户端向复制状态机提交一条获取锁的命令，其首次发起的命令已成功获取锁，但客户端始终未收到确认响应。当客户端重试该请求时，会发现锁已被占用。</p></blockquote><p>Raft 的设计目标之一，便是实现<strong>线性化语义</strong>，从根源上规避此类问题。在线性化语义下，每个操作都会在<strong>调用发起</strong>与<strong>响应返回</strong>之间的某个时间点<strong>瞬时执行且仅执行一次</strong>。这是一种强一致性模型，客户端极易理解，且该模型明确禁止命令被多次处理。</p><p>要在 Raft 中实现线性化语义，服务器需对重复请求做<strong>过滤处理</strong>。核心思路是：服务器持久化保存客户端操作的执行结果，利用该结果跳过同一请求的多次执行。具体实现方式为：为每个客户端分配一个<strong>唯一标识</strong>，客户端为自身发起的每一条命令分配<strong>唯一序列号</strong>；服务器的状态机为每个客户端维护一个<strong>会话</strong>，该会话会跟踪针对该客户端已处理的最新序列号，以及对应的执行结果。当服务器收到某条命令时，若检测到其序列号已被处理过，会直接向客户端返回结果，而不会重新执行该命令。</p><p>基于上述重复请求过滤机制，Raft 即可实现线性化语义：Raft 日志为所有服务器定义了命令的串行执行顺序，每条命令会在其<strong>首次出现在 Raft 日志中</strong>的时刻，瞬时且仅执行一次；而该命令后续在日志中出现的所有重复条目，都会被状态机按上述规则过滤掉。</p><p>该方案还可自然扩展，以支持单客户端的<strong>并发请求</strong>处理：只需对客户端会话的存储结构做调整，不再仅跟踪最新的序列号与对应结果，而是维护一个<strong>序列号 - 执行结果</strong>的键值对集合。客户端每次发起请求时，需在请求中携带<strong>自身尚未收到执行结果的最小序列号</strong>；服务器状态机收到该请求后，会丢弃所有比该序列号更小的执行结果记录。</p><p>但受限于存储资源，会话无法被永久保存，服务器最终必须对长期无活动的客户端会话执行<strong>过期清理</strong>。这一操作会带来两个新问题：服务器如何就客户端会话的过期时间达成共识？以及如何处理会话被过早过期、但实际仍在活跃的客户端？</p><p>首先，服务器必须就会话的过期时间达成共识，否则各节点的状态机会出现数据不一致。例如，某一服务器对某客户端的会话执行了过期清理，后续便会重新执行该客户端的重复命令；而集群中其他服务器仍保留该会话，会过滤掉这些重复命令 —— 最终导致复制状态机的全局不一致。因此，会话的过期清理逻辑必须是<strong>确定性</strong>的，这一点与状态机的常规操作要求完全一致。目前有两种可行的实现方案：一是为服务器维护的会话数量设置上限，采用<strong>最近最少使用</strong>（LRU）策略淘汰过期会话；二是基于集群协商一致的时间源，触发会话的过期清理。LogCabin 采用的是第二种方案：主节点为每一条追加至 Raft 日志的命令附加自身的当前时间戳，服务器在提交该日志条目时，会就该时间戳达成共识；随后状态机便基于该确定性的时间戳，对非活跃的客户端会话执行过期清理。而活跃的客户端会在空闲期主动发送<strong>保活请求</strong>。</p><h2 id="6-4-更高效地处理只读查询"><a href="#6-4-更高效地处理只读查询" class="headerlink" title="6.4 更高效地处理只读查询"></a>6.4 更高效地处理只读查询</h2><p>客户端的只读命令仅对复制状态机进行查询，不会对其做出修改。因此自然会产生一个问题：这类查询是否可以绕开 Raft 日志？毕竟 Raft 日志的设计初衷，是按统一顺序将状态变更复制到集群各节点的状态机中。绕开日志能带来可观的性能收益 —— 只读查询在诸多应用中均为高频操作，而向日志追加条目所需的同步磁盘写入，本身是耗时操作。</p><p>但若无额外的防护措施，绕开日志会导致只读查询返回<strong>过期结果</strong>。例如，某任领导者若与集群其他节点发生网络分区，集群剩余节点可能会选举出新的领导者，并向 Raft 日志提交新的条目。如果这个被分区的领导者在未与其他节点交互的情况下响应只读查询，返回的结果就是过期的，且不满足<strong>线性一致性</strong>。线性一致性要求，读操作的结果必须反映出<strong>该读操作发起后</strong>某个时刻的系统状态；每一次读操作，至少要返回最新已提交写操作的执行结果。（允许返回过期读结果的系统，仅能保证<strong>串行化</strong>特性，这是一种更弱的一致性级别。）已有第三方 Raft 实现因过期读问题出现故障，因此该问题需要重点关注。</p><p>所幸，我们可以在绕开 Raft 日志处理只读查询的同时，依然保证线性一致性。要实现这一目标，领导者需执行以下步骤：</p><ol><li>若领导者尚未将其当前任期内的任一条目标记为已提交，则等待该操作完成。<strong>领导者完备性原则</strong>保证了领导者拥有所有已提交条目，但是在任期开始之初，可能无法确定具体是哪些条目。为明确这一点，领导者需要提交一个自身任期内的条目。Raft 的处理方式是，让每位领导者在任期开始时，向日志中提交一条<strong>空操作（no-op）条目</strong>。该空操作条目一经提交，领导者的 <strong>commitIndex</strong> 在其任期内，就将始终不低于集群中其他所有节点的 commitIndex。</li><li>领导者将当前的 commitIndex 保存至本地变量 <strong>readIndex</strong>（读取索引），该值将作为查询操作所基于的状态版本的下界。</li><li>领导者需要确保自身未被未知的新任领导者取代。其会发起一轮新的<strong>心跳</strong>，并等待集群<strong>多数节点</strong>的确认响应。一旦收到这些响应，领导者即可确定：在发送心跳的时刻，集群中不存在任期更大的领导者。因此，彼时的 readIndex，是集群中所有节点曾记录过的最大提交索引。</li><li>领导者等待自身的状态机推进至至少与 readIndex 对应的位置，此时的状态足以满足线性一致性的要求。</li><li>最后，领导者针对自身的状态机执行该查询，并将结果回复给客户端。</li></ol><blockquote><p>关于第 2、4 点可能有个疑问：领导者将当前的 commitIndex 保存至本地变量 readIndex 有啥用？提交 no-op 空条目后 commitIndex 不是等于 readIndex？都提交到状态机了吧，为啥有 “待自身的状态机推进至至少与 readIndex 对应的位置” 这种说法？</p><p>原因：<br>关于提交日志条目到状态机，就像交给一个消息队列一样，队列里面的日志条目最终会应用到状态机，但不是立即应用，状态机的实际运行进度，只由另一个独立指标决定 —— 最后应用索引（Last Applied Index）。<br>所以一个只读查询到达时，状态机里面会存在这样一段时间窗口：日志条目已经复制到多数派集群并且完成提交（commitIndex 更新），但是这个提交的日志条目可能还没有在状态机应用（Last Applied Index &lt; commitIndex），如果直接返回结果的话会导致客户端接收到 Raft 集群已提交的消息却查不到对应数据；但如果无限制延迟查询的话，若此时集群又接收到新的写操作日志条目并提交，会导致 commitIndex 不断增大，若以动态的 commitIndex 为基准等待，执行查询时获取到的并不是查询发起时的状态结果，而可能是被新的日志条目覆盖后的结果。</p><p>因此不能立即执行查询返回结果，也不能没有限制地延后执行查询。</p><p>解决方案：<br>Raft 的方案是处理客户端只读查询请求时，Leader 接收请求后，不会立即执行查询，而是先暂存该请求（新 Leader 则需要先完成本任期 no-op 空条目提交，以确保 commitIndex 为集群全局可靠值）；<br>在处理该请求的这一刻，给每个只读查询分配一个局部变量 readIndex，记录当前的 readIndex &#x3D; commitIndex（冻结固定的状态基准，让等待有明确终止条件），随后先通过心跳包确认 Leader 仍为合法主节点，保证 <code>readIndex</code> 对应的日志已在集群共识提交；返回状态允许包含后续已应用日志。<br>再等待 Last Applied Index 达到 readIndex；当 Last Applied Index 达到 readIndex 后，通过读写锁互斥让应用日志的线程短暂阻塞，原子性执行查询并拿到结果（可同步 &#x2F; 异步返回给客户端），锁释放后应用线程立刻继续异步应用后续的日志条目。<br>期间集群运行不受任何影响，系统依旧可以接受新的日志条目并完成提交，让 commitIndex 持续增大。</p></blockquote><p>这种方式比将只读查询作为新条目提交至日志的方式更高效，因为它避免了同步磁盘写入。为进一步提升效率，领导者可平摊确认自身领导权的开销：对于已累积的任意数量的只读查询，仅需发起一轮心跳即可完成领导权确认。</p><p><strong>跟随者也可协助分担只读查询的处理工作</strong>。这不仅能提升系统的读吞吐量，还能将负载从领导者转移，让领导者可以处理更多的读写请求。但若无额外防护措施，这些由跟随者处理的读操作，同样存在返回过期数据的风险。例如，与集群发生分区的跟随者，可能长时间无法从领导者处接收新的日志条目；即便跟随者收到了领导者的心跳，该领导者也可能已被取代，只是自身尚未知晓。要安全处理读请求，跟随者可向领导者发起请求，仅获取当前的 readIndex（领导者会执行上述 1-3 步）；随后，跟随者可针对自身的状态机执行上述 4-5 步，处理所有已累积的只读查询。</p><p>LogCabin 在领导者节点上实现了上述算法，且在高负载场景下，会将心跳的开销平摊至多个只读查询。目前，LogCabin 的跟随者节点暂不处理只读请求。</p><h3 id="6-4-1-利用时钟减少只读查询的消息交互"><a href="#6-4-1-利用时钟减少只读查询的消息交互" class="headerlink" title="6.4.1 利用时钟减少只读查询的消息交互"></a>6.4.1 利用时钟减少只读查询的消息交互</h3><p>前文提出的只读查询处理方案，可在异步模型中实现线性一致性（该模型中时钟、处理器及消息的运行速率均无约束）。该安全等级的实现依赖通信交互：每批只读查询均需向集群半数以上节点发送一轮心跳包，这会增加查询的延迟。本节后续将介绍一种替代方案，该方案通过时钟机制使只读查询彻底避免消息发送。目前 LogCabin 尚未实现此方案，除非为满足性能需求确有必要，否则不建议采用。</p><p>若要以时钟替代消息实现只读查询，可通过常规的心跳机制实现一种租约机制<sup>[33]</sup>。当领导者的心跳包得到集群多数节点的确认后，即可认定在约一个选举超时时间内，不会有其他节点成为新的领导者，并据此续期自身租约（见图 6.3）。在租约有效期内，领导者可直接响应只读查询，无需进行任何额外的通信交互。（第 3 章介绍的领导权转移机制支持领导者提前交接，交接前领导者需先让自身租约失效。）</p><p><img src="/9a0e6259ac11/6_3.png"></p><blockquote><p>图 6.3：<br>利用时钟替代消息实现只读查询时，领导者将通过常规的心跳机制维护租约。当领导者的心跳得到集群多数节点的确认后，会将自身租约有效期延长至「起始时间 + 选举超时时间 + 时钟漂移上限」，因为从节点在此之前不会触发选举超时。领导者在租约有效期内，可无需进行任何通信，直接处理只读查询请求。</p></blockquote><p>该租约方案要求集群中所有服务器的时钟漂移存在上限约束（即在指定时间段内，任意服务器的时钟走时速率，均不超过其他服务器的该上限倍）。确定并维持该上限值在实际运维中存在诸多挑战 —— 例如进程调度、垃圾回收暂停、虚拟机迁移，或为实现时间同步进行的时钟速率调整，均会对其造成影响。若该前提假设无法满足，系统可能会返回任意过期的数椐。</p><p>所幸可通过一项简单的扩展方案，提升对客户端的一致性保障：即便在异步模型假设下（即时钟出现异常时），每个客户端仍能看到复制状态机的状态呈单调递增演进，即实现顺序一致性。例如，客户端不会先看到日志索引 n 对应的状态，在切换至其他服务器后，却只能看到日志索引 n-1 对应的状态。该保障的实现方式为：服务器在向客户端返回的每一个响应中，均附带当前状态机状态对应的日志索引；客户端需跟踪自身已获取结果对应的最新日志索引，并在每次发起请求时将该信息传递给服务器。若服务器接收到某客户端的请求时，发现该客户端已见过的日志索引高于自身的最后应用日志索引，则暂不处理该请求。</p><h2 id="6-5-结论"><a href="#6-5-结论" class="headerlink" title="6.5 结论"></a>6.5 结论</h2><p>本章探讨了客户端与 Raft 集群交互过程中的若干问题。其中，线性一致性的实现与只读查询的优化这两个问题，在正确性层面的处理尤为微妙。遗憾的是，现有共识算法相关研究文献仅关注集群节点间的通信机制，却将这些重要问题排除在外。我们认为这一做法存在疏漏：一个完整的分布式系统必须实现与客户端的正确交互，否则核心共识算法所保障的一致性等级便无从体现。正如我们在实际的 Raft 落地系统中所见，客户端交互逻辑已成为系统故障的主要诱因，而我们也希望，对这些问题的深入理解能够助力规避此类问题的后续发生。</p>]]></content>
      
      
      <categories>
          
          <category> 技术理论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式系统 </tag>
            
            <tag> Raft </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Arch+River 使用</title>
      <link href="/6d8e2f58e408/"/>
      <url>/6d8e2f58e408/</url>
      
        <content type="html"><![CDATA[<p>My dotfiles : <a href="https://github.com/ECAMT35/dotfiles.git">https://github.com/ECAMT35/dotfiles.git</a></p><p>Q：为什么不用 Labwc 了？<br>A：想体验下平铺式的窗口管理器，并且听说 River 的资源消耗很友好。</p><h1 id="实际体验"><a href="#实际体验" class="headerlink" title="实际体验"></a>实际体验</h1><p><a href="https://codeberg.org/river">River</a>  虽然是平铺式窗口管理器，但是你也可以手动让他浮动起来做到堆叠的效果。River 和  Labwc 不同，它把合成器和布局管理器分离开，虽然它自带了一个 <code>rivertile</code> 作为一个布局管理器，但是我觉得并不太好用，我需要有窗口最大化的功能（最大化≠全屏），而社区开源的 <code>rivercarro</code> 很好地满足了我的需求，使我能在窗口管理上快速地从 Labwc 切换到 River。</p><p>除了平铺式的窗口管理，让我感知比较强的是资源占用。<br>以我的机器为基准，开机 Labwc 的初始占用大概是 <code>179M</code> 左右，久了可能会维持在 <code>350M</code> 上下。而 River 的初始占用是 <code>155M</code> 左右，虽然有几次我看到它的内存飙到 <code>400M</code>，但是很快就降到正常的状态，并且有时候会降到 <code>100M</code> 上下，感觉它的内存管理做得很好。</p><p>另外我已经不再使用 <code>Waybar</code>，它实在是过于重量而且 Bug 不少（之前的内存泄漏让我难受了一阵子，虽然说后面官方好像修了），但 Waybar 也是有优点的：开箱即用很便捷，并且挺好看。<br>作为替代，我使用了 River 社区开源的 <a href="https://codeberg.org/sewn/dam">dam</a>。样子和个性化确实没 Waybar 好，但相比与 Waybar 这个实在太轻量了（Waybar 的初始内存占用大概是 <code>64M</code>，用久了可能成 <code>90M</code>，而 <code>dam + 脚本</code> 几乎一直是 <code>11M +6M</code> 上下），缺点就是需要自己完成脚本制作来获取数据以及不能被包管理器管理（每改一次就需要重新编译）。</p><p>虽然说这个时代可能都是 16G 内存起步的电脑了，而且窗口管理器（WM）的资源占用都挺小，纠结着几百 M 的内存和 CPU 意义不大。但是我还是更喜欢这种轻量、优秀的程序啊（也不是说  Labwc 和 Waybar 是垃圾的意思，它们都很优秀，只是 River 更符合我的爱好）。</p><p>唯一的缺点是，偶尔我的 <code>Super</code> 键会失灵。这个 River 的 Bug 有但很少触发，我至今不知道怎么才能再现这个 Bug，希望后续能彻底解决吧。</p><p>总的来说体验挺好，期待 River 0.4 的大更新。</p><h1 id="桌面软件包"><a href="#桌面软件包" class="headerlink" title="桌面软件包"></a>桌面软件包</h1><p>其实软件包和 <a href="https://ecamt35.github.io/ce269dce74a9/">《Arch+Labwc 使用》</a> 里的差不多，只有一小部分做了更换：</p><p>更换内容：<br>bar: Waybar -&gt; dam<br>背光调节: brightnessctl -&gt; 自定义脚本，见 dotfile 仓库: <code>.local/bin</code><br>监控: htop -&gt; btop<br>浏览器: Firefox -&gt; Firefox + Chromium<br>字体：增加 <code>ttf-hack</code> 为 monopace 首选</p><p>增加了 KVM，因为去工作了，需要用到一堆 Window 专用的软件</p><p>另外，附带上自己更改的 dam，直接编译就能用了，修改详情见 patch 目录，以及 dam 所需的脚本（<a href="https://codeberg.org/unixchad/damblocks">unixchad&#x2F;damblocks</a> 给了我很多灵感）：</p><ul><li><a href="https://github.com/ECAMT35/dam">dam</a></li><li><a href="https://github.com/ECAMT35/dotfiles/blob/master/.config/dam/init">dam-init</a>—这个还需要配合几个脚本使用，相关脚本仍在我的 dotfile 仓库: <code>.local/bin</code></li></ul>]]></content>
      
      
      <categories>
          
          <category> GNU/Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Archlinux </tag>
            
            <tag> River </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis事务</title>
      <link href="/705d67412b1c/"/>
      <url>/705d67412b1c/</url>
      
        <content type="html"><![CDATA[<p>参考：<br><a href="https://redis.io/docs/latest/develop/programmability/eval-intro/">Scripting with Lua</a>——<a href="https://redis.ac.cn/docs/latest/develop/interact/programmability/eval-intro/">译文</a><br><a href="https://pdai.tech/md/db/nosql-redis/db-redis-x-trans.html">Redis进阶 - 事务：Redis事务详解</a></p><h1 id="Redis事务与传统事务的区别"><a href="#Redis事务与传统事务的区别" class="headerlink" title="Redis事务与传统事务的区别"></a>Redis事务与传统事务的区别</h1><p>说到传统的事务，也就是 ACID，先回顾一下它的特性：</p><ul><li><strong>原子性</strong>（<code>Atomicity</code>）：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；</li><li><strong>一致性</strong>（<code>Consistency</code>）：执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；</li><li><strong>隔离性</strong>（<code>Isolation</code>）：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；</li><li><strong>持久性</strong>（<code>Durability</code>）：一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。</li></ul><p>而 Redis 事务通常不能看作传统的事务：<br>Redis 事务的本质是一组命令的集合。它支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。</p><p>以下是它们特性的对比：</p><table><thead><tr><th>特性</th><th>MySQL事务</th><th>Redis事务</th></tr></thead><tbody><tr><td><strong>原子性</strong></td><td>强原子性：要么全部成功，要么全部回滚</td><td>弱原子性：要么全部执行，要么全部不执行，但执行中若命令错误，事务中后续未执行命令仍会继续执行</td></tr><tr><td><strong>一致性</strong></td><td>强一致性：保证事务前后数据符合业务约束</td><td>无一致性保障：Redis无数据约束，操作失败可能导致数据逻辑错误</td></tr><tr><td><strong>隔离性</strong></td><td>支持多种隔离级别（读未提交、读已提交、可重复读、串行化）</td><td>天然”串行隔离”：Redis是单线程模型，所有命令按顺序执行，无需额外隔离机制</td></tr><tr><td><strong>持久性</strong></td><td>强持久性：事务提交后数据永久写入磁盘（依赖redo log）</td><td>无直接持久性：依赖RDB&#x2F;AOF持久化，事务本身不保证持久化</td></tr></tbody></table><p>可以看出，Redis 的事务对比数据库的 ACID，不同的地方主要是在于 A(Atomic)，以及由 A 导致的 C(Consistency)。因为事务中如果有一个命令失败了，Redis 的事务是不会帮你自动回滚的，并且事务中剩下的命令会继续执行下去直到结束事务。这样的操作可能会导致一致性的问题。</p><h1 id="Redis事务的上位替代选择"><a href="#Redis事务的上位替代选择" class="headerlink" title="Redis事务的上位替代选择"></a>Redis事务的上位替代选择</h1><p>所以在我看来，Redis 的事务的作用，更像是要求先处理一个客户端请求的命令队列（Redis 是单线程工作机制），直到这个命令队列被执行完（保证过程中不会被其他客户端的请求命令打断插入），才去处理其他客户端请求的命令。</p><blockquote><p>redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。</p></blockquote><p>这样的话，使用 Lua 脚本可以完美替代 Redis 事务。并且有更多的操作空间。</p><blockquote><p>官方介绍：<br>Redis 允许用户在服务器上上传和执行 Lua 脚本。脚本可以使用程序控制结构，并在执行时使用大部分<a href="https://redis.ac.cn/docs/latest/commands/">命令</a>来访问数据库。由于脚本在服务器中执行，因此从脚本读写数据非常高效。</p><p>Redis 保证脚本的原子执行。在执行脚本期间，所有服务器活动在其整个运行时都会被阻塞。这些语义意味着脚本的所有效果要么尚未发生，要么已经发生。<br>脚本提供了在许多情况下非常有价值的几个特性，包括</p><ul><li>通过在数据所在位置执行逻辑来提供局部性。数据局部性降低了整体延迟并节省了网络资源</li><li>确保脚本原子执行的阻塞语义。</li><li>能够组合 Redis 缺失或过于小众而无法成为其一部分的简单功能。</li></ul><p>Lua 允许你在 Redis 内部运行部分应用程序逻辑。此类脚本可以跨多个键执行条件更新，可能原子地组合多种不同的数据类型。<br>脚本在 Redis 中由嵌入式执行引擎执行。目前，Redis 支持单个脚本引擎，即 <a href="https://lua.ac.cn/">Lua 5.1</a> 解释器。完整的文档请参考<a href="https://redis.ac.cn/docs/latest/develop/interact/programmability/lua-api/">Redis Lua API 参考</a>页面。</p><p>虽然服务器执行它们，但 Eval 脚本被视为客户端应用程序的一部分，因此它们没有名称、版本或持久化。因此，如果脚本丢失（例如服务器重启、故障转移到副本后），应用程序可能需要在任何时候重新加载所有脚本。自版本 7.0 起，<a href="https://redis.ac.cn/docs/latest/develop/interact/programmability/functions-intro/">Redis 函数</a>提供了一种替代的可编程性方法，允许使用额外的编程逻辑扩展服务器本身。</p></blockquote><p>总的来说，把 Redis 事务的命令，全写到一个 Lua 脚本就完事了，这种操作更加节省网络IO，更加灵活。</p><h1 id="如何让Redis事务有回滚的能力"><a href="#如何让Redis事务有回滚的能力" class="headerlink" title="如何让Redis事务有回滚的能力"></a>如何让Redis事务有回滚的能力</h1><p>如上所说，Redis事务没有类似 InnoDB 的 <code>undo log</code> 与 <code>MVCC</code> 的机制，所以肯定是无法完成自动版本回滚的。</p><p>但是如果我一定要 Redis 有数据回滚这个功能，可以实现吗？<br>答案也许是可以的。<strong>虽然 Redis 原生事务无法在执行错误后自动阻止后续命令执行，但可以通过 Lua脚本实现这个功能（这就是上位替代的原因之一）</strong>。</p><p>在 Redis 中，如果某个命令执行失败，Redis 会记录错误并返回的，我们完全可以利用这个返回结果来判断。<br>我们可以 LUA 脚本中，在执行写操作前，记录原值，添加执行后返回的结果判断，如果第一步失败，直接返回错误，就不执行后续命令。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 示例：原子操作，失败则全部回滚</span></span><br><span class="line"><span class="keyword">local</span> key = KEYS[<span class="number">1</span>]</span><br><span class="line"><span class="keyword">local</span> value = ARGV[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 检查原始值</span></span><br><span class="line"><span class="keyword">local</span> original = redis.call(<span class="string">&quot;GET&quot;</span>, key)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 尝试更新</span></span><br><span class="line"><span class="keyword">local</span> set_result = redis.call(<span class="string">&quot;SET&quot;</span>, key, value)</span><br><span class="line"><span class="keyword">if</span> set_result ~= <span class="string">&quot;OK&quot;</span> <span class="keyword">then</span></span><br><span class="line">    <span class="comment">-- 如果SET失败，回滚并返回错误</span></span><br><span class="line">    redis.call(<span class="string">&quot;SET&quot;</span>, key, original)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;ROLLBACK&quot;</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 如果需要执行更多操作，可以在这里继续</span></span><br><span class="line"><span class="comment">-- 例如：更新另一个键</span></span><br><span class="line"><span class="keyword">local</span> update_result = redis.call(<span class="string">&quot;INCR&quot;</span>, <span class="string">&quot;counter&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> update_result == <span class="literal">nil</span> <span class="keyword">then</span></span><br><span class="line">    <span class="comment">-- 如果INCR失败，回滚第一个操作</span></span><br><span class="line">    redis.call(<span class="string">&quot;SET&quot;</span>, key, original)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;ROLLBACK&quot;</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="string">&quot;SUCCESS&quot;</span></span><br></pre></td></tr></table></figure><p>当然这个方案并不是毫无缺点。</p><ol><li>当这个业务比较复杂，涉及的数据比较多、处于并发量高的时候，性能是大大降低的，原因是 Rsdis 的单线程工作机制</li><li>Redis本身没有 InnoDB 的 <code>redo log</code> 机制，当命令执行出错时，这个时候如果者Redis 进程终止了或宕机了，是不能完成上一次的数据回滚的，虽然有AOF日志恢复当时的数据，但你可能不知道当时的命令有没有执行错误。</li></ol><p>所以如果没有非常强的数据一致性要求，这个自己实现的 Redis 回滚机制其实并不是很推荐()</p>]]></content>
      
      
      <categories>
          
          <category> 技术理论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> Lua </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Netty+java完成简单的RPC实现</title>
      <link href="/b62e44ed24b2/"/>
      <url>/b62e44ed24b2/</url>
      
        <content type="html"><![CDATA[<p>RPC又称为远程调用，它让客户端像调用本地方法一样调用远程服务，屏蔽了底层的网络通信细节。</p><p>一个基本的RPC框架需要这几个部分：</p><ul><li><strong>rpc-client</strong>：提供服务接口和实现</li><li><strong>rpc-server</strong>：调用远程服务的客户端</li><li><strong>公共服务接口-api</strong>：客户端用来调用远程方法的代理对象，由服务端完成具体的实现</li></ul><h1 id="rpc-client"><a href="#rpc-client" class="headerlink" title="rpc-client"></a>rpc-client</h1><p>主要是构建 rpc 请求，一般有几个重要的参数：</p><ul><li>抽象接口类名</li><li>抽象方法名（版本、组等，可选）</li><li>参数类型、参数列表</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">RpcRequest</span> <span class="variable">request</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RpcRequest</span>(<span class="string">&quot;com.api.HelloService&quot;</span>, <span class="string">&quot;sayHello&quot;</span>, <span class="keyword">new</span> <span class="title class_">Class</span>[]&#123;String.class&#125;, <span class="keyword">new</span> <span class="title class_">Object</span>[]&#123;<span class="string">&quot;张三&quot;</span>&#125;);</span><br><span class="line"><span class="comment">// 此处使用 Jackson 序列化</span></span><br><span class="line"><span class="type">String</span> <span class="variable">jsonRequest</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectMapper</span>().writeValueAsString(request);</span><br><span class="line"><span class="comment">// 发送 rpc 请求报文</span></span><br><span class="line">endpoint.sendMessage(jsonRequest);</span><br></pre></td></tr></table></figure><h1 id="rpc-server"><a href="#rpc-server" class="headerlink" title="rpc-server"></a>rpc-server</h1><p>主要工作：</p><ul><li>对抽象接口进行具体的实现；</li><li>完成服务注册功能（此处仅是基于内存的简单实现）；</li><li>使用 Netty 完成 WebSocket 服务器的构建；</li></ul><p>工作流程：</p><ol><li>完成服务注册</li><li>启动 WebSocket 服务器</li><li>收到 rpc 请求报文，根据抽象接口类名，在服务注册中心找到对应的实现类</li><li>再根据方法名、参数列表，通过反射的方式获取到调用的方法</li><li>调用方法，构建响应报文给返回客户端</li></ol><h2 id="服务注册"><a href="#服务注册" class="headerlink" title="服务注册"></a>服务注册</h2><p>此处仅是基于内存的简单实现，本质是一个 <code>Map&lt;String, Object&gt; serviceMap</code> 完成的一个映射表。</p><ul><li>key&#x3D;抽象接口类名（版本、组等为可选）</li><li>value&#x3D;服务实现类实例</li></ul><p>需要在启动 WebSocket 服务器前完成注册：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> Map&lt;String, Object&gt; serviceMap = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 注册服务：将接口与实现类绑定</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> serviceInterface 服务接口（如 api 模块下的 HelloService.class）</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> serviceImpl 服务实现类实例（如 new HelloServiceImpl()）</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">registerService</span><span class="params">(Class&lt;?&gt; serviceInterface, Object serviceImpl)</span> &#123;</span><br><span class="line">    <span class="comment">// 存储接口的全限定名（客户端通过该名称找到服务）</span></span><br><span class="line">    serviceMap.put(serviceInterface.getName(), serviceImpl);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="调用本地接口"><a href="#调用本地接口" class="headerlink" title="调用本地接口"></a>调用本地接口</h2><p>核心是反射获取类的方法，然后执行：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 根据请求找到服务实现类</span></span><br><span class="line"><span class="type">Object</span> <span class="variable">serviceImpl</span> <span class="operator">=</span> serviceMap.get(request.getInterfaceName());</span><br><span class="line"><span class="keyword">if</span> (serviceImpl == <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;服务未注册：&quot;</span> + request.getInterfaceName());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 反射得到类的信息</span></span><br><span class="line">Class&lt;?&gt; serviceClass = serviceImpl.getClass();</span><br><span class="line"><span class="comment">// 再根据方法名、参数列表获取要调用的具体方法</span></span><br><span class="line"><span class="type">Method</span> <span class="variable">method</span> <span class="operator">=</span> serviceClass.getMethod(</span><br><span class="line">request.getMethodName(),</span><br><span class="line">request.getParameterTypes() <span class="comment">// 注意：参数类型必须完全匹配</span></span><br><span class="line">);</span><br><span class="line"><span class="comment">// 执行方法，result用于返回rpc响应</span></span><br><span class="line"><span class="type">Object</span> <span class="variable">result</span> <span class="operator">=</span> method.invoke(serviceImpl, request.getParameters());</span><br></pre></td></tr></table></figure><p>以上是一个rpc的简单实现思路，具体实现肯定是比较复杂的。<br>如可使用 zookeeper 做注册中心和配置中心；高性能序列化；负载均衡；重试机制；限流&#x2F;降级&#x2F;熔断；</p>]]></content>
      
      
      <categories>
          
          <category> 技术理论 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>如何保证MQ消息顺序性</title>
      <link href="/40c2be128276/"/>
      <url>/40c2be128276/</url>
      
        <content type="html"><![CDATA[<p>参考：</p><p><a href="https://www.bilibili.com/video/BV13mW4zzEDs/">怎么保证mq消息顺序性？保证不了</a><br><a href="https://www.cnblogs.com/wzh2010/p/15888528.html">MQ系列12：如何保证消息顺序性</a></p><p>消息的有序性在很多业务场景中占有很重要的位置。<br>比如购物场景，需要按照 创建订单 -&gt; 订单付款 -&gt; 完成订单 顺序执行。<br>又比如出行场景，接单 -&gt; 接送到达目的地 -&gt; 付款 -&gt; 完成订单。<br>这种是严格按照顺序执行的，这样的顺序消费才不会出问题，而且各个订单之间是互相独立和并行执行的。<br>所以，在 MQ 中，如何稳定地保证顺序性消息处理，是一个不可避免的话题。</p><h1 id="消息的顺序性说明"><a href="#消息的顺序性说明" class="headerlink" title="消息的顺序性说明"></a>消息的顺序性说明</h1><p>消息的有序执行，一般不是单个组件的能力。而是整个消息从生产，排队，存储到消费都是有序的，比如上面提到的购物和出行场景。</p><p>这就要求我们在消息队列（无论是 Kafka、RocketMQ 还是 RabbitMQ）中，保证以下前提：</p><ul><li>消息生产的有序性：即生产者组件有序发送消息。</li><li>消息入出队列的有序性：消息需严格按照进入队列的先后顺序入队和出队，遵循 FIFO 原则。</li><li>消息的存储的有序性：与上一点一致，部分场景下为提高可靠性需持久化到磁盘，这时候应该遵循有序存放，才能保证后续有序消费。</li><li>消息消费的有序性：即按照顺序进行消费。又分为全局顺序消息与局部顺序消息，全局是指 Topic 下的所有消息都要保证顺序；局部顺序消息保证每一组消息被顺序消费即可。</li></ul><h2 id="全局有序和局部有序"><a href="#全局有序和局部有序" class="headerlink" title="全局有序和局部有序"></a>全局有序和局部有序</h2><p><strong>全局有序是所有消息按发送顺序消费，局部有序是指定业务维度的消息按顺序消费</strong></p><table><thead><tr><th>类型</th><th>定义</th><th>业务场景</th><th>实现成本</th></tr></thead><tbody><tr><td>全局有序</td><td>所有消息严格遵循 “发送顺序 &#x3D; 消费顺序”</td><td>股票交易行情（需全量按时间排序）</td><td>极高（仅单队列 + 单消费者）</td></tr><tr><td>局部有序</td><td>同一业务标识（如订单 ID、用户 ID）的消息按顺序消费</td><td>电商订单（下单→支付→发货）、外卖订单（下单→接单→配送）</td><td>较低（多队列 + 按业务 ID 路由）</td></tr></tbody></table><p>大多数业务无需追求全局有序，只需保证局部有序（如同一订单、同一用户的消息顺序）。</p><p>举个例子：<br>外卖平台无需保证 “用户 A 的下单消息” 和 “用户 B 的下单消息” 的顺序（保证了也没有什么意义，因为两个订单是否全局有序执行不会有任何影响），但必须保证 “用户 A 的下单 → 接单 → 配送” 三条消息按顺序消费。若 “配送” 消息先被处理，会出现 “订单还没被接单就开始配送” 的逻辑错误。</p><p>如果想让全局都是顺序性消费，那么只能用一个消费者去消费队列（一般来说也是单个生产者），这是会严重影响整体性能的。</p><p>所以接下来的内容主要围绕局部有序这个需求进行。</p><h1 id="消息有序性的核心"><a href="#消息有序性的核心" class="headerlink" title="消息有序性的核心"></a>消息有序性的核心</h1><h2 id="MQ存储消息的有序性"><a href="#MQ存储消息的有序性" class="headerlink" title="MQ存储消息的有序性"></a>MQ存储消息的有序性</h2><p>消息队列（MQ）本身的特性决定了其存储的顺序性能力：</p><ul><li>单队列&#x2F;分区的 FIFO 特性：同一队列&#x2F;分区的消息存储和投递遵循先进先出原则，MQ 会将同一队列的消息按投递顺序持久化到磁盘</li><li>跨队列&#x2F;分区的无序性：不同队列&#x2F;分区间的消息可能存在网络延迟差异，MQ本身不保证跨队列&#x2F;分区的全局顺序</li></ul><p>所以按顺序发送到 MQ 单队列的消息，取出的时候也是有序的，不需要我们额外做些什么。<br>我们只需要保证消息的生产和消费时的顺序性就行了。</p><h2 id="消息生产的有序性"><a href="#消息生产的有序性" class="headerlink" title="消息生产的有序性"></a>消息生产的有序性</h2><p>要保证整个消息队列的有序性执行，首先要保证消息生产的有序性。<br>一个完整的过程如果被分配到了不同的队列&#x2F;分区，这可能是消息乱序的起点。</p><p>举个例子：<br>一次完整的消费过程：创建订单、付款、完成订单<br>如果这三个消息分别在三个不同的队列，那这三个步骤可以说是并行执行的，很可能 “完成订单” 反而先被消费，发生逻辑错误。</p><p>所以我们必须保证一组顺序的消息都存入同一个队列&#x2F;分区中。</p><p>方案如下：<br><strong>自定义路由算法，让需有序的消息进入同一队列</strong></p><ul><li>一个订单的多个子消息的父订单号是一致，我们把这些消息按照订单号取模，投送到对应的 Queue 中就行了，比如 订单号 % 队列数量（ 163105015 % 9）</li><li>发送消息自定义消息标签（消息标签可以用队列编号命名），一组消息使用同一个标签，该组标签对应的消息都投向标签所在的队列。</li></ul><p>我们可以定义多个队列&#x2F;分区，多个队列同时存在，也意味着可以存在多个消费者。这显然比全局有序需要满足的条件 ”只允许单个队列-单个消费者“ 性能将会更好。</p><h2 id="消息消费的有序性"><a href="#消息消费的有序性" class="headerlink" title="消息消费的有序性"></a>消息消费的有序性</h2><p>既然消息生产和消息持久化都可以做到有序性。那么只要保证消费的有序性，就能保证整个消息队列的有序执行。</p><p>方案如下：<br><strong>每个队列只能由一个消费者消费</strong></p><p>每个 MQ 消息队列只能由一个消费者消费的话，这个消费者最终能拿到MQ消息队列中所有的消息，所以拿到的消息在总体上是有序的（FIFO），可避免多消费者拆分队列导致的顺序混乱。</p><p>每个队列只能由一个消费者消费的方案虽能保证顺序，但会导致性能瓶颈 —— 若队列中消息量过大，单个消费者串行处理会造成消息积压。</p><p>单消费者效率低的问题也有可行的解决方案：<br><strong>消费者内部维护多个阻塞队列，把同一业务 ID 消息投递到同一个阻塞队列，每个阻塞队列单线程串行，多个阻塞队列并行处理</strong>。</p><p>注意事项：</p><ol><li>阻塞队列需单线程串行处理，可以绑定阻塞队列和独立线程来实现。通过多个阻塞队列并行的方式达到多线程的效果。（否则这与多个消费者消费同一个 MQ 队列没有什么区别了）</li><li>当然这种方法要注意对 MQ 进行 ACK 的时机，因为要放到阻塞队列里面执行，所以 ACK 机制必须换成手动 ACK。时机是从阻塞队列取出消息并处理成功后。</li><li>RabbitMQ 的 <code>prefetch</code> 机制控制的是未 ACK 消息的最大数量（预取数），只要未 ACK 消息数低于 <code>prefetch</code> 上限，即使有未处理完成的消息，消费者也会拉取新消息补充到额度上限，不会等待所有消息处理完。（比如设置 <code>prefetch=5</code>，目前有 3 条同时 ACK，另两条未 ACK，消费者不会等待另外两条消息任务执行完成才向 MQ 一下子获取 5 条新消息，而是 ACK 之后检查未 ACK 最大数量，小于 <code>prefetch</code> 则立即获取新消息补至预取上限）</li></ol><h1 id="导致乱序的其他因素"><a href="#导致乱序的其他因素" class="headerlink" title="导致乱序的其他因素"></a>导致乱序的其他因素</h1><h2 id="扩容缩容导致乱序"><a href="#扩容缩容导致乱序" class="headerlink" title="扩容缩容导致乱序"></a>扩容缩容导致乱序</h2><p>上述的保证局部有序较高性能的方案，是绝对不能随便对队列进行扩容缩容的。<br>一旦扩容缩容，消息队列数量就变化了，从而导致本该在一个队列的消息被分配到不同的队列。</p><p>举个例子：<br>“下单” 消息已经分配到队列1，在投递 “支付” 消息前，此时发生扩容，可能导致 “支付” 消息被分配到队列2，上述也说了消息如果不在同一个 MQ 消息队列&#x2F;分区，是不能保证顺序性的。</p><p>所以最好是先把队列数量固定。或者把出现乱序的同一业务 ID 的所有消息重新投递到特殊的队列处理（这个队列做好完全的顺序检查，可以重复入队等来保证消息的顺序执行）。或者双写过渡，先同时向新旧队列写入消息，待旧队列消息消费完毕后，再停止向旧队列写入、开启新队列的消费。</p><h2 id="Rebalance导致乱序"><a href="#Rebalance导致乱序" class="headerlink" title="Rebalance导致乱序"></a>Rebalance导致乱序</h2><p>MQ 的 “Rebalance” 机制（如 Kafka 的消费者组重平衡）会在 “消费者数量变化”（如下线、新增消费者）时，重新分配 “消费者 - 队列” 的绑定关系。若原消费某队列的消费者被分配到新队列，历史消息与新消息会被不同消费者处理，引发乱序。</p><h2 id="消息重试导致乱序"><a href="#消息重试导致乱序" class="headerlink" title="消息重试导致乱序"></a>消息重试导致乱序</h2><p>消息重试也会破坏顺序性。当消息处理失败或者被拒绝时，MQ 会将消息重新入队（当做新的消息被放到当前队列末尾），若此时重试消息（第一顺序执行的消息）排在新消息（如第二顺序才执行的消息）之后，会导致需要有序消费的消息乱序。</p><p>因此消息消费失败只能进行本地重试-&gt;死信队列，不能把消息放回到MQ队列重试。</p><p>如果采用消费者内部维护阻塞队列的方案，只允许线程内同步重试，处理消息的单线程在当前消息处理失败后，直接在当前上下文循环重试（如最多3次），重试期间不处理阻塞队列的下一条消息。从而避免消息重新入队阻塞队列，打乱阻塞队列中消息的顺序。</p><h2 id="兜底措施"><a href="#兜底措施" class="headerlink" title="兜底措施"></a>兜底措施</h2><p>最好把 MQ 看作不太可靠的中间件，不要全依靠 MQ 保证有序性和可靠性。</p><p>不依靠 MQ 队列实现有序性，就需要在消费消息的时候进行业务检查，如：</p><ol><li>保证消息消费的幂等性；</li><li>检查上一个顺序消息是否被消费完成，没有被消费完成的话本消息可以选择重新投递到 MQ 队列消息&#x2F;死信队列，也可以先尝试重入消费者内部的阻塞队列。</li><li>开启定时任务检查对应的数据，做好补偿策略等。</li></ol><p>上述方法可以作为兜底，全做好了也可以完全不依靠 MQ 来保证有序性和可靠性。但是这种全面检查肯定是需要时间和资源的，在高并发的情况下不太适用。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol><li><strong>自定义路由算法，让需有序的消息进入同一队列</strong></li><li><strong>每个队列只能由一个消费者消费</strong></li><li><strong>消费者内部维护多个阻塞队列，把同一业务 ID 消息投递到同一个阻塞队列，每个阻塞队列单线程串行，多个阻塞队列并行处理</strong></li></ol>]]></content>
      
      
      <categories>
          
          <category> 技术理论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Netty的简单使用</title>
      <link href="/b0f908175cdc/"/>
      <url>/b0f908175cdc/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Netty 4.2.9 中已更换部分相关接口，本文章代码部分已过期。另外业务线程池部分现在可以被Java的虚拟线程取代了</p></blockquote><p><strong>Netty的主从Reactor多线程模型</strong>：BossGroup 处理连接请求，WorkerGroup 处理I&#x2F;O操作。</p><p>Netty 一般需要两个必须的线程组 + 一个可选的自定义业务线程池来完成工作：</p><ul><li><strong>BossGroup</strong>：与客户端建立连接；</li><li><strong>WorkerGroup</strong>：处理已连接的 I&#x2F;O 事件（读写、编解码）；</li><li><strong>自定义业务线程池</strong>：执行耗时的业务逻辑（如数据库操作、复杂计算）；</li></ul><p>大致的工作流程：</p><ol><li><strong>监听端口</strong>：BossGroup 中的线程会绑定服务端端口（如 8080），持续监听客户端的 TCP 连接请求（三次握手）；</li><li><strong>接收连接</strong>：当客户端完成 TCP 三次握手后，连接会进入内核的 “已完成连接队列”，BossGroup 的线程调用 <code>accept()</code> 获取该连接，生成代表连接的 <code>Channel</code> 对象；</li><li><strong>转交连接</strong>：将 <code>Channel</code> 注册到 WorkerGroup 中某个 Worker 线程（<code>EventLoop</code>）的 <code>Selector</code> 上，此后该连接的所有 I&#x2F;O 事件都由这个 Worker 线程负责。</li><li><strong>转交业务</strong>：如有耗时业务，Worker 线程则把该业务给业务线程池，Worker 线程继续处理 I&#x2F;O 事件。</li></ol><h1 id="BossGroup"><a href="#BossGroup" class="headerlink" title="BossGroup"></a>BossGroup</h1><p>BossGroup 的工作非常轻量（仅处理连接建立），因此线程数不需要太多。实际开发中通常直接使用 <code>new NioEventLoopGroup(1)</code> ——1 个线程足够应对大部分场景。</p><h1 id="WorkerGroup"><a href="#WorkerGroup" class="headerlink" title="WorkerGroup"></a>WorkerGroup</h1><p>WorkerGroup 是 Netty 处理 I&#x2F;O 事件的核心，它的职责是<strong>处理已建立连接的所有网络事件</strong>，包括：</p><ul><li>读取客户端发送的数据；</li><li>对数据进行编解码（如 JSON 转对象、协议解析）；</li><li>将处理后的数据写回客户端。</li></ul><p>WorkerGroup 的线程数通常设置为<strong>CPU 核心数 × 2</strong>（Netty 的默认值）。</p><p>整个 WorkerGroup 的结构大概如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">WorkerGroup（工作线程组：管理所有 Worker，负责连接分配）</span><br><span class="line">├─ Worker 1（EventLoop 线程：处理I/O事件，驱动 Selector）</span><br><span class="line">│  └─ Selector 1（多路复用器：监听I/O事件，仅负责&quot;检测&quot;不处理）</span><br><span class="line">│     ├─ Channel 1（连接通道：对应客户端A的TCP连接，传输数据）</span><br><span class="line">│     ├─ Channel 2（连接通道：对应客户端B的TCP连接，传输数据）</span><br><span class="line">│     └─ ...</span><br><span class="line">├─ Worker 2（EventLoop线程：处理I/O事件，驱动Selector）</span><br><span class="line">│  └─ ...</span><br><span class="line">└─ ...</span><br></pre></td></tr></table></figure><p>WorkerGroup 负责把 Channel 交给不太忙的的 Worker 线程，所以每个 Worker 线程可能负责大量的 Channel。</p><p>每个 Worker 线程本质是 <code>EventLoop</code> 线程，循环调用 <code>Selector.select()</code> 监听多个 Channel 的 I&#x2F;O 事件， Worker 线程从 Selector.select() 拿到已经准备好了的 I&#x2F;O 事件和对应的 Channel 集合，然后 Worker 线程逐个处理这些事件。</p><p>处理完这些事件后，再次进入循环调用 <code>Selector.select()</code> 重复上一步。</p><blockquote><p><code>EventLoop</code> 是指单个线程以无限循环的方式不断按一定的流程处理任务。</p></blockquote><p>当 Worker 线程处理就绪事件时，如果事件处理非常耗时（比如超过 1 秒，甚至几分钟），会引发一系列连锁性的严重性能问题，本质原因是<strong>单线程循环被阻塞，导致后续所有依赖该线程的操作无法执行</strong>。</p><p>举个例子：<br>Worker 线程解析到一个 I&#x2F;O 事件，这是一个耗时1分钟的业务请求。那么同一批还未处理的事件&#x2F;需要由下轮循环才能获取的就绪事件都需要等很久才被处理，可能会导致对应的客户端一直没有收到响应，从而超时断开连接、发送冗余请求等。</p><p>这一系列的连锁反应会使整个服务器的吞吐量暴跌，出现假死（进程没崩溃，但大部分客户端的请求无响应）。</p><p>Q: 耗时的工作总得处理啊，怎么办？<br>A: 那就再创建一个业务线程池，把耗时的工作由 WorkerGroup 转交给他就行了。</p><h1 id="业务线程池"><a href="#业务线程池" class="headerlink" title="业务线程池"></a>业务线程池</h1><p>当 WorkerGroup 完成数据的读取和编解码后，就需要处理具体的业务逻辑了（如校验数据、操作数据库、调用 RPC 服务）。<br>这些操作往往耗时较长（毫秒级甚至秒级），如果放在 Worker 线程中执行，会阻塞 I&#x2F;O 处理。因此需要一个专门的业务线程池来承载这些重活。</p><p>线程数量分配：</p><ul><li>CPU 密集型：以 “CPU 核心数” 为基准；</li><li>I&#x2F;O 密集型：以 “CPU 核心数 ×2” 为基准。</li></ul><h1 id="基于WebSocket的Netty服务器"><a href="#基于WebSocket的Netty服务器" class="headerlink" title="基于WebSocket的Netty服务器"></a>基于WebSocket的Netty服务器</h1><p>示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NettyServer</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;netty.websocket.port:8080&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> port;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;netty.websocket.path:/ws&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String webSocketPath;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;netty.websocket.max-frame-size:65536&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> maxFrameSize;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;netty.websocket.idle-timeout:60&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> idleTimeout;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 自定义的业务线程池</span></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> ExecutorService businessExecutor;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> EventLoopGroup bossGroup;</span><br><span class="line">    <span class="keyword">private</span> EventLoopGroup workerGroup;</span><br><span class="line">    <span class="keyword">private</span> Channel serverChannel;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> ObjectProvider&lt;WebSocketFrameHandler&gt; webSocketFrameHandlerProvider;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostConstruct</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">start</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">        bossGroup = <span class="keyword">new</span> <span class="title class_">NioEventLoopGroup</span>(<span class="number">1</span>);</span><br><span class="line">        workerGroup = <span class="keyword">new</span> <span class="title class_">NioEventLoopGroup</span>(); <span class="comment">// 默认CPU核心数*2</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">ServerBootstrap</span> <span class="variable">bootstrap</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ServerBootstrap</span>();</span><br><span class="line">            bootstrap.group(bossGroup, workerGroup)</span><br><span class="line">                    <span class="comment">// 指定服务器通道类型（NIO非阻塞）</span></span><br><span class="line">                    .channel(NioServerSocketChannel.class)</span><br><span class="line">                    <span class="comment">// 服务端TCP参数配置</span></span><br><span class="line">                    .option(ChannelOption.SO_BACKLOG, <span class="number">1024</span>) <span class="comment">// 半连接队列大小</span></span><br><span class="line">                    .option(ChannelOption.SO_REUSEADDR, <span class="literal">true</span>) <span class="comment">// 端口释放后立即重用</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="comment">// 客户端连接参数配置（child开头的选项用于子通道）</span></span><br><span class="line">                    .childOption(ChannelOption.SO_KEEPALIVE, <span class="literal">true</span>) <span class="comment">// 开启TCP心跳</span></span><br><span class="line">                    .childOption(ChannelOption.TCP_NODELAY, <span class="literal">true</span>) <span class="comment">// 禁用Nagle算法</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="comment">// 配置通道初始化器（每个新连接都会执行）</span></span><br><span class="line">                    .childHandler(<span class="keyword">new</span> <span class="title class_">ChannelInitializer</span>&lt;SocketChannel&gt;() &#123;</span><br><span class="line">                        <span class="meta">@Override</span></span><br><span class="line">                        <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">initChannel</span><span class="params">(SocketChannel ch)</span> &#123;</span><br><span class="line">                            <span class="comment">// 获取通道流水线（责任链模式，处理器按顺序执行）</span></span><br><span class="line">                            <span class="type">ChannelPipeline</span> <span class="variable">pipeline</span> <span class="operator">=</span> ch.pipeline();</span><br><span class="line"></span><br><span class="line">                            <span class="comment">// HTTP编解码处理器</span></span><br><span class="line">                            pipeline.addLast(<span class="keyword">new</span> <span class="title class_">HttpServerCodec</span>());</span><br><span class="line"></span><br><span class="line">                            <span class="comment">// HTTP消息聚合器</span></span><br><span class="line">                            pipeline.addLast(<span class="keyword">new</span> <span class="title class_">HttpObjectAggregator</span>(maxFrameSize));</span><br><span class="line"></span><br><span class="line">                            <span class="comment">// WebSocket 协议升级</span></span><br><span class="line">                            pipeline.addLast(<span class="keyword">new</span> <span class="title class_">WebSocketServerProtocolHandler</span>(</span><br><span class="line">                                    webSocketPath, <span class="comment">// WebSocket连接路径</span></span><br><span class="line">                                    <span class="literal">null</span>, <span class="comment">// 子协议（不指定）</span></span><br><span class="line">                                    <span class="literal">true</span>, <span class="comment">// 允许扩展</span></span><br><span class="line">                                    maxFrameSize, <span class="comment">// 最大帧大小</span></span><br><span class="line">                                    <span class="literal">false</span>, <span class="comment">// 不允许掩码（服务端接收客户端消息时）</span></span><br><span class="line">                                    <span class="literal">true</span> <span class="comment">// 自动关闭连接</span></span><br><span class="line">                            ));</span><br><span class="line"></span><br><span class="line">                            <span class="comment">// 空闲检测（仅读空闲）</span></span><br><span class="line">                            pipeline.addLast(<span class="keyword">new</span> <span class="title class_">IdleStateHandler</span>(</span><br><span class="line">                                    idleTimeout, <span class="number">0</span>, <span class="number">0</span>, TimeUnit.SECONDS</span><br><span class="line">                            ));</span><br><span class="line"></span><br><span class="line">                            <span class="comment">// 自定义WebSocket消息处理器（注入业务线程池）</span></span><br><span class="line">                            <span class="type">WebSocketFrameHandler</span> <span class="variable">frameHandler</span> <span class="operator">=</span> webSocketFrameHandlerProvider.getObject();</span><br><span class="line">                            frameHandler.setBusinessExecutor(businessExecutor);</span><br><span class="line">                            pipeline.addLast(frameHandler);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 绑定端口并启动服务</span></span><br><span class="line">            serverChannel = bootstrap.bind(port).sync().channel();</span><br><span class="line">            log.info(<span class="string">&quot;Netty WebSocket server started at ws://localhost:&#123;&#125;&#123;&#125;&quot;</span>, port, webSocketPath);</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            log.error(<span class="string">&quot;Netty server start interrupted&quot;</span>, e);</span><br><span class="line">            Thread.currentThread().interrupt(); <span class="comment">// 恢复中断状态</span></span><br><span class="line">            stop();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            log.error(<span class="string">&quot;Failed to start Netty server&quot;</span>, e);</span><br><span class="line">            stop();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 停止Netty服务器（Spring容器销毁时执行）</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@PreDestroy</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">stop</span><span class="params">()</span> &#123;</span><br><span class="line">        </span><br><span class="line">        log.info(<span class="string">&quot;Shutting down Netty WebSocket server...&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 关闭服务器通道（解绑端口，停止接收新连接）</span></span><br><span class="line">        <span class="keyword">if</span> (serverChannel != <span class="literal">null</span> &amp;&amp; serverChannel.isActive()) &#123;</span><br><span class="line">            serverChannel.close().addListener(future -&gt; &#123;</span><br><span class="line">                <span class="keyword">if</span> (future.isSuccess()) &#123;</span><br><span class="line">                    log.info(<span class="string">&quot;Server channel closed successfully&quot;</span>);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    log.error(<span class="string">&quot;Server channel closed failed&quot;</span>, future.cause());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 关闭Worker线程组（处理完现有任务后关闭）</span></span><br><span class="line">        <span class="keyword">if</span> (workerGroup != <span class="literal">null</span>) &#123;</span><br><span class="line">            workerGroup.shutdownGracefully(<span class="number">1</span>, <span class="number">5</span>, TimeUnit.SECONDS)</span><br><span class="line">                    .addListener(future -&gt; log.info(<span class="string">&quot;Worker group shutdown completed&quot;</span>));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 关闭Boss线程组</span></span><br><span class="line">        <span class="keyword">if</span> (bossGroup != <span class="literal">null</span>) &#123;</span><br><span class="line">            bossGroup.shutdownGracefully(<span class="number">1</span>, <span class="number">5</span>, TimeUnit.SECONDS)</span><br><span class="line">                    .addListener(future -&gt; log.info(<span class="string">&quot;Boss group shutdown completed&quot;</span>));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        log.info(<span class="string">&quot;Netty WebSocket server stopped&quot;</span>);</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取当前服务器绑定的端口（用于监控）</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getBoundPort</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (serverChannel != <span class="literal">null</span> &amp;&amp; serverChannel.isActive()) &#123;</span><br><span class="line">            <span class="keyword">return</span> ((InetSocketAddress) serverChannel.localAddress()).getPort();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@Scope(&quot;prototype&quot;)</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WebSocketFrameHandler</span> <span class="keyword">extends</span> <span class="title class_">SimpleChannelInboundHandler</span>&lt;WebSocketFrame&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 业务线程池</span></span><br><span class="line">    <span class="keyword">private</span> ExecutorService businessExecutor;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 提供业务线程池setter方法，供NettyServer注入</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setBusinessExecutor</span><span class="params">(ExecutorService businessExecutor)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.businessExecutor = businessExecutor;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ... 其他原有逻辑（channelRead0, 事件处理等）</span></span><br><span class="line">    <span class="comment">// 使用this.businessExecutor提交任务即可</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">channelRead0</span><span class="params">(ChannelHandlerContext ctx, WebSocketFrame msg)</span> &#123;</span><br><span class="line">    <span class="comment">// 1. 异步处理前，增加引用计数（父类释放时不会导致计数为0）</span></span><br><span class="line">    msg.retain(); </span><br><span class="line"></span><br><span class="line">    businessExecutor.submit(() -&gt; &#123;</span><br><span class="line">        <span class="comment">// 2. 业务线程中处理消息，此时msg未被释放</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (msg <span class="keyword">instanceof</span> TextWebSocketFrame) &#123;</span><br><span class="line">                <span class="type">String</span> <span class="variable">text</span> <span class="operator">=</span> ((TextWebSocketFrame) msg).text();</span><br><span class="line">                <span class="type">String</span> <span class="variable">result</span> <span class="operator">=</span> processBusiness(text);</span><br><span class="line">                <span class="comment">// 写回响应时，切换到I/O线程（Netty要求：写操作必须在I/O线程执行）</span></span><br><span class="line">                ctx.executor().execute(() -&gt; &#123;</span><br><span class="line">                    <span class="keyword">if</span> (ctx.channel().isActive()) &#123;</span><br><span class="line">                        ctx.writeAndFlush(<span class="keyword">new</span> <span class="title class_">TextWebSocketFrame</span>(result));</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            log.error(<span class="string">&quot;Business process failed&quot;</span>, e);</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="comment">// 3. 业务处理完后，手动释放引用（平衡之前的retain()）</span></span><br><span class="line">            ReferenceCountUtil.release(msg); </span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 无需手动finally释放——父类会自动处理（此时msg引用计数为1，父类释放后变为0）</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="基于TCP的Netty服务器"><a href="#基于TCP的Netty服务器" class="headerlink" title="基于TCP的Netty服务器"></a>基于TCP的Netty服务器</h1><p> 这个是纯TCP的服务器，之前做测试的时候用的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NettyServer</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> EventLoopGroup bossGroup;</span><br><span class="line">    <span class="keyword">private</span> EventLoopGroup workerGroup;</span><br><span class="line">    <span class="keyword">private</span> Channel serverChannel;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">port</span> <span class="operator">=</span> <span class="number">8080</span>; <span class="comment">// Netty 监听端口</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostConstruct</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">start</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        bossGroup = <span class="keyword">new</span> <span class="title class_">NioEventLoopGroup</span>(<span class="number">1</span>); <span class="comment">// 主线程组（处理连接请求）</span></span><br><span class="line">        workerGroup = <span class="keyword">new</span> <span class="title class_">NioEventLoopGroup</span>(); <span class="comment">// 工作线程组（处理 I/O 操作）</span></span><br><span class="line"></span><br><span class="line">        <span class="type">ServerBootstrap</span> <span class="variable">bootstrap</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ServerBootstrap</span>();</span><br><span class="line">        bootstrap.group(bossGroup, workerGroup)</span><br><span class="line">                .channel(NioServerSocketChannel.class) <span class="comment">// 使用 NIO 传输</span></span><br><span class="line">                .childHandler(<span class="keyword">new</span> <span class="title class_">ChannelInitializer</span>&lt;SocketChannel&gt;() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">initChannel</span><span class="params">(SocketChannel ch)</span> &#123;</span><br><span class="line"></span><br><span class="line">                        ch.pipeline()</span><br><span class="line">                                <span class="comment">//.addLast(new LoggingHandler(LogLevel.INFO)) // 添加网络层日志</span></span><br><span class="line">                                .addLast(<span class="keyword">new</span> <span class="title class_">StringDecoder</span>())</span><br><span class="line">                                .addLast(<span class="keyword">new</span> <span class="title class_">StringEncoder</span>())</span><br><span class="line">                                .addLast(<span class="keyword">new</span> <span class="title class_">MyServerHandler</span>()) <span class="comment">// 添加自定义处理器（需实现）</span></span><br><span class="line">                        ;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;)</span><br><span class="line">                .option(ChannelOption.SO_BACKLOG, <span class="number">128</span>) <span class="comment">// 连接队列大小</span></span><br><span class="line">                .childOption(ChannelOption.SO_KEEPALIVE, <span class="literal">true</span>); <span class="comment">// 保持 TCP 连接</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 绑定端口并启动服务器</span></span><br><span class="line">        serverChannel = bootstrap.bind(port).sync().channel();</span><br><span class="line">        System.out.println(<span class="string">&quot;Netty server started on port: &quot;</span> + port);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PreDestroy</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">stop</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (serverChannel != <span class="literal">null</span>) &#123;</span><br><span class="line">            serverChannel.close(); <span class="comment">// 关闭 Channel</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (workerGroup != <span class="literal">null</span>) &#123;</span><br><span class="line">            workerGroup.shutdownGracefully(); <span class="comment">// 优雅关闭工作线程组</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (bossGroup != <span class="literal">null</span>) &#123;</span><br><span class="line">            bossGroup.shutdownGracefully(); <span class="comment">// 优雅关闭主线程组</span></span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;Netty server stopped&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyServerHandler</span> <span class="keyword">extends</span> <span class="title class_">SimpleChannelInboundHandler</span>&lt;String&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">channelRead0</span><span class="params">(ChannelHandlerContext ctx, String msg)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Received: &quot;</span> + msg);</span><br><span class="line">        ctx.writeAndFlush(<span class="string">&quot;Echo: &quot;</span> + msg); <span class="comment">// 回传消息</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">exceptionCaught</span><span class="params">(ChannelHandlerContext ctx, Throwable cause)</span> &#123;</span><br><span class="line">        cause.printStackTrace();</span><br><span class="line">        ctx.close(); <span class="comment">// 发生异常时关闭连接</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试：<br>终端使用telnet连上TCP连接：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ telnet 127.0.0.1 8080</span><br><span class="line">Trying 127.0.0.1...</span><br><span class="line">Connected to 127.0.0.1.</span><br><span class="line">Escape character is <span class="string">&#x27;^]&#x27;</span>.</span><br><span class="line">my fork</span><br><span class="line">Echo: my fork</span><br><span class="line">my spoon</span><br><span class="line">Echo: my spoon</span><br></pre></td></tr></table></figure><p>Netty服务端日志：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Received: my fork</span><br><span class="line">Received: my spoon</span><br></pre></td></tr></table></figure><p>Netty服务端接收到Msg经过解码编码后进行回应，并记录日志。</p>]]></content>
      
      
      <categories>
          
          <category> 技术理论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Netty </tag>
            
            <tag> WebSocket </tag>
            
            <tag> NIO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式IM设计的胡思乱想</title>
      <link href="/d451d62f56e3/"/>
      <url>/d451d62f56e3/</url>
      
        <content type="html"><![CDATA[<p>参考：</p><p><a href="https://cloud.tencent.com/developer/article/1936475">IM消息机制（一）：保证在线实时消息的可靠投递</a><br><a href="https://blog.csdn.net/qq_21561833/article/details/135681086">分布式websocket即时通信(IM)系统保证消息可靠性【第八期】</a><br><a href="https://blog.yueban.site/2021/02/09/Telegram%20%E5%AE%89%E5%85%A8%E6%96%B9%E6%A1%88%E8%A7%A3%E6%9E%90%20-%20%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%88%B0%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%9A%84%E5%8A%A0%E5%AF%86/#Authorization-Key-auth-key">Telegram 安全方案解析 - 客户端到服务端的加密</a></p><h1 id="分布式WebSocket"><a href="#分布式WebSocket" class="headerlink" title="分布式WebSocket"></a>分布式WebSocket</h1><p>常见方案在我介绍分布式 WebSocket 的文章有说。<br>我偏好选择 Redis 中央路由+消息队列的方式。</p><p>使用 Netty 服务器代替 Tomcat，创建一个WebSocket服务器。</p><h1 id="X3DH加密"><a href="#X3DH加密" class="headerlink" title="X3DH加密"></a>X3DH加密</h1><p>X3DH仅用于单聊的消息，每条消息发送的时候，服务器端记录发送者的公钥（IK,EK），接收者的公钥（IK,SPK,OPK）。</p><h1 id="消息的可靠投递"><a href="#消息的可靠投递" class="headerlink" title="消息的可靠投递"></a>消息的可靠投递</h1><blockquote><p>Q：为什么在有TCP的情况下还需要自己实现聊天消息的ACK机制？<br>A：TCP是“传输可靠”，应用层ACK是“业务可靠”。</p><p>TCP的可靠性确保数据从发送端的TCP层到接收端的TCP层的字节流完整、有序、无重复。<br>但是在IM系统里面光是传输到是没有意义的，TCP确保数据包到达接收端的TCP层，但接收方应用可能崩溃、卡死或处理失败，各种原因没及时保存数据包导致消息再也无法成功展示给用户，永久漏了这条消息。</p></blockquote><h2 id="六报文设计"><a href="#六报文设计" class="headerlink" title="六报文设计"></a>六报文设计</h2><p>IM系统的六报文设计是<strong>消息可靠投递的核心机制</strong>，通过<strong>双重确认</strong>和<strong>超时重传</strong>确保消息不丢失。</p><p>报文分为三种：</p><ol><li>请求报文（request，后简称为为R）</li><li>应答报文（acknowledge，后简称为A）</li><li>通知报文（notify，后简称为N）</li></ol><p><strong>msg:R&#x2F;A&#x2F;N</strong>：确保消息从发送方到接收方的可靠性。<br><strong>ack:R&#x2F;A&#x2F;N</strong>：确保接收方已读消息，并通知发送方。</p><p>流程</p><ol><li><strong>发送请求（msg:R）</strong>- 客户端A发送消息到服务器（IM Server）。</li><li><strong>发送确认（msg:A）</strong>- IM Server确认消息已接收，返回ACK给客户端A。</li><li><strong>消息通知（msg:N）</strong>- IM Server将消息推送给客户端B（若在线）。</li><li><strong>客户端B确认请求（ack:R）</strong>- 客户端B向 IM Server 发送ACK确认请求收到消息。</li><li><strong>服务端确认（ack:A）</strong>- IM Server确认客户端B的ACK。</li><li><strong>发送方通知（ack:N）</strong>- IM Server通知客户端A消息已送达客户端B。</li></ol><p>可以在消息表维护一个status字段，记录目前状态（sent, delivered, read, finished），从而避免显示的ack:N推送。<br>finish字段用于过滤状态为已读的历史消息，减少网络IO以及没有必要的去重</p><p>整个流程大概如下（单聊）：<br><img src="/Pasted%20image%2020251004153517.png"></p><h2 id="超时与重传"><a href="#超时与重传" class="headerlink" title="超时与重传"></a>超时与重传</h2><p>若客户端向服务器发送消息后，没有收到 msg:A，则需要进行一定次数的重传，同时维护重传计数器，如首次超时 1s 重试，第二次 2s，第三次 4s，最大重试 3 次（避免无限重试），超过次数则标记 “发送失败” 并提示用户。</p><p>重传消息可能会导致多条相同消息发送，本来你也许只想发送一次该条消息的。那给消息设置一个唯一 ID 则是一个很好的解决方案。<br>如客户端使用 UUID 作为请求 ID 来跟踪定位这条消息，用于发送方确认是否成功发送以及获取对应的消息 ID，实际的消息 ID 则由服务器端生成（雪花算法 ID）。</p><h1 id="消息同步机制"><a href="#消息同步机制" class="headerlink" title="消息同步机制"></a>消息同步机制</h1><h2 id="读扩散和写扩散"><a href="#读扩散和写扩散" class="headerlink" title="读扩散和写扩散"></a>读扩散和写扩散</h2><p>写扩散（Write Diffusion）</p><ul><li><strong>核心逻辑</strong>：当一条消息发送到群聊时，将消息<strong>复制并存储到每个群成员的个人收件箱</strong>中。</li><li><strong>形象理解</strong>：类似于 “群发邮件”，发件人一次发送，系统自动给每个收件人复制一份存到他们的邮箱。</li><li><strong>读写特点</strong>：<ul><li>写操作成本高（群成员越多，写入次数越多）；</li><li>读操作简单高效（用户只需查询自己的收件箱，无需额外计算）。</li></ul></li></ul><p>读扩散（Read Diffusion）</p><ul><li><strong>核心逻辑</strong>：当一条消息发送到群聊时，<strong>只存储一份到群的公共消息列表</strong>中。用户读取消息时，再从公共列表中拉取自己有权限查看的消息。</li><li><strong>形象理解</strong>：类似于 “论坛帖子”，发帖人只发一次到论坛，用户各自去论坛查看。</li><li><strong>读写特点</strong>：<ul><li>写操作成本低（无论群大小，只写一次）；</li><li>读操作复杂（需要计算用户可见范围、过滤已读消息等）。</li></ul></li></ul><p>写扩散理论上是每人有自己的信箱，可以使用统一的收件箱存储所有用户的扩散消息。发送者发送消息的时候，还需要额外为接收者在 DB 插入一条记录，每个用户根据自己的 ID 获取相应的扩散信息。</p><p>读扩散不需要为接收者额外插入一条记录，只需要记录发送者发出的消息，用户在消息表中使用自己的 ID 进行过滤获取。</p><p>单聊下读写扩散相差不大，差别在大群聊天就能体现出来了。<br>场景：用户A在1000人的群中发一条消息：<br>写扩散：先存 1 条原始消息到 message 表，再向 1000 个群成员的收件箱各写 1 条关联记录（inbox表需写 1000 条）。<br>读扩散：服务器只需将消息存储到消息表（1次写入），但是由于消息表可能积累很多历史消息的记录，所以读取最新消息时可能会读取大量历史消息再进行去重过滤比较耗时，但是这个缺点可以使用游标过滤解决。</p><h2 id="推送机制"><a href="#推送机制" class="headerlink" title="推送机制"></a>推送机制</h2><p>无论群聊还是单人，由于个人偏好我选择读扩散；</p><p>强制主动推送的时机是用户建立 WebSocket 长连接后；</p><h3 id="Pull"><a href="#Pull" class="headerlink" title="Pull"></a>Pull</h3><p>双人聊天均使用服务器主动推送消息；群聊根据群聊大小需选择主动推送还是等待用户 pull。</p><p>当群内产生新消息时，服务器不直接通过 WebSocket 推完整消息，而是推一个 “极简信号”，告知客户端 “某个群有新消息，该 Pull 了”。</p><p>可以利用 Redis 做一个群聊未读功能，只存储群聊未读消息计数不存储信息，等用户进入聊天会话的时候再开始分页查询。用户发送消息时，给该群所有用户的未读计数器计数+1；——使用LUA<br>不是给 1000 人大群建 1000 个独立计数器，而是用 “群为 key，用户为 field， 未读消息计数为 value” 的 Hash 结构，1 个群的所有用户计数器存在 1 个 Redis 键里。</p><p>在线触发时机：服务器需维护 “用户 - WebSocket 连接” 映射表，同时维护 “群 - 用户” 在线关系表，群消息成功写入数据库后，筛选出 “在群内且当前 WebSocket 在线” 的用户，仅给这些用户触发信号推送；</p><p>离线后登陆策略：获取用户所有群的未读计数器，避免一登陆就要等待比较长时间的检索以及大量 ACK:R&#x2F;A&#x2F;N 报文导致客户端和服务端出现性能问题。</p><p>考虑群聊未读计数器的持久化。</p><h3 id="游标"><a href="#游标" class="headerlink" title="游标"></a>游标</h3><p>被动推送的方法是 pull + 游标，消息表索引是个联合索引，注意左前缀原则避免索引失效。如果偏移值是 msg_id，那么 msg_id 索引需要放到联合索引最后避免索引失效。</p><p>但是使用 msg_id 单个游标可能会在群聊出现漏消息问题，因为不同用户可能在多个节点生成多个雪花 ID，较小的那个因为网络等问题而导致最后才入库，而此时用户已经更新了游标，导致较早生成（ID较小）但是落库较晚的消息被跳过，并且永远无法被感知读取也是有可能的。<br>这种情况可以使用<strong>复合游标</strong>去解决，使用（<strong>宽松时间戳，msg_id</strong>）作为游标更加安全。Pull 时使用<code>created_at &gt; ? OR (created_at = ? AND msg_id &gt; ?)</code> 去查询，时间戳优先，ID兜底。</p><p>仅使用纯时间戳作为游标也有点问题，Pull 是 “即时查询”，同一时间戳有多条消息可能出现楼消息的情况：<br>消息 X：ID&#x3D;101（先落库）；<br>消息 Y：ID&#x3D;102（中间落库）；<br>消息 Z：ID&#x3D;103（因节点压力延迟 0.5 秒落库）<br>此时用户读到Y就返回了，下次查询时使用 <code>created_at &gt; ?</code> 来查询就会漏掉Z。</p><blockquote><p>时间戳建议用MySQL函数生成来保证全局一致性<br>宽松时间戳是指上条消息的时间戳减去n秒（向前多取1秒）</p></blockquote><h3 id="消息分片"><a href="#消息分片" class="headerlink" title="消息分片"></a>消息分片</h3><p>某帖子看到的，也许也可以考虑：<br>超大群的消息可以采用消息分片，服务器端将群消息按 “时间片” 分片存储到缓存（如每5min一个分片，避免大key问题）。<br>群消息落库后，同步写入 Redis 缓存，避免每次拉取都查底层数据库。如果客户端的游标时间戳（最后一条消息的时间）在这个分片之前，那就到数据库去拉去；否则先从 Redis 获取到分片的所有消息，再根据复合游标过滤已接收的消息再发送给用户端。</p>]]></content>
      
      
      <categories>
          
          <category> 技术理论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式下的WebSocket</title>
      <link href="/3d36dd04b30a/"/>
      <url>/3d36dd04b30a/</url>
      
        <content type="html"><![CDATA[<p>参考：<br><a href="https://zhuanlan.zhihu.com/p/258097038">https://zhuanlan.zhihu.com/p/258097038</a><br><a href="https://lawrenceli.me/blog/websocket-cluster#%E7%AE%80%E5%8D%95%E5%B9%BF%E6%92%AD%E5%AE%9E%E7%8E%B0-websocket-%E9%9B%86%E7%BE%A4">https://lawrenceli.me/blog/websocket-cluster#%E7%AE%80%E5%8D%95%E5%B9%BF%E6%92%AD%E5%AE%9E%E7%8E%B0-websocket-%E9%9B%86%E7%BE%A4</a></p><h1 id="单例WebSocket回顾"><a href="#单例WebSocket回顾" class="headerlink" title="单例WebSocket回顾"></a>单例WebSocket回顾</h1><p>示例代码没有使用 <code>Spring Boot</code> 集成，是使用 <code>javax.websocket</code> API 实现的单例 WebSocket 应用。这是一个简单的例子，实际使用上可以添加心跳检测机制、异步广播、清理无效会话等功能；</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> javax.websocket.*;</span><br><span class="line"><span class="keyword">import</span> javax.websocket.server.ServerEndpoint;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ConcurrentHashMap;</span><br><span class="line"></span><br><span class="line"><span class="meta">@ServerEndpoint(&quot;/chat&quot;)</span> <span class="comment">// WebSocket 服务端点</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SimpleWebSocketServer</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 使用 ConcurrentHashMap 存储所有连接会话</span></span><br><span class="line">    <span class="comment">// Key: 会话ID (String), Value: WebSocket会话对象 (Session)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ConcurrentHashMap&lt;String, Session&gt; sessions = </span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">ConcurrentHashMap</span>&lt;&gt;();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 当新客户端连接时调用</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@OnOpen</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onOpen</span><span class="params">(Session session)</span> &#123;</span><br><span class="line">        <span class="comment">// 将新会话添加到Map</span></span><br><span class="line">        sessions.put(session.getId(), session);</span><br><span class="line">        </span><br><span class="line">        System.out.println(<span class="string">&quot;新客户端连接: &quot;</span> + session.getId());</span><br><span class="line">        sendMessage(session, <span class="string">&quot;欢迎加入聊天室! 你的ID: &quot;</span> + session.getId());</span><br><span class="line">        broadcast(<span class="string">&quot;系统消息: 用户 &quot;</span> + session.getId() + <span class="string">&quot; 加入聊天室&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 当收到客户端消息时调用</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@OnMessage</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onMessage</span><span class="params">(String message, Session sender)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;收到消息 [&quot;</span> + sender.getId() + <span class="string">&quot;]: &quot;</span> + message);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 广播消息给所有客户端</span></span><br><span class="line">        broadcast(<span class="string">&quot;用户 &quot;</span> + sender.getId() + <span class="string">&quot;: &quot;</span> + message);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 当客户端断开连接时调用</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@OnClose</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onClose</span><span class="params">(Session session, CloseReason reason)</span> &#123;</span><br><span class="line">        <span class="comment">// 从Map中移除会话</span></span><br><span class="line">        sessions.remove(session.getId());</span><br><span class="line">        </span><br><span class="line">        System.out.println(<span class="string">&quot;客户端断开: &quot;</span> + session.getId() + <span class="string">&quot;, 原因: &quot;</span> + reason.getReasonPhrase());</span><br><span class="line">        broadcast(<span class="string">&quot;系统消息: 用户 &quot;</span> + session.getId() + <span class="string">&quot; 离开聊天室&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 错误处理</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@OnError</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onError</span><span class="params">(Session session, Throwable throwable)</span> &#123;</span><br><span class="line">        System.err.println(<span class="string">&quot;连接错误: &quot;</span> + session.getId());</span><br><span class="line">        throwable.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 广播消息给所有客户端</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> message 要发送的消息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">broadcast</span><span class="params">(String message)</span> &#123;</span><br><span class="line">        <span class="comment">// 遍历所有会话并发送消息</span></span><br><span class="line">        sessions.forEach((id, session) -&gt; &#123;</span><br><span class="line">            <span class="keyword">if</span> (session.isOpen()) &#123;</span><br><span class="line">                sendMessage(session, message);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 发送消息给单个客户端</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> session 目标会话</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> message 要发送的消息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">sendMessage</span><span class="params">(Session session, String message)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 使用异步方式发送，避免阻塞</span></span><br><span class="line">            session.getAsyncRemote().sendText(message);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            System.err.println(<span class="string">&quot;发送消息失败: &quot;</span> + e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>重写的方法：</p><ul><li>onOpen：在客户端与WebSocket服务连接时触发方法执行</li><li>onClose：在客户端与WebSocket连接断开的时候触发执行</li><li>onMessage：在接收到客户端发送的消息时触发执行</li><li>onError：在发生错误时触发执行</li></ul><p>流程：</p><ol><li>客户端与服务端建立 TCP 连接，使用 HTTP 协议升级为 WebSocket 协议连接到服务端的 <code>/chat</code> 端点，触发 <code>onOpen</code> 方法；</li><li>客户端以 WebSocket 数据帧的形式发送消息；</li><li>服务端的 <code>onMessage</code> 方法被触发；</li><li>服务端使用 WebSocket Session 进行数据发送；</li><li>若客户端主动下线，触发 <code>onClose</code>；若通信时网络中断触发 <code>onError</code>；</li></ol><h1 id="单例和分布式WebSocket的区别"><a href="#单例和分布式WebSocket的区别" class="headerlink" title="单例和分布式WebSocket的区别"></a>单例和分布式WebSocket的区别</h1><p>一图流：</p><table><thead><tr><th><strong>对比维度</strong></th><th><strong>单例环境</strong></th><th><strong>分布式环境</strong></th><th><strong>问题根源</strong></th></tr></thead><tbody><tr><td><strong>连接管理</strong></td><td>单节点内存维护所有连接（如 <code>ConcurrentHashMap</code>）</td><td>连接分散在多个节点，无全局视图</td><td>WebSocket 的 Session 基于 TCP 连接，无法跨节点序列化或共享</td></tr><tr><td><strong>消息路由</strong></td><td>直接遍历本地连接推送消息</td><td>需跨节点定位目标连接，否则部分用户收不到消息</td><td>用户连接可能分布在任意节点，发送方节点无法直接访问接收方连接</td></tr><tr><td><strong>负载均衡</strong></td><td>无需考虑连接分布</td><td>新增&#x2F;减少节点时连接分配不均（如轮询算法）</td><td>持久连接无法像 HTTP 请求那样动态重分配到新节点</td></tr><tr><td><strong>会话状态</strong></td><td>Session 绑定到本地内存</td><td>Session 状态需外部存储（如 Redis）</td><td>WebSocket Session 包含 TCP 连接信息，无法在集群间迁移</td></tr></tbody></table><p>分析：<br>WebSocket 是有状态的协议，每个连接是绑定到特定服务器节点的。</p><p>单体应用下只有一台服务器，所有的客户端连接的都是这一台消息服务器，所以当发布消息者发送消息时，所有的客户端其实已经全部与这台服务器建立了连接，直接群发消息就可以了。</p><p>换成分布式系统后，如果客户端连接的服务器发生故障或负载均衡切换，其他节点无法获取该连接的状态。</p><p>如：客服系统单机部署时，用户A与客服B连接同一节点，消息可正常推送；分布式部署后，若用户A连接节点1，客服B连接节点2，则用户A的消息无法到达客服B。</p><p>单机应用下不会出现通信问题：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">    title 单机部署 - 消息正常推送</span><br><span class="line">    participant 用户A as 用户A</span><br><span class="line">    participant 节点 as 节点1</span><br><span class="line">    participant 客服B as 客服B</span><br><span class="line">    </span><br><span class="line">    rect rgba(0, 128, 0, 0.1)</span><br><span class="line">        用户A-&gt;&gt;节点: 连接请求</span><br><span class="line">        节点--&gt;&gt;用户A: 连接成功</span><br><span class="line">        </span><br><span class="line">        客服B-&gt;&gt;节点: 连接请求</span><br><span class="line">        节点--&gt;&gt;客服B: 连接成功</span><br><span class="line">        </span><br><span class="line">        用户A-&gt;&gt;节点: 发送消息给客服B</span><br><span class="line">        节点-&gt;&gt;节点: 查找本地连接&lt;br/&gt;找到客服B会话</span><br><span class="line">        节点-&gt;&gt;客服B: 推送消息</span><br><span class="line">        客服B--&gt;&gt;节点: 接收成功</span><br><span class="line">    end</span><br></pre></td></tr></table></figure><p>分布式下出现通信问题：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">    title 分布式部署 - 消息无法送达</span><br><span class="line">    participant 用户A as 用户A</span><br><span class="line">    participant LB as 负载均衡器</span><br><span class="line">    participant 节点1 as 节点1</span><br><span class="line">    participant 节点2 as 节点2</span><br><span class="line">    participant 客服B as 客服B</span><br><span class="line">    </span><br><span class="line">    rect rgba(128, 0, 0, 0.1)</span><br><span class="line">        用户A-&gt;&gt;LB: 连接请求</span><br><span class="line">        LB-&gt;&gt;节点1: 分配用户A</span><br><span class="line">        节点1-&gt;&gt;用户A: 连接成功</span><br><span class="line">        </span><br><span class="line">        客服B-&gt;&gt;LB: 连接请求</span><br><span class="line">        LB-&gt;&gt;节点2: 分配客服B</span><br><span class="line">        节点2-&gt;&gt;客服B: 连接成功</span><br><span class="line">        </span><br><span class="line">        用户A-&gt;&gt;节点1: 发送消息给客服B</span><br><span class="line">        节点1-&gt;&gt;节点1: 查找本地连接&lt;br/&gt;未找到客服B</span><br><span class="line">        节点1--&gt;&gt;用户A: 发送失败/无响应</span><br><span class="line">    end</span><br></pre></td></tr></table></figure><blockquote><p>Q: WebSocket 连接通过 Nginx 通过 Gateway 再到服务器，连接上之后就不会再走 Nginx 和Gateway 的均衡负载选择后端服务器了吗？</p><p>A: 连接建立后，WebSocket 数据仍需经过 Nginx 和 Gateway，因为它们作为代理维持了 TCP 长连接，会持续作为中间代理，转发所有数据帧，但不再重新选择服务器节点（除非连接中断或主动切换）</p></blockquote><h1 id="常见解决方案"><a href="#常见解决方案" class="headerlink" title="常见解决方案"></a>常见解决方案</h1><h2 id="广播模式"><a href="#广播模式" class="headerlink" title="广播模式"></a>广播模式</h2><p>原理：<br>使用消息队列进行广播。<br>在接收到消息时，不是直接通过 WebSocket 发送消息给对应客户端，而是发布消息到中间件（如 Redis Pub&#x2F;Sub、RabbitMQ），所有节点消费并判断是否需处理本地连接。</p><p>优点：实现简单，扩展性强。</p><p>缺点：网络流量大（消息被所有节点消费），给所有节点带来压力。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">    participant 用户A as 用户A</span><br><span class="line">    participant 节点1 as 节点1</span><br><span class="line">    participant MQ as 消息中间件</span><br><span class="line">    participant 节点2 as 节点2</span><br><span class="line">    participant 客服B as 客服B</span><br><span class="line">    </span><br><span class="line">    rect rgba(0, 100, 200, 0.1)</span><br><span class="line">        note over 用户A,节点1: 用户A发送消息</span><br><span class="line">        用户A-&gt;&gt;节点1: 发送消息给客服B</span><br><span class="line">        </span><br><span class="line">        note over 节点1,MQ: 发布消息到中间件</span><br><span class="line">        节点1-&gt;&gt;MQ: 发布消息到队列&#123;&quot;target&quot;: &quot;客服B&quot;, &quot;content&quot;: &quot;...&quot;&#125;</span><br><span class="line">        </span><br><span class="line">        note over MQ: 中间件广播消息</span><br><span class="line">        MQ--&gt;&gt;节点1: 推送消息（所有节点都收到）</span><br><span class="line">        MQ--&gt;&gt;节点2: 推送消息</span><br><span class="line">        </span><br><span class="line">        note over 节点1,节点1: 节点1处理消息</span><br><span class="line">        节点1-&gt;&gt;节点1: 检查本地连接 客服B不在本节点 → 忽略</span><br><span class="line">        </span><br><span class="line">        note over 节点2,客服B: 节点2处理消息</span><br><span class="line">        节点2-&gt;&gt;节点2: 检查本地连接 找到客服B会话</span><br><span class="line">        节点2-&gt;&gt;客服B: 推送消息</span><br><span class="line">        客服B--&gt;&gt;节点2: 接收成功</span><br><span class="line">    end</span><br></pre></td></tr></table></figure><h2 id="路由模式"><a href="#路由模式" class="headerlink" title="路由模式"></a>路由模式</h2><p>原理：<br>中央路由表+精准投递。</p><p>如：连接时存储（用户ID, 节点ID）映射关系存储到路由表，发送消息时根据对方客户端所在的节点ID作为消息队列 <code>RoutingKey</code>，精确推送到目标节点的专属队列。</p><p>优点：精准投递，网络高效，消息只发送到目标节点。</p><p>缺点：</p><ol><li>路由表依赖，Redis宕机导致系统不可用；</li><li>状态不一致，客户端意外断开重连到新节点而路由表未更新——可以通过缓存过期续期那一套解决；</li><li>节点1宕机后重启，用户2重新连接到了一个节点2，此前若有等待被发到用户2的消息，那么仍是节点1的专属队列，节点1正要给用户2发送消息时发现本地并没有这个 WebSoket Session，需要重新查询路由表投递给消息队列，导致延时增大；若节点1没恢复，消息则永远不会发送到用户2；</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">    participant C as 客户端A</span><br><span class="line">    participant N1 as 节点1</span><br><span class="line">    participant Redis as 路由表（Redis）</span><br><span class="line">    participant MQ as 消息队列</span><br><span class="line">    participant N2 as 节点2</span><br><span class="line">    participant S as 客服B</span><br><span class="line">    </span><br><span class="line">    C-&gt;&gt;N1: 发送消息</span><br><span class="line">    N1-&gt;&gt;Redis: 查询目标节点</span><br><span class="line">    Redis--&gt;&gt;N1: 返回节点2</span><br><span class="line">    N1-&gt;&gt;MQ: 转发到节点2队列</span><br><span class="line">    MQ-&gt;&gt;N2: 投递消息</span><br><span class="line">    N2-&gt;&gt;S: 推送消息</span><br></pre></td></tr></table></figure><h2 id="哈希环"><a href="#哈希环" class="headerlink" title="哈希环"></a>哈希环</h2><p>不借助这些队列&#x2F;订阅机制，通过哈希函数将用户ID映射到 WebSocket 服务器，实现消息的路由和推送。该方案可以有效减少消息广播带来的网络流量，并提高消息传递的效率。<br>需要通过心跳等机制，去维护节点的存活情况，保证路由到的 WebSocket 服务器节点可用。</p>]]></content>
      
      
      <categories>
          
          <category> 技术理论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式系统 </tag>
            
            <tag> WebSocket </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>父子任务共用线程池导致死锁</title>
      <link href="/322ab9175e3b/"/>
      <url>/322ab9175e3b/</url>
      
        <content type="html"><![CDATA[<p>父子任务共用线程池导致死锁的核心原因是<strong>资源竞争与循环等待</strong>。当父任务在执行过程中提交子任务到同一线程池，并等待子任务完成时，如果线程池的线程资源被父任务完全占用，子任务无法获取线程执行，父任务又因等待子任务结果而无法释放线程，最终形成死锁。</p><p><strong>原因分析</strong>：</p><ol><li><strong>线程池资源竞争</strong><br> 父任务占用了线程池的所有线程，子任务因无可用线程而被放入队列等待。</li><li><strong>父任务等待子任务结果</strong><br> 父任务通过 <code>Future.get()</code> 等方法阻塞等待子任务完成，而子任务无法执行（因线程被父任务占用）。</li><li><strong>循环依赖</strong><br> 子任务需要父任务释放线程才能执行，父任务需要子任务完成才能释放线程，形成死锁。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.concurrent.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DeadlockDemo</span> &#123;</span><br><span class="line">    <span class="comment">// 创建固定大小为2的线程池（关键点：线程池过小）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">ExecutorService</span> <span class="variable">executor</span> <span class="operator">=</span> Executors.newFixedThreadPool(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 提交父任务</span></span><br><span class="line">        executor.submit(() -&gt; parentTask(<span class="string">&quot;Parent-1&quot;</span>));</span><br><span class="line">        executor.submit(() -&gt; parentTask(<span class="string">&quot;Parent-2&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">parentTask</span><span class="params">(String name)</span> &#123;</span><br><span class="line">        System.out.println(name + <span class="string">&quot; 开始执行&quot;</span>);</span><br><span class="line">        </span><br><span class="line">    <span class="comment">// 提交子任务，异步</span></span><br><span class="line">        Future&lt;?&gt; childFuture = executor.submit(() -&gt; &#123;</span><br><span class="line">            System.out.println(name + <span class="string">&quot; 的子任务开始执行&quot;</span>);</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Thread.sleep(<span class="number">100</span>); <span class="comment">// 模拟工作</span></span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException ignored) &#123;&#125;</span><br><span class="line">            System.out.println(name + <span class="string">&quot; 的子任务结束&quot;</span>);</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 父任务阻塞等待子任务完成（致命点）</span></span><br><span class="line">            childFuture.get(); </span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(name + <span class="string">&quot; 结束&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>过程分析</strong>：</p><p>假设线程池大小为2（如示例所示）：</p><ol><li><strong>初始状态</strong><ul><li><code>Parent-1</code> 占用线程1</li><li><code>Parent-2</code> 占用线程2</li></ul></li><li><strong>父任务提交子任务</strong><ul><li><code>Parent-1</code> 提交 <code>Child-1</code> → 进入任务队列</li><li><code>Parent-2</code> 提交 <code>Child-2</code> → 进入任务队列</li></ul></li><li><strong>父任务等待子任务</strong><ul><li><code>Parent-1</code> 调用 <code>childFuture.get()</code> → <strong>阻塞等待</strong> <code>Child-1</code> 执行</li><li><code>Parent-2</code> 调用 <code>childFuture.get()</code> → <strong>阻塞等待</strong> <code>Child-2</code> 执行</li></ul></li><li><strong>死锁形成</strong><ul><li>线程池中所有线程（线程1、2）都被父任务占用且处于阻塞状态</li><li>子任务（<code>Child-1</code>, <code>Child-2</code>）在队列中等待空闲线程</li><li>但父任务不释放线程 → 子任务永远得不到执行 → 父任务永远等不到结果</li></ul></li></ol><p>这种情况下，只有当工作队列是有界的，且父任务在阻塞前提交多个子任务使工作队列被占满，从而创建新线程才有可能让死锁解开。（有一种父子任务共用线程池不会出现死锁的情况——队列是 SynchronousQueue 这种无存储功能的）</p><p>在这种父子共用线程池的场景，建议有一个兜底的操作——在父任务在等待子任务结果时设置一个超时时间。虽然这个不能完全避免死锁的出现，但是可以避免永久死锁。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    childFuture.get(<span class="number">5</span>, TimeUnit.SECONDS);</span><br><span class="line">&#125; <span class="keyword">catch</span> (TimeoutException e) &#123;</span><br><span class="line">    <span class="comment">// 1. 取消卡住的子任务</span></span><br><span class="line">    childFuture.cancel(<span class="literal">true</span>); </span><br><span class="line">    <span class="comment">// 2. 记录错误/告警</span></span><br><span class="line">    log.error(<span class="string">&quot;子任务执行超时&quot;</span>, e);</span><br><span class="line">    <span class="comment">// 3. 执行备用方案</span></span><br><span class="line">    fallbackStrategy();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那怎么<strong>完全避免</strong>这种死锁呢：</p><ol><li>父任务和子任务用独立线程池；</li><li>避免阻塞等待，使用 <code>CompletableFuture</code> 异步回调</li></ol>]]></content>
      
      
      <categories>
          
          <category> 事故收集 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线程池 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GPG简单使用</title>
      <link href="/21a4bb4d997e/"/>
      <url>/21a4bb4d997e/</url>
      
        <content type="html"><![CDATA[<p>参考：<br><a href="https://wiki.archlinux.org/title/GnuPG">https://wiki.archlinux.org/title/GnuPG</a></p><p>介绍：GnuPG 是完整实现了 <a href="https://tools.ietf.org/html/rfc4880">RFC4880</a>（即PGP）所定义的 <a href="https://openpgp.org/about/">OpenPGP</a> 标准的自由软件。GnuPG 可以加密和签名你的数据和通讯信息，包含一个通用的密钥管理系统以及用于各种公钥目录的访问模块。GnuPG，简称 GPG，是一个易于与其它程序整合的命令行工具，拥有很多前端程序和函数库。GnuPG 还支持 S&#x2F;MIME 和 Secure Shell (ssh)。</p><h1 id="快速使用"><a href="#快速使用" class="headerlink" title="快速使用"></a>快速使用</h1><h2 id="加密解密"><a href="#加密解密" class="headerlink" title="加密解密"></a>加密解密</h2><p>使用非对称加解密：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg -r ECAMT -e 1.png </span><br></pre></td></tr></table></figure><p>使用对称加解密：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg -c 1.png </span><br></pre></td></tr></table></figure><p>查看：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ls</span> -l</span><br><span class="line">总计 12960</span><br><span class="line">-rw-r--r-- 1 ECAMT ECAMT 6633916 12月 8日 1.png</span><br><span class="line">-rw-r--r-- 1 ECAMT ECAMT 6634809  5月18日 1.png.gpg</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"><span class="comment"># 使用非对称加密</span></span><br><span class="line">file 1.png.gpg </span><br><span class="line">1.png.gpg: data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用对称加密</span></span><br><span class="line">file 1.png.gpg </span><br><span class="line">1.png.gpg: PGP symmetric key encrypted data - AES with 256-bit key salted &amp; iterated - SHA256 .</span><br></pre></td></tr></table></figure><p>无论哪种方式加都是使用 <code>-d</code> 解密（使用 <code>&gt;</code> 代替 <code>-o</code> 输出到 <code>2.png</code>）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg -d 1.png.gpg &gt; 2.png</span><br></pre></td></tr></table></figure><hr><p>使用例：加密归档文件</p><p>可以一口气完成归档压缩加密：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bsdtar -cf - -J &lt;path/direction&gt; | gpg -c &gt; &lt;xx.gpg&gt;</span><br></pre></td></tr></table></figure><blockquote><p>压缩应在加密前：加密后的数据是随机字节，难以被压缩。因此，若需压缩，务必先压缩再加密。</p></blockquote><blockquote><p>仍建议分开归档压缩和加密的步骤，如 <code>xz</code>（LZMA算法）在压缩数据时，其行为会受到输出目标的类型（文件 vs 管道）的影响，使用管道传输传递给gpg时，xz 使用流式压缩模式，每个数据块可能包含额外的头信息和校验值，导致最后的体积略大。</p></blockquote><h2 id="签名校验"><a href="#签名校验" class="headerlink" title="签名校验"></a>签名校验</h2><p>签名主要用于验证数据的完整性、来源真实性以及防止数据被篡改。</p><p>常用签名：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --output &lt;doc.sig&gt; --sign &lt;doc&gt;</span><br></pre></td></tr></table></figure><p>校验：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --verify &lt;doc.sig&gt;</span><br></pre></td></tr></table></figure><hr><p>使用例：git提交并签名</p><p>提交时签名：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -S --gpg-sign=ECAMT</span><br></pre></td></tr></table></figure><p>查看（需要提前导入公钥）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">log</span> --show-signature</span><br></pre></td></tr></table></figure><p>git设置为指定自动私钥签名（仍需要 <code>-S</code> 参数）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git config <span class="built_in">set</span> user.signingKey &lt;user-id&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 校验</span></span><br><span class="line">git config get user.signingKey &lt;user-id&gt;</span><br></pre></td></tr></table></figure><p>git设置每次自动签名：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config commit.gpgsign <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>电子邮件完整验证也能用到。</p><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><h1 id="主目录"><a href="#主目录" class="headerlink" title="主目录"></a>主目录</h1><p>GnuPG 套件将密钥环和私钥存储在 GnuPG 主目录，并从中读取配置。默认路径为 <code>~/.gnupg</code>。有两种方法可以改变主目录的路径：</p><ul><li>设置 <code>$GNUPGHOME</code> <a href="https://wiki.archlinuxcn.org/wiki/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F" title="环境变量">环境变量</a>。</li><li>使用 <code>--homedir</code> 参数，如 <code>$ gpg --homedir &lt;/path/to/dir&gt;</code></li></ul><p>默认情况下，<strong>主目录的<a href="https://wiki.archlinuxcn.org/wiki/Permissions" title="Permissions">权限</a>设置为 <code>700</code>，其包含的文件的权限设置为 <code>600</code></strong>。只有目录的所有者有权读取、写入和访问文件。这是出于安全目的，不应更改。如果此目录或其中的任何文件不遵循此安全措施，您将收到有关不安全文件和主目录权限的警告。</p><h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><p>GnuPG 的所有行为都可以通过命令行参数进行配置。对于您希望成为默认参数的参数，可以将它们添加到相应的配置文件中：</p><ul><li>gpg 检查 <code>gnupg_home/gpg.conf</code>（用户）和 <code>/etc/gnupg/gpg.conf</code>（全局）。由于 gpg 是 GnuPG 的主要入口点，因此大部分感兴趣的配置都在这里。请参阅 <a href="https://www.gnupg.org/documentation/manuals/gnupg/GPG-Options.html">GPG 选项</a> 获取可能的选项。</li><li>dirmngr 会检查 <code>gnupg_home/dirmngr.conf</code> 和 <code>/etc/gnupg/dirmngr.conf</code> 两个配置文件。dirmngr 是由 gpg 内部调用的程序，用于访问 PGP 密钥服务器。请参阅 <a href="https://www.gnupg.org/documentation/manuals/gnupg/Dirmngr-Options.html">Dirmngr 选项</a> 以了解可能的选项。</li></ul><p>这两个配置文件涵盖了常见用例，但 GnuPG  套件中还有更多带有自己选项的辅助程序。请参阅 <a href="https://www.gnupg.org/documentation/manuals/gnupg/index.html">GnuPG 手册</a> 获取详细列表。</p><p>创建所需的文件，并按照 主目录 章节中讨论的方法设置其权限为600。</p><p>在这些文件中添加任何你想要的长选项。不要写两个破折号，只需写选项的名称和所需的参数。例如，要始终使GnuPG在特定路径上使用密钥环，就像使用 <code>gpg --no-default-keyring --keyring keyring-path ...</code> 调用它一样： </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gnupg_home/gpg.conf (或 /etc/gnupg/gpg.conf)</span><br><span class="line">---</span><br><span class="line">no-default-keyring</span><br><span class="line">keyring &lt;keyring-path&gt;</span><br></pre></td></tr></table></figure><h2 id="新用户的默认选项"><a href="#新用户的默认选项" class="headerlink" title="新用户的默认选项"></a>新用户的默认选项</h2><p>要给新建用户设定一些默认选项，把配置文件放到 <code>/etc/skel/.gnupg/</code>。系统创建新用户时，就会把文件复制到 GnuPG 目录。还有一个 <em>addgnupghome</em> 命令可以为已有用户创建新 GnuPG 主目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">addgnupghome user1 user2</span><br></pre></td></tr></table></figure><p>此命令会检查 <code>/home/user1/.gnupg/</code> 和 <code>/home/user2/.gnupg/</code>，并从 skeleton 目录复制文件过去。具有已存在的 GnuPG 主目录的用户只需跳过即可。</p><h1 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h1><blockquote><p>注意：</p><ul><li>如果需要一个 <em><code>user-id</code></em>，可以使用 key ID、指纹、用户名或电邮地址的部分等替代，GnuPG 对此的处理很灵活。</li><li>如果需要一个 <em><code>key-id</code></em>，可以给命令加上 <code>--keyid-format=long</code> 选项来查询。例如，如果想要查看主密匙，可以使用<code>gpg --list-secret-keys --keyid-format=long user-id</code>命令，<em>key-id</em> 是和 <em>sec</em> 同一行的十六进制散列值。</li></ul></blockquote><h2 id="创建密钥对"><a href="#创建密钥对" class="headerlink" title="创建密钥对"></a>创建密钥对</h2><p>用下面命令创建一个密钥对：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --full-gen-key</span><br></pre></td></tr></table></figure><p>使用 <code>--expert</code> 选项可以选择其它的加密算法，尤其是较新的<a href="https://zh.wikipedia.org/wiki/%E6%A4%AD%E5%9C%86%E6%9B%B2%E7%BA%BF%E5%AF%86%E7%A0%81%E5%AD%A6" title="zhwp:椭圆曲线密码学">ECC（椭圆曲线加密）</a>。</p><p>命令执行后会需要用户回答一些问题，大部分用户应该需要的是：</p><ul><li>默认的“RSA 和 RSA”用于加密和解密。</li><li>默认的密钥长度，即 3072。增大长度到 4096“成本极高，但获益很少”。<a href="https://www.gnupg.org/faq/gnupg-faq.html#no_default_of_rsa4096">这个帖子说明了为何 GPG 不默认使用 RSA-4096</a>。</li><li>过期日期。大部分用户可以选择一年。这样即使无法访问密钥环，用户也知道密钥已经过期。如果有需要，可以不重新签发密钥就延长过期时间。</li><li>用户名和电子邮件。可以给同样的密钥不同的身份，比如给同一个密钥关联多个电子邮件。</li><li><strong>不填写</strong>可选注释。注释字段并没有被<a href="https://lists.gnupg.org/pipermail/gnupg-devel/2015-July/030150.html">很好地定义</a>，作用有限。</li><li>一个安全的密钥口令。可参考<a href="https://wiki.archlinuxcn.org/wiki/Security#%E9%80%89%E6%8B%A9%E5%AE%89%E5%85%A8%E7%9A%84%E5%AF%86%E7%A0%81" title="Security">如何选择安全的密码</a>。</li></ul><blockquote><p>注意：任何导入密钥的人都可以看到这里的用户名和电子邮件地址。</p></blockquote><blockquote><p>提示：较简单的 <code>--gen-key</code> 选项对密钥类型、密钥长度、过期时间均使用默认值，仅询问姓名和电邮地址。</p></blockquote><h2 id="查看密钥"><a href="#查看密钥" class="headerlink" title="查看密钥"></a>查看密钥</h2><p>查看公钥：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --list-keys</span><br></pre></td></tr></table></figure><p>查看私钥:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --list-secret-keys</span><br></pre></td></tr></table></figure><h2 id="导出公钥"><a href="#导出公钥" class="headerlink" title="导出公钥"></a>导出公钥</h2><p>GPG 的主要用途是通过公钥加密信息以确保其私密性。你可以分发自己的公钥，而其他人通过该公钥加密发给你的信息。而你的私钥必须<strong>始终</strong>保密，否则将会威胁信息的私密性。相关内容，请参见<a href="https://zh.wikipedia.org/wiki/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86" title="zhwp:公开密钥加密">公开密钥加密</a>。</p><p>所以其他人需要有你的公钥才能给你发加密信息。</p><p>以下命令可生成公钥的 ASCII 版本（<code>--armor</code> 参数）（例如用于以电子邮件发布）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --<span class="built_in">export</span> --armor --output &lt;public-key.asc&gt; &lt;user-id&gt;</span><br></pre></td></tr></table></figure><p>此外，还可以通过<a href="https://wiki.archlinuxcn.org/wiki/GnuPG#%E4%BD%BF%E7%94%A8%E5%85%AC%E9%92%A5%E6%9C%8D%E5%8A%A1%E5%99%A8">密钥服务器</a>分发公钥。</p><blockquote><p>提示：</p><ul><li>使用 <code>--no-emit-version</code> 可以避免打印版本号，通过配置文件也可以进行此设置。</li><li>可以省略 <code>user-id</code> 以导出密钥环内所有的公钥。这可以用来分享多个身份，或是将其导入到另一个程序，比如 <a href="https://wiki.archlinuxcn.org/wiki/Thunderbird#Use_OpenPGP_with_external_GnuPG" title="Thunderbird">Thunderbird</a>。</li></ul></blockquote><h2 id="导入公共密钥"><a href="#导入公共密钥" class="headerlink" title="导入公共密钥"></a>导入公共密钥</h2><p>要给其他人发送加密信息，或者验证他们的签名，就需要他们的公钥。通过文件 <code>public.key</code> 导入公钥到密钥环：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --import &lt;public.key.asc&gt;</span><br></pre></td></tr></table></figure><p>此外，还可以通过<a href="https://wiki.archlinuxcn.org/wiki/GnuPG#%E5%AF%86%E9%92%A5%E6%9C%8D%E5%8A%A1%E5%99%A8">#密钥服务器</a>导入公钥。</p><h2 id="使用公钥服务器"><a href="#使用公钥服务器" class="headerlink" title="使用公钥服务器"></a>使用公钥服务器</h2><h3 id="发布公钥"><a href="#发布公钥" class="headerlink" title="发布公钥"></a>发布公钥</h3><p>你可以将你的公钥注册到一个公共的密钥服务器，这样其他人不用联系你就能获取到你的公钥：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --send-keys &lt;key-id&gt;</span><br></pre></td></tr></table></figure><blockquote><p>警告：一旦一个公钥被发送到密钥服务器，它就无法从服务器上删除。<a href="https://pgp.mit.edu/faq.html">这个网页</a>解释了原因。</p></blockquote><blockquote><p>注意：与公钥相关联的电邮地址一旦公开，可能会被垃圾邮件发送者盯上。请做好相应的防护措施。</p></blockquote><h3 id="搜索和接收公钥"><a href="#搜索和接收公钥" class="headerlink" title="搜索和接收公钥"></a>搜索和接收公钥</h3><p>要查询公钥的详细信息而不是导入，执行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --search-keys &lt;user-id&gt;</span><br></pre></td></tr></table></figure><p>要导入一个公钥：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --receive-keys &lt;key-id&gt;</span><br></pre></td></tr></table></figure><p>要使用密钥服务器中的最新版本刷新&#x2F;更新钥匙串：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --refresh-keys</span><br></pre></td></tr></table></figure><blockquote><p>警告：</p><ul><li>您应该通过将其指纹与所有者在独立来源（例如直接联系该人）上发布的指纹进行比较，以验证检索到的公钥的真实性。请参阅 <a href="https://en.wikipedia.org/wiki/Public_key_fingerprint" title="wikipedia:Public key fingerprint">Wikipedia:Public key fingerprint</a> 获取更多信息。</li><li>接收密钥时，建议使用长密钥 ID 或完整指纹。使用短密钥 ID 可能会导致冲突。所有具有短密钥 ID 的密钥都将被导入，参见 <a href="https://lore.kernel.org/lkml/20160815153401.9EC2BADC2C@smtp.postman.i2p/">在野外发现的伪密钥</a>作为示例。</li></ul></blockquote><blockquote><p>提示：将 <code>auto-key-retrieve</code> 添加到 <a href="https://wiki.archlinuxcn.org/wiki/GnuPG#Configuration_files">GPG 配置文件</a>中，将在需要时自动从密钥服务器获取密钥。这不会对安全性造成妥协，但可以被视为<strong>侵犯隐私</strong>；请参阅<a href="https://man.archlinux.org/man/gpg.1">gpg(1)</a>中的”web bug”。</p></blockquote><h3 id="公钥服务器"><a href="#公钥服务器" class="headerlink" title="公钥服务器"></a>公钥服务器</h3><p>常见的公钥服务器：</p><ul><li><a href="https://keyserver.ubuntu.com/">Ubuntu Keyserver</a>：联盟式（federated）、没有验证、公钥不可删除。</li><li><a href="https://keys.mailvelope.com/">Mailvelope Keyserver</a>：中心式、验证电邮 ID、公钥可删除。</li><li><a href="https://keys.openpgp.org/">keys.openpgp.org</a>：中心式、验证电邮 ID、公钥可删除、没有第三方签名（即不支持信任网络）。</li></ul><p><a href="https://en.wikipedia.org/wiki/Key_server_(cryptographic)#Keyserver_examples" title="wikipedia:Key server (cryptographic)">维基百科（英文）</a>上有更多的服务器。</p><p>备选公钥服务器可以在 配置文件 中的 <code>keyserver</code> 选项中注明，例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">~/.gnupg/dirmngr.conf</span><br><span class="line">---</span><br><span class="line">keyserver hkp://keyserver.ubuntu.com</span><br></pre></td></tr></table></figure><p>当常规服务器无法正常工作时，临时使用另一台服务器很方便。例如，可以通过以下方法实现：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --keyserver &lt;hkps://keys.openpgp.org/&gt; --search-keys &lt;user-id&gt;</span><br></pre></td></tr></table></figure><h1 id="加密与解密"><a href="#加密与解密" class="headerlink" title="加密与解密"></a>加密与解密</h1><h2 id="非对称加解密"><a href="#非对称加解密" class="headerlink" title="非对称加解密"></a>非对称加解密</h2><p>在加密（参数<code>--encrypt</code>或<code>-e</code>）一个文件或一条信息给另外一个人（参数<code>--recipient</code>或<code>-r</code>）之前，你需要先导入他的公钥。如果你还没有创建自己的密钥对，请先创建。</p><p>要加密一个名为 doc 的文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --recipient &lt;user-id&gt; --encrypt &lt;doc&gt;</span><br></pre></td></tr></table></figure><p>要解密（参数 <code>--decrypt</code> 或 <code>-d</code>）一个用你的公钥加密的、名为 <em>doc</em>.gpg 的文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --output &lt;doc&gt; --decrypt &lt;doc.gpg&gt;</span><br></pre></td></tr></table></figure><p><em>gpg</em> 会提示你输入密钥口令，并将 <em>doc</em>.gpg 中的数据解密到 <em>doc</em>。如果你忽略了参数 <code>-o</code>（<code>--output</code>），<em>gpg</em> 将会直接输出解密的信息。</p><blockquote><p>提示：</p><ul><li>使用参数 <code>--armor</code> 以 ASCII 编码的形式加密文件（适用于复制与粘贴文本文件格式的消息）。</li><li>使用 <code>-R &lt;user-id&gt;</code> 或 <code>--hidden-recipient &lt;user-id&gt;</code> 代替 <code>-r</code> 可以不将收件人的指纹 ID 放入加密的消息中。这有助于隐藏收件人的信息，是针对流量分析的一个有限对策。</li><li>使用 <code>--no-emit-version</code> 以避免打印版本号。也可将相应配置添加到你的配置文件中。</li><li>你可以使用 GPG 将自己作为收件人来加密敏感文件，但是每次只能压缩一个文件——尽管你可以将多个文件压缩后再进行加密。如果需要加密一个目录或一整个文件系统，请参见 <a href="https://wiki.archlinuxcn.org/wiki/Data-at-rest_encryption#Available_methods" title="Data-at-rest encryption">Data-at-rest encryption#Available methods</a>。</li></ul></blockquote><h2 id="对称加解密"><a href="#对称加解密" class="headerlink" title="对称加解密"></a>对称加解密</h2><p>对称加密不需要生成密钥对，可用来简单地给文件加上密码。使用 <code>-c</code>&#x2F;<code>--symmetric</code> 参数来进行对称加密：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg -c &lt;doc&gt;</span><br></pre></td></tr></table></figure><p>下面的例子：</p><ul><li>用口令给 <code>doc</code> 进行了对称加密</li><li>用 AES-256 加密算法对口令进行加密</li><li>用 SHA-512 摘要算法对口令进行打乱</li><li>打乱 65536 次</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg -c --s2k-cipher-algo AES256 --s2k-digest-algo SHA512 --s2k-count 65536 doc</span><br></pre></td></tr></table></figure><p>下面的命令可解密以口令对称加密的 <code>doc.gpg</code> 文件，并将解密的文档输出到同一目录下的 <code>doc</code> 文件中：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --output &lt;doc&gt; --decrypt &lt;doc&gt;.gpg</span><br></pre></td></tr></table></figure><p>解密时有时不需要输入密码，原因是 gpg-agent 缓存了。</p><h2 id="目录操作"><a href="#目录操作" class="headerlink" title="目录操作"></a>目录操作</h2><p>可用 <a href="https://man.archlinux.org/man/gpgtar.1">gpgtar(1)</a> 对目录进行加密和解密。</p><p>加密：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpgtar -c -o &lt;dir.gpg&gt; &lt;<span class="built_in">dir</span>&gt;</span><br></pre></td></tr></table></figure><p>解密：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpgtar -d &lt;dir.gpg&gt;</span><br></pre></td></tr></table></figure><h1 id="签名"><a href="#签名" class="headerlink" title="签名"></a>签名</h1><p>签名用于认证和时间戳文档。如果文档被修改，验证签名将失败。与使用公钥加密文档不同，签名是使用用户的私钥创建的。文档的接收者然后使用发送者的公钥验证签名。</p><h2 id="签署文件"><a href="#签署文件" class="headerlink" title="签署文件"></a>签署文件</h2><p>要签署文件，请使用<code>-s</code>&#x2F;<code>--sign</code>标志：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --output &lt;doc.sig&gt; --sign &lt;doc&gt;</span><br></pre></td></tr></table></figure><p><code>doc.sig</code>包含原始文件<code>doc</code>的压缩内容和以二进制格式表示的签名，但文件并未加密。但是，您可以将签名与加密结合使用。</p><h2 id="以可读形式签名文件或消息"><a href="#以可读形式签名文件或消息" class="headerlink" title="以可读形式签名文件或消息"></a>以可读形式签名文件或消息</h2><p>要签署文件而无需将其压缩为二进制格式，请使用：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --output &lt;doc&gt;.sig --clearsign &lt;doc&gt;</span><br></pre></td></tr></table></figure><p>在这里，原始文件<code>doc</code>的内容和签名以可读形式存储在<code>doc.sig</code>中。</p><h2 id="创建独立的签名文件"><a href="#创建独立的签名文件" class="headerlink" title="创建独立的签名文件"></a>创建独立的签名文件</h2><p>要创建一个单独的签名文件，以便与文档或文件本身份开分发，请使用<code>--detach-sig</code>标志：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --output &lt;doc.sig&gt; --detach-sig &lt;doc&gt;</span><br></pre></td></tr></table></figure><p>在这里，签名存储在<code>doc.sig</code>中，但<code>doc</code>的内容不会存储在其中。这种方法常用于分发软件项目，以允许用户验证程序未被第三方修改。</p><h2 id="验证签名"><a href="#验证签名" class="headerlink" title="验证签名"></a>验证签名</h2><p>要验证签名，请使用<code>--verify</code>标志：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --verify &lt;doc.sig&gt;</span><br></pre></td></tr></table></figure><p>其中<code>doc.sig</code>是包含您要验证的签名的已签名文件。</p><p>如果您要验证一个已分离签名，验证时必须同时存在已签名的数据文件和签名文件。例如，要验证 Arch Linux 的最新 iso 文件，您可以执行以下操作：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --verify &lt;archlinux-version.iso.sig&gt;</span><br></pre></td></tr></table></figure><p>其中<code>archlinux-version.iso</code>必须位于相同的目录中。</p><p>您还可以使用第二个参数指定已签名的数据文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --verify &lt;archlinux-version.iso.sig&gt; &lt;/path/to/archlinux-version.iso&gt;</span><br></pre></td></tr></table></figure><p>如果一个文件除了被签名外还被加密，只需<a href="https://wiki.archlinuxcn.org/wiki/GnuPG#%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86">解密</a>该文件，其签名也将被验证。</p><h1 id="密钥维护"><a href="#密钥维护" class="headerlink" title="密钥维护"></a>密钥维护</h1><h2 id="备份你的私钥"><a href="#备份你的私钥" class="headerlink" title="备份你的私钥"></a>备份你的私钥</h2><p>用如下命令备份你的私钥。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --export-secret-keys --armor --output &lt;private-key.asc&gt; &lt;user-id&gt;</span><br></pre></td></tr></table></figure><p>请注意，上述命令将要求您输入密钥的密码。这是因为，否则任何获得上述导出文件访问权限的人都可以像您一样对文档进行加密和签名，而无需知道您的密码。</p><p><strong>警告：</strong></p><ul><li>口令通常是密钥安全方面最薄弱的环节。最好把导出的文件放在另一个系统或者设备里，比如物理保险柜或者加密驱动器中。这是当你遇到设备被盗、磁盘故障等情况时恢复对密钥控制权的唯一安全措施。</li><li>这种备份方式有一些安全局限性，这篇文章 <a href="https://web.archive.org/web/20210803213236/https://habd.as/post/moving-gpg-keys-privately/">https://web.archive.org/web/20210803213236/https://habd.as/post/moving-gpg-keys-privately/</a> 中有关于用 <em>gpg</em> 备份和导入密钥的更加安全的办法。</li></ul><p>用如下命令导入你的私钥备份</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --import &lt;private-key.asc&gt;</span><br></pre></td></tr></table></figure><p><strong>提示：</strong> 你可以用 <a href="https://wiki.archlinuxcn.org/wiki/Paperkey" title="Paperkey">Paperkey</a> 来把私钥导出为明文文本或条形码，并打印出来存档。</p><h2 id="备份你的吊销证书"><a href="#备份你的吊销证书" class="headerlink" title="备份你的吊销证书"></a>备份你的吊销证书</h2><p>若使用gpg公钥服务器</p><p>生成新密钥对的时候会同时生成吊销证书，默认存放在 <code>~/.gnupg/openpgp-revocs.d/</code> 下，证书的文件名是对应的密钥的指纹。 你也可以用以下命令手动生成吊销证书：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --gen-revoke --armor --output &lt;revcert.asc&gt; &lt;user-id&gt;</span><br></pre></td></tr></table></figure><p>如果密钥丢失或泄露，此证书可用于 <a href="https://wiki.archlinuxcn.org/wiki/GnuPG#%E5%90%8A%E9%94%80%E5%AF%86%E9%92%A5">#吊销密钥</a>。如果你无法访问密钥，则无法使用上述命令生成新的吊销证书，那么备份将非常有用。吊销证书很短，你可以把他打印出来然后在需要使用的时候手动输入到电脑里。</p><blockquote><p>警告：任何能接触到吊销证书的人都可以吊销你的密钥对，而且无法撤消。所以请像保护私钥一样保护你的吊销证书。</p></blockquote><h2 id="编辑你的密钥"><a href="#编辑你的密钥" class="headerlink" title="编辑你的密钥"></a>编辑你的密钥</h2><p>运行 <code>gpg --edit-key &lt;user-id&gt;</code> 命令将会出现一个菜单，该菜单使你能够执行大部分密钥管理相关的任务。</p><p>在编辑密钥子菜单中输入 <code>help</code> 命令可以显示完整的命令列表。以下是一些有用的命令：</p><blockquote><p>passwd       # 修改密码短语<br>clean        # 压缩任何不再可用的用户ID（例如已撤销或已过期）<br>revkey       # 撤销密钥<br>addkey       # 向该密钥添加子密钥<br>expire       # 更改密钥过期时间<br>adduid       # 添加附加的名称、注释和电子邮件地址<br>addphoto     # 向密钥添加照片（必须是JPG格式，推荐大小为240x288，当提示时输入完整路径）</p></blockquote><blockquote><p>提示：如果你有多个电子邮件账户，你可以使用 <code>adduid</code> 命令将每个账户都添加为一个身份。然后你可以将你最喜欢的账户设置为 <code>primary</code>。</p></blockquote><h2 id="删除密钥对"><a href="#删除密钥对" class="headerlink" title="删除密钥对"></a>删除密钥对</h2><p>删除私钥：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --delete-secret-key &lt;user-id&gt;</span><br></pre></td></tr></table></figure><p>删除私钥后，需单独删除公钥：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --delete-key &lt;user-id&gt;</span><br></pre></td></tr></table></figure><p>校验：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gpg --list-keys</span><br><span class="line">gpg --list-secret-keys</span><br></pre></td></tr></table></figure><h1 id="gpg-agent"><a href="#gpg-agent" class="headerlink" title="gpg-agent"></a>gpg-agent</h1><p><em>gpg-agent</em> 主要用作守护进程，用于请求和缓存密钥链的密码。这在外部程序（如邮件客户端）使用 GnuPG 时十分有用。 <a href="https://archlinux.org/packages/?name=gnupg">gnupg</a>包 带有默认自动启动的 <a href="https://wiki.archlinuxcn.org/wiki/Systemd/%E7%94%A8%E6%88%B7" title="Systemd&#x2F;用户">systemd&#x2F;用户</a>套接字。这些套接字分别是 <code>gpg-agent.socket</code>、<code>gpg-agent-extra.socket</code>、<code>gpg-agent-browser.socket</code>、<code>gpg-agent-ssh.socket</code> 和 <code>dirmngr.socket</code>。</p><ul><li><em>gpg</em> 使用 <code>gpg-agent.socket</code> 连接到 <em>gpg-agent</em> 守护进程。</li><li><code>gpg-agent-extra.socket</code> 的作用是在本地建立一个转发自远程系统的 Unix 域套接字。这样就可以在远程系统上使用 <em>gpg</em>，而无需向远程系统公开私钥。有关详细信息，请参阅 <a href="https://man.archlinux.org/man/gpg-agent.1">gpg-agent(1)</a>。</li><li><code>gpg-agent-browser.socket</code> 允许 Web 浏览器访问 <em>gpg-agent</em> 守护进程。</li><li><a href="https://wiki.archlinuxcn.org/wiki/SSH" title="SSH">SSH</a> 使用 <code>gpg-agent-ssh.socket</code> 缓存 <em>ssh-add</em> 程序添加的 <a href="https://wiki.archlinuxcn.org/wiki/SSH_keys" title="SSH keys">SSH keys</a>。有关必要的配置，请参阅 <a href="https://wiki.archlinuxcn.org/wiki/GnuPG#SSH_agent">#SSH agent</a>。</li><li><code>dirmngr.socket</code> 启动一个 GnuPG 守护进程来处理与 keyserver 的连接。</li></ul><blockquote><p>注意：如果您没有使用默认的 GnuPG <a href="https://wiki.archlinuxcn.org/wiki/GnuPG#%E7%9B%AE%E5%BD%95%E4%BD%8D%E7%BD%AE">#目录位置</a>, 您需要<a href="https://wiki.archlinuxcn.org/wiki/Systemd#%E4%BF%AE%E6%94%B9%E7%8E%B0%E5%AD%98%E5%8D%95%E5%85%83%E6%96%87%E4%BB%B6" title="Systemd">编辑</a>所有套接字文件让其使用 <code>gpgconf --list-dirs</code> 的值。 套接字名称使用 <a href="https://github.com/gpg/gnupg/blob/260bbb4ab27eab0a8d4fb68592b0d1c20d80179c/common/homedir.c#L710-L713">非默认 GnuPG 主目录的哈希</a>，您可以硬编码它不用担心它的改变。</p></blockquote><h2 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h2><p>gpg-agent 用 <code>~/.gnupg/gpg-agent.conf</code> 文件配置。配置选项列在 <a href="https://man.archlinux.org/man/gpg-agent.1">gpg-agent(1)</a> 中。例如，您可以更改默认密钥的缓存 ttl：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">~/.gnupg/gpg-agent.conf</span><br><span class="line">---</span><br><span class="line">default-cache-ttl 3600</span><br></pre></td></tr></table></figure><blockquote><p>提示：要缓存整个会话的密码(passphrase)，请运行以下命令：</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/lib/gnupg/gpg-preset-passphrase --preset XXXXX</span><br></pre></td></tr></table></figure><p>其中 XXXXX 是 keygrip。您可以在运行 <code>gpg --with-keygrip -K</code> 时获取它的值。密码(passphrase)将一直保存到 <code>gpg-agent</code> 重新启动为止。如果设置了 <code>default-cache-ttl</code> 值，会优先采用它。</p><p>在 Linux 中，为了允许预设的密码短语，需要通过使用 <code>--allow-preset-passphrase</code> 启动 gpg-agent，或在 <code>~/.gnupg/gpg-agent.conf</code> 中设置<code>allow-preset-passphrase</code>。</p><h2 id="重新加载-gpg-agent"><a href="#重新加载-gpg-agent" class="headerlink" title="重新加载 gpg-agent"></a>重新加载 gpg-agent</h2><p>在修改完配置之后，用 <em>gpg-connect-agent</em> 重新加载 gpg-agent：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg-connect-agent reloadagent /bye</span><br></pre></td></tr></table></figure><p>该命令应该输出 <code>OK</code>。</p><p>但是在某些情况下，只是重新启动可能不够，比如当 <code>keep-screen</code> 被添加到 gpg-agent 配置中时。在这种情况下，您首先需要终止正在进行的 gpg-agent 进程，然后按上述方法重新启动它。</p><h2 id="pinentry"><a href="#pinentry" class="headerlink" title="pinentry"></a>pinentry</h2><p><code>gpg-agent</code> 可以在 <code>pinentry-program</code> 中设定，以便使用特定的 <a href="https://archlinux.org/packages/?name=pinentry">pinentry</a>包 用户界面来提示用户输入(passphrase)。例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">~/.gnupg/gpg-agent.conf</span><br><span class="line">---</span><br><span class="line">pinentry-program /usr/bin/pinentry-curses</span><br></pre></td></tr></table></figure><p>还有其他 pinentry 程序可选，参考 <code>pacman -Ql pinentry | grep /usr/bin/</code> 的输出结果。</p><blockquote><p>提示：</p><ul><li>为了使用 <code>/usr/bin/pinentry-kwallet</code> 您需要安装软件包 <a href="https://aur.archlinux.org/packages/kwalletcli/">kwalletcli</a>AUR。</li><li>所有的默认 pinentry 程序（除了 <code>/usr/bin/pinentry-emacs</code>）都支持 <a href="https://specifications.freedesktop.org/secret-service/">DBus Secret Service API</a> ，它允许通过一个兼容的管理器(如 <a href="https://wiki.archlinuxcn.org/wiki/GNOME_Keyring" title="GNOME Keyring">GNOME Keyring</a> 或 <a href="https://wiki.archlinuxcn.org/wzh/index.php?title=KeePass&action=edit&redlink=1" title="KeePass（页面不存在）">KeePassXC</a>)记住密码。</li></ul></blockquote><p>记得在修改完配置后要<a href="https://wiki.archlinuxcn.org/wiki/GnuPG#%E9%87%8D%E6%96%B0%E5%8A%A0%E8%BD%BD_gpg-agent">#重新加载 gpg-agent</a>。</p><h2 id="缓存密码"><a href="#缓存密码" class="headerlink" title="缓存密码"></a>缓存密码</h2><p><code>max-cache-ttl</code> 和 <code>default-cache-ttl</code> 定义 gpg-agent 的密码缓存时间（秒）。要在会话中只输入一次密码，设置一个非常高的值即可，例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gpg-agent.conf</span><br><span class="line">---</span><br><span class="line">max-cache-ttl 60480000</span><br><span class="line">default-cache-ttl 60480000</span><br></pre></td></tr></table></figure><p>对于 SSH 仿真模式下的密码缓存，需要设置 <code>default-cache-ttl-ssh</code> 和 <code>max-cache-ttl-ssh</code>，例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gpg-agent.conf</span><br><span class="line">---</span><br><span class="line">default-cache-ttl-ssh 60480000</span><br><span class="line">max-cache-ttl-ssh 60480000</span><br></pre></td></tr></table></figure><h2 id="Unattended-passphrase"><a href="#Unattended-passphrase" class="headerlink" title="Unattended passphrase"></a>Unattended passphrase</h2><p>从 GnuPG 2.1.0 开始，需要使用 gpg-agent 和 pinentry，这可能会破坏使用 <code>--passphrase-fd 0</code> 命令行选项从 STDIN 传入的密码短语的向后兼容性。为了拥有与旧版本相同类型的功能，必须做两件事：</p><p>首先，编辑 gpg-agent 配置允许 <em>loopback</em> pinentry 模式 :</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">~/.gnupg/gpg-agent.conf</span><br><span class="line">---</span><br><span class="line">allow-loopback-pinentry</span><br></pre></td></tr></table></figure><p>如果 gpg-agent 正在运行，<a href="https://wiki.archlinuxcn.org/wiki/GnuPG#%E9%87%8D%E6%96%B0%E5%8A%A0%E8%BD%BD_gpg-agent">重新加载</a>它使配置生效。</p><p>其次，要么应用程序需要更新，以包括一个命令行参数来使用回环模式，例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpg --pinentry-mode loopback ...</span><br></pre></td></tr></table></figure><p>如果不可能这样做，则可以将选项添加到配置中：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">~/.gnupg/gpg.conf</span><br><span class="line">---</span><br><span class="line">pinentry-mode loopback</span><br></pre></td></tr></table></figure><blockquote><p>上游作者指出，在 <code>gpg.conf</code> 中设置 <code>pinentry-mode loopback</code> 可能会破坏其他用法，如果可能，最好使用命令行选项。<br><a href="https://dev.gnupg.org/T1772">https://dev.gnupg.org/T1772</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> GNU/Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GPG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CAP与分布式系统</title>
      <link href="/fa2bcf65db26/"/>
      <url>/fa2bcf65db26/</url>
      
        <content type="html"><![CDATA[<p>参考：<br><a href="https://ieeexplore.ieee.org/abstract/document/6133253">https://ieeexplore.ieee.org/abstract/document/6133253</a><br><a href="https://www.infoq.cn/article/cap-twelve-years-later-how-the-rules-have-changed/">https://www.infoq.cn/article/cap-twelve-years-later-how-the-rules-have-changed/</a></p><p>CAP理论三个特性：</p><ul><li><p>一致性（Consistency，C）：所有节点在同一时间看到相同的数据。</p></li><li><p>高可用（High Availability，A）：所有请求（读&#x2F;写）都能在合理时间内得到响应，即使部分节点出现故障。系统始终对外提供服务，不拒绝请求，但响应结果可能是旧数据或临时状态。</p></li><li><p>分区容忍性（Network Partition tolerance，P）：网络分区（Network Partition）发生时，导致部分节点之间通信中断，系统也不会停止服务，仍能继续运行。</p></li></ul><h1 id="“三选二”的表述过于简化，忽略了分区（P）的必然性"><a href="#“三选二”的表述过于简化，忽略了分区（P）的必然性" class="headerlink" title="“三选二”的表述过于简化，忽略了分区（P）的必然性"></a>“三选二”的表述过于简化，忽略了分区（P）的必然性</h1><p>P 是 Network Partition tolerance，指的是要求分布式系统中存在部分节点、子网路无法访问时，系统依然能正常提供服务。</p><p>CAP“三选二”的说法本身具有一定误导性。CAP被广泛描述为“一致性、可用性、分区容忍性三者只能选其二”，但这种表述容易让人误以为分区（P）是一个可选项，甚至可以完全避免。</p><p>如果 P 可以舍弃，就有两种可能：  </p><ol><li>网路绝对可靠、系统中没有节点会出错（现实世界绝对不可能，除非单个节点）</li><li>当分区事件出现，系统不再正常提供服务（集群单个节点出现问题，整个系统停止）</li></ol><p>实际上，<strong>分区（P）是分布式系统中必须接受的现实</strong>。网络故障、节点宕机、跨数据中心通信等问题在分布式系统中不可避免。因此，真正的选择是在一致性（C）和可用性（A）之间权衡，而不是“三选二”。</p><p>两个节点发生分区时且有具有分区容忍（P）的情况下，要么阻止数据写入（只读状态）以保证数据的一致性（CP系统）；要么允许部分节点写入而导致产生数据的不一致性（AP系统），由此网络分区（P）下的CA几乎不能完成。</p><h1 id="忽略了分区发生的频率和业务场景的灵活性"><a href="#忽略了分区发生的频率和业务场景的灵活性" class="headerlink" title="忽略了分区发生的频率和业务场景的灵活性"></a>忽略了分区发生的频率和业务场景的灵活性</h1><p>CAP理论被解读为“所有场景下只能选C或A”，但实际系统设计中，<strong>分区发生的频率远低于正常运行状态</strong>。</p><p><strong>在大多数时间，系统可以同时满足CA</strong>：<br>当网络分区未发生时，系统可以追求强一致性和高可用性（CA）。例如，单数据中心内的数据库集群在正常运行时，通常可以同时满足CA。</p><p><strong>分区时的动态权衡</strong>：<br>CAP理论的核心矛盾仅在分区发生时才显现。此时，系统需要根据业务需求选择CP或AP，而不是全局静态选择。</p><p>e.g.<br>Google Spanner通过强一致性（CP）设计，但在全球范围内极少发生分区（依赖专网和原子钟同步），因此在实际中可以“假装”是CA系统。</p><p>此外，当客户端和服务端发生分区时，高可用必是不存在的，服务无法对外提供访问。</p><h1 id="忽视了C和A的可量化性"><a href="#忽视了C和A的可量化性" class="headerlink" title="忽视了C和A的可量化性"></a>忽视了C和A的可量化性</h1><p>CAP理论被简化为“非此即彼”的二元对立（C vs. A），但实际上<strong>一致性和可用性都可以以不同粒度实现</strong>。</p><p><strong>一致性（C）的层级</strong>：<br>从强一致性（线性一致性）到最终一致性，存在多种中间状态。例如，NoSQL数据库支持“最终一致性”，而区块链使用“拜占庭容错”算法。</p><p><strong>可用性（A）的层级</strong>：<br>可用性并非100%的绝对值，而是可以量化为“99.99%可用”或“部分可用”。例如，12306订票系统在极端情况下允许“基本可用”，而非完全不可用。</p><p>e.g.<br>在电商系统中，购物车服务可以容忍短时间的数据不一致（AP），而支付服务必须保证强一致性（CP）。</p><h1 id="忽略了网络延迟和分布式系统的复杂性"><a href="#忽略了网络延迟和分布式系统的复杂性" class="headerlink" title="忽略了网络延迟和分布式系统的复杂性"></a>忽略了网络延迟和分布式系统的复杂性</h1><p>CAP理论的原始表述<strong>忽略了网络延迟和数据复制的时间开销</strong>，导致对一致性的理解过于理想化。</p><p><strong>网络延迟的必然性</strong>：<br>即使在无分区的情况下，数据从节点A复制到节点B也需要时间。CAP理论中的“一致性”要求数据瞬间同步，这在现实中是不可能的。我们无法判断是网络延迟导致节点间无法通讯还是网络分区导致的。<br>此时有两个选择，一个是继续等待，另一个是忽略风险继续操作。如：Paxos将会无限地将决策进行延期（CP）。</p><p><strong>PACELC理论</strong>（Partition-tolerance, Availability, Consistency Else Latency, Consistency）扩展了CAP，指出：</p><ul><li><strong>当发生分区时</strong>（P），在A和C之间权衡；</li><li><strong>当无分区时</strong>（E），在延迟（L）和一致性（C）之间权衡。例如，MySQL在无分区时通过主从复制实现高一致性，但需要容忍一定的延迟。</li></ul><h1 id="忽视了工程实践中的折中方案"><a href="#忽视了工程实践中的折中方案" class="headerlink" title="忽视了工程实践中的折中方案"></a>忽视了工程实践中的折中方案</h1><p>CAP理论被解读为“必须严格选择CP或AP”，但实际系统设计中存在大量<strong>折中策略</strong>。</p><p><strong>混合架构</strong>：<br>系统可以针对不同模块选择不同的策略。例如，金融交易模块选择CP（强一致性），而推荐系统模块选择AP（高可用性）。</p><p><strong>算法优化</strong>：<br>通过Paxos、Raft等共识算法，在分区发生时实现“最终一致性”，既保障可用性，又逐步恢复一致性。</p><h1 id="管理网络分区"><a href="#管理网络分区" class="headerlink" title="管理网络分区"></a>管理网络分区</h1><p>系统设计者的挑战在于缓和系统分区对一致性和可用性带来的影响。核心思路是显式地管理网络分区，不仅包括探测，还需要一个特定的恢复程序，以及一个计划来应对分区过程中系统不变性被打破的情况。这个管理过程有三个步骤：</p><ul><li>特测到分区的发生</li><li>进入显式的分区状态，并限制部分操作</li><li>当通信恢复时，启动分区恢复过程</li></ul><p>最后一步的作用是重建一致性，并为系统分区时程序造成的错误进行补偿。</p><p>分区的演化过程：正常的操作由一系列原子操作构成，因而分区总是出现在操作之间。一旦系统发现超时，便检测到了分区，而发现分区的这一侧进入分区状态。如果分区确实存在，那么分区的两侧都会进入分区模式，不过单侧分区也不是不可能。在这种情况下，对侧根据需要发起通信，本侧可能正常回复，也可能不需要回复，这两种情况都能保持一致性。不过，由于感知到分区的一侧有可能会发生不一致的操作，所以其必须进入分区模式。使用“众数”机制的系统就是单侧分区的例子。一侧拥有众数，可以正常工作，而另一侧不行。支持离线操作的系统显然有分区模式的概念，有些原子广播的系统，比如Java的JGroups也是一样。</p><p>设计系统中进行分区管理需要考虑的问题：<br>问题1：哪些操作可以继续，哪些操作在分区合并之后仍然保证其准确性？<br>问题2：分区恢复时如何合并分区？<br>问题3：如何补偿在分区阶段造成的错误？</p><hr><p>e.g.<br>ATM机上的补偿问题<br>在ATM（自动柜员机）的设计中，强一致性看似符合逻辑的选择，但现实情况是可用性远比一致性重要。理由很简单：高可用性意味着高收入。不管怎么样，讨论如何补偿分区期间被破坏的不变性约束，ATM 的设计很适合作为例子。</p><p>ATM 的基本操作是存款、取款、查看余额。关键的不变性约束是余额应大于或等于零。因为只有取款操作会触犯这项不变性约束，也就只有取款操作将受到特别对待，其他两种操作随时都可以执行。</p><p>ATM 系统设计师可以选择在分区期间禁止取款操作，因为在那段时间里没办法知道真实的余额，当然这样会损害可用性。现代 ATM 的做法正相反，在 stand-in 模式下（即分区模式），ATM 限制净取款额不得高于 k，比如 k 为 $200。低于限额的时候，取款完全正常；当超过限额的时候，系统拒绝取款操作。这样，ATM 成功将可用性限制在一个合理的水平上，既允许取款操作，又限制了风险。</p><p>分区结束的时候，必须有一些措施来恢复一致性和补偿分区期间系统所造成的错误。状态的恢复比较简单，因为操作都是符合交换率的，补偿就要分几种情况去考虑。最后的余额低于零违反了不变性约束。由于 ATM 已经把钱吐出去了，错误成了外部实在。银行的补偿办法是收取透支费并指望顾客偿还。因为风险已经受到限制，问题并不严重。还有一种情况是分区期间的某一刻余额已经小于零（但 ATM 不知道），此时一笔存款重新将余额变为正的。银行可以追溯产生透支费，也可以因为顾客已经缴付而忽略该违反情况。</p><p>总的来说，由于通信的延迟，银行系统并不依靠一致性来获取正确性，而是基于审计和补偿。另一个例子是支票风筝（check kiting），意思是客户从多个支行取走现金，在它们彼此通信之前就溜之大吉。这种透支后面会被抓到，并导致法律层面上的补偿。</p><hr><p>e.g.<br>飞机上刷Visa卡的过程可以被视为网络分区的一个体现，飞机在飞行中通常无法连接地面网络（如国际航班无蜂窝网络），导致支付终端与银行系统之间形成逻辑网络分区。其实这个过程与ATM机的例子差不多。</p><p>策略1：可用性优先（AP系统）</p><ul><li>分区期间的操作：飞机上的支付终端可能允许乘客离线刷卡（如预授权模式），记录交易数据并暂存。例如，某些航班允许乘客购买餐食或商品，飞行前冻结一定金额，确保乘客在飞行中刷卡时账户余额足够。分区恢复后，银行根据实际消费金额调整冻结金额。（Pre-Authorization）。</li><li>分区恢复后的补偿：飞机着陆后，终端通过地面网络将交易数据批量上传至银行系统。若账户余额不足或卡片无效，银行需通过补偿机制修正错误。如：重复交易补偿、透支处理。</li></ul><p>策略2：一致性优先（CP系统）</p><ul><li>分区期间的限制：若系统强制要求实时验证（如高风险交易），则分区期间可能拒绝所有刷卡请求，牺牲可用性。例如，某些航班仅允许现金支付，或禁止高额度信用卡交易。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术理论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CAP </tag>
            
            <tag> 分布式系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL架构及SQL执行流程、优化</title>
      <link href="/3a827e313e2d/"/>
      <url>/3a827e313e2d/</url>
      
        <content type="html"><![CDATA[<p>参考：<br><a href="https://developer.aliyun.com/article/1575323">全解MySQL之架构篇：自顶向下深入剖析MySQL整体架构！</a><br><a href="https://xiaolincoding.com/mysql/base/how_select.html#%E7%AC%AC%E4%BA%8C%E6%AD%A5-%E6%9F%A5%E8%AF%A2%E7%BC%93%E5%AD%98">执行一条 select 语句，期间发生了什么？</a><br><a href="https://javaguide.cn/database/mysql/how-sql-executed-in-mysql.html">SQL语句在MySQL中的执行过程</a><br><a href="https://github.com/alibaba/p3c/blob/master/Java%E5%BC%80%E5%8F%91%E6%89%8B%E5%86%8C%28%E9%BB%84%E5%B1%B1%E7%89%88%29.pdf">Java开发手册(黄山版)</a><br><a href="https://www.cnblogs.com/juno3550/p/14887672.html">MySQL 慢 SQL &amp; 优化方案</a><br><a href="https://developer.aliyun.com/article/1008410">老司机总结的12条 SQL 优化方案</a><br><a href="https://blog.csdn.net/guoqi_666/article/details/122484535">sql优化的15个小技巧</a></p><h1 id="一、MySQL架构"><a href="#一、MySQL架构" class="headerlink" title="一、MySQL架构"></a>一、MySQL架构</h1><p>MySQL Architecture with Pluggable Storage Engines:<br><a href="https://dev.mysql.com/doc/refman/8.4/en/images/mysql-architecture.png">https://dev.mysql.com/doc/refman/8.4/en/images/mysql-architecture.png</a><br><img src="https://dev.mysql.com/doc/refman/8.4/en/images/mysql-architecture.png"></p><p>从上往下看，依次会分为网络连接层、系统服务层、存储引擎层、以及文件系统层</p><ul><li>网络连接层：主要是指数据库连接池，会负责处理所有客户端接入的工作。</li><li>服务层：主要包含<code>SQL</code>接口、解析器、优化器以及缓存缓冲区四块区域。</li><li>存储引擎层：这里是指<code>MySQL</code>支持的各大存储引擎，如<code>InnoDB、MyISAM</code>等。</li><li>文件系统层：涵盖了所有的日志，以及数据、索引文件，位于系统硬盘上。</li></ul><h2 id="网络连接层"><a href="#网络连接层" class="headerlink" title="网络连接层"></a>网络连接层</h2><p>当一个客户端尝试与<code>MySQL</code>建立连接时，<code>MySQL</code>内部都会派发一条线程负责处理该客户端接下来的所有工作。而数据库的连接层负责的就是所有客户端的接入工作。若数据库连接建立成功，<code>MySQL</code>会“安排”一条线程维护当前客户端的连接，这条线程也会时刻标识着当前连接在干什么工作，可以通过<code>show processlist;</code>命令查询所有正在运行的线程及其工作详情。</p><p>连接建立成功后，<code>MySQL</code>与客户端之间会采用半双工的通讯机制工作。</p><blockquote><ul><li>全双工：代表通讯的双方在同一时间内，即可以发送数据，也可以接收数据。</li><li>半双工：代表同一时刻内，单方要么只能发送数据，要么只能接受数据。</li><li>单工：当前连接只能发送数据或只能接收数据，也就是“单向类型的通道”。</li></ul></blockquote><h3 id="数据库连接池"><a href="#数据库连接池" class="headerlink" title="数据库连接池"></a>数据库连接池</h3><p>每个客户端连接数据库都需要一条线程去维护，但创建新的线程是需要一定的资源消耗的，而且线程资源不可能无限量创建。</p><p><code>Connection Pool</code>的存在主要是为了复用线程、管理线程以及限制最大连接数的。一方面提升了性能，第二方面还节省了一定程度上的资源开销。</p><p>连接池的最大线程数可以通过参数<code>max-connections</code>来控制，如果到来的客户端连接超出该值时，新到来的连接都会被拒绝，关于最大连接数的一些命令主要有两条：</p><ul><li><code>show variables like &#39;%max_connections%&#39;;</code>：查询目前<code>DB</code>的最大连接数。</li><li><code>set GLOBAL max_connections = 200;</code>：修改数据库的最大连接数为指定值。</li></ul><p>对于不同的机器配置，可以适当的调整连接池的最大连接数大小，以此可以在一定程度上提升数据库的性能。除了可以查询最大连接数外，<code>MySQL</code>本身还会对客户端的连接数进行统计，对于这点可以通过命令<code>show status like &quot;Threads%&quot;;</code>查询。</p><h2 id="系统服务层"><a href="#系统服务层" class="headerlink" title="系统服务层"></a>系统服务层</h2><p><code>MySQL</code>大多数核心功能都位于这一层，包括客户端<code>SQL</code>请求解析、语义分析、查询优化、缓存以及所有的内置函数（例如：日期、时间、统计、加密函数…），所有跨引擎的功能都在这一层实现，譬如存储过程、触发器和视图等一系列服务。</p><p>主要包含<code>SQL</code>接口（SQL Interface）、解析器（Parser）、优化器（Optimizer）以及缓存（Caches&amp;Buffers）相关的这些部分。</p><h3 id="SQL接口"><a href="#SQL接口" class="headerlink" title="SQL接口"></a>SQL接口</h3><p><code>SQL</code>接口组件的主要作用就是负责处理客户端的<code>SQL</code>语句，当客户端连接建立成功之后，会接收客户端的<code>SQL</code>命令，比如<code>DML、DDL</code>语句以及存储过程、触发器等，当收到<code>SQL</code>语句时，<code>SQL</code>接口会将其分发给其他组件，然后等待接收执行结果的返回，最后会将其返回给客户端。</p><blockquote><p>简单来说，也就是<code>SQL</code>接口会作为客户端连接传递<code>SQL</code>语句时的入口，并且作为数据库返回数据时的出口。</p></blockquote><p>对于这个组件主要有两个作用，第一是对于<code>SQL</code>语句的类型划分，第二则是触发器。</p><p>根据<code>SQL</code>的不同的作用，<code>SQL</code>分为五大类：</p><ul><li><code>DML</code>：数据库操作语句，比如<code>update、delete、insert</code>等都属于这个分类。</li><li><code>DDL</code>：数据库定义语句，比如<code>create、alter、drop</code>等都属于这个分类。</li><li><code>DQL</code>：数据库查询语句，比如最常见的<code>select</code>就属于这个分类。</li><li><code>DCL</code>：数据库控制语句，比如<code>grant、revoke</code>控制权限的语句都属于这个分类。</li><li><code>TCL</code>：事务控制语句，例如<code>commit、rollback、setpoint</code>等语句属于这个分类。</li></ul><p>再来聊一聊<code>MySQL</code>的触发器，这东西估计大部分小伙伴没用过，但它在有些情景下还较为实用，不过想要了解触发器是什么，首先咱们还得先理解存储过程。</p><blockquote><p>存储过程：是指提前编写好的一段较为常用或复杂<code>SQL</code>语句，然后指定一个名称存储起来，然后先经过编译、优化，完成后，这个“过程”会被嵌入到<code>MySQL</code>中。</p></blockquote><p>也就是说，存储过程的本质就是一段预先写好并编译完成的<code>SQL</code>，而我们要聊的触发器则是一种特殊的存储过程，但 触发器 与 存储过程 的不同点在于：<strong>存储过程需要手动调用后才可执行，而触发器可由某个事件主动触发执行</strong>。<br>在<code>MySQL</code>中支持<code>INSERT、UPDATE、DELETE</code>三种事件触发，同时也可以通过<code>AFTER、BEFORE</code>语句声明触发的时机，是在操作执行之前还是执行之后。</p><blockquote><p>说简单一点，<code>MySQL触发器</code>就类似于<code>Spring</code>框架中的<code>AOP</code>切面。</p></blockquote><h3 id="解析器"><a href="#解析器" class="headerlink" title="解析器"></a>解析器</h3><p>客户端连接发送的<code>SQL</code>语句，经过<code>SQL</code>接口后会先被分发到解析器，解析器这东西其实在所有语言中都存在，<code>Java、C、Go...</code>等其他语言都有，解析器的作用主要是做词法分析、语义分析、语法树生成…这类工作的，<code>Java</code>源码在编写后，会经历这个过程，<code>SQL</code>语言同样类似。</p><p>而解析器这一步的作用主要是为了验证<code>SQL</code>语句是否正确，以及将<code>SQL</code>语句解析成<code>MySQL</code>能看懂的机器码指令。稍微拓展一点大家就明白了，好比如我们编写如下一条<code>SQL</code>：</p><blockquote><p><code>select * form user;</code></p></blockquote><p>然后运行会得到如下错误信息：</p><blockquote><p><code>ERROR 1064 (42000): You have an error in your SQL syntax; check....</code></p></blockquote><p>在上述<code>SQL</code>中，我们将<code>from</code>写成了<code>form</code>，结果运行时<code>MySQL</code>提示语法错误了，<code>MySQL</code>是如何发现的呢？就是在词法分析阶段，检测到了存在语法错误，因此抛出了对应的错误码及信息。当然，如果<code>SQL</code>正确，则会进行下一步工作，生成<code>MySQL</code>能看懂的执行指令。</p><h3 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h3><p>解析器完成相应的词法分析、语法树生成….等一系列工作后，紧接着会来到优化器，优化器的主要职责在于生成执行计划，比如选择最合适的索引，选择最合适的<code>join</code>方式等，最终会选择出一套最优的执行计划。</p><blockquote><p>当然，在这里其实有很多资料也会聊到，存在一个执行器的抽象概念，实际上执行器是不存在的，因此前面聊到过，每个客户端连接在<code>MySQL</code>中都用一条线程维护，而线程是操作系统的最小执行单位，因此所谓的执行器，本质上就是线程本身。</p></blockquote><p>优化器生成了执行计划后，维护当前连接的线程会负责根据计划去执行<code>SQL</code>，这个执行的过程实际上是在调用存储引擎所提供的<code>API</code>。</p><h3 id="缓存-缓冲"><a href="#缓存-缓冲" class="headerlink" title="缓存&amp;缓冲"></a>缓存&amp;缓冲</h3><p>这块主要分为了读取缓存与写入缓冲；</p><blockquote><p><code>mysql 8.0+</code>已经完全移除Caches模块，以下相关命令不起作用；<br>在我的<code>mariadb 10.6.21</code>中，这个功能还保留着；</p></blockquote><p>读取缓存主要是指<code>select</code>语句的数据缓存，当然也会包含一些权限缓存、引擎缓存等信息，但主要还是<code>select</code>语句的数据缓存。<br>设计初衷是提高性能，通过缓存来减少解析器、优化器、存储引擎的执行时间。</p><p>对于<code>Cache</code>是否开启可通过命令查询：</p><ul><li><code>show global variables like &quot;%query_cache_type%&quot;;</code>：查询缓存是否开启。</li><li><code>show global variables like &quot;%query_cache_size%&quot;;</code>：查询缓存的空间大小。</li></ul><p>同时还可以通过<code>show status like&#39;%Qcache%&#39;;</code>命令查询缓存相关的统计信息。</p><p>MySQL查询缓存原理<br>MySQL查询缓存是一个查询结果缓存。它将以<code>SEL</code>开头的传入查询与哈希表进行比较，如果匹配，则返回上一次执行查询的结果。<br>就是将查询<code>SQL</code>进行<code>Hash</code>处理，然后将结果存进内存，假如第二次查询<code>SQLHash</code>值存在，那么直接从内存中读取，加快查询的速率。</p><p>为什么MySQL要放弃查询缓存？</p><ol><li>对于 <code>Select * from stu</code>与<code>select * from stu</code> 由于Hash的结果不同，所以查询缓存不会被命中，对于复杂的业务场景这种情况可能会大量发生。</li><li>查询缓存会在表增删改的情况下失效，所以查询缓存适合读多写少的场景，QueryCache理想的场景往往是只读的。</li><li>对于表分区默认查询缓存关闭。</li><li>对于未命中缓存的Sql，会进行数据写入，官方统计会消耗13%的资源。</li><li>对于某些的函数，查询缓存也不会生效，比如 now()</li></ol><hr><p>简单了解了查询缓存后，再来看看写入缓冲；<br>缓冲区的设计主要是：<strong>为了通过内存的速度来弥补磁盘速度较慢对数据库造成的性能影响</strong>。在数据库中读取某页数据操作时，会先将从磁盘读到的页存放在缓冲区中，后续操作相同页的时候，可以基于内存操作。</p><p>一般来说，当你对数据库进行写操作时，都会先从缓冲区中查询是否有你要操作的页，如果有，则直接对内存中的数据页进行操作（例如修改、删除等），对缓冲区中的数据操作完成后，会直接给客户端返回成功的信息，然后<code>MySQL</code>会在后台利用一种名为<code>Checkpoint</code>的机制，将内存中更新的数据刷写到磁盘。</p><blockquote><p><code>MySQL</code>在设计时，通过缓冲区能减少大量的磁盘<code>IO</code>，从而进一步提高数据库整体性能。毕竟每次操作都走磁盘，性能自然上不去的。</p></blockquote><p><em>PS：后续高版本的<code>MySQL</code>移除了查询缓存区，但并未移除缓冲区，这是两个概念，请切记！</em></p><blockquote><p>同时缓冲区是与存储引擎有关的，不同的存储引擎实现也不同，比如<code>InnoDB</code>的缓冲区叫做<code>innodb_buffer_pool</code>，而<code>MyISAM</code>则叫做<code>key_buffer</code></p></blockquote><h2 id="存储引擎层"><a href="#存储引擎层" class="headerlink" title="存储引擎层"></a>存储引擎层</h2><p>存储引擎也可以理解成<code>MySQL</code>最重要的一层，在前面的服务层中，聚集了<code>MySQL</code>所有的核心逻辑操作，而引擎层则负责具体的数据操作以及执行工作。</p><p>如果有小伙伴研究过<code>Oracle、SQLServer</code>等数据库的实现，应该会发现这些数据库只有一个存储引擎，因为它们是闭源的，所以仅有官方自己提供的一种引擎。而<code>MySQL</code>则因为其开源特性，所以存在很多很多款不同的存储引擎实现，<code>MySQL</code>为了能够正常搭载不同的存储引擎运行，因此引擎层是被设计成可拔插式的，也就是可以根据业务特性，为自己的数据库选择不同的存储引擎。</p><blockquote><p><code>MySQL</code>的存储引擎主要分为官方版和民间版，前者是<code>MySQL</code>官方开发的，后者则是第三方开发的。存储引擎在<code>MySQL</code>中，相关的规范标准被定义成了一系列的接口，如果你也想要使用自己开发的存储引擎，那么只需要根据<code>MySQL AB</code>公司定义的准则，编写对应的引擎实现即可。</p></blockquote><p><code>MySQL</code>目前有非常多的存储引擎可选择，其中最为常用的则是<code>InnoDB</code>与<code>MyISAM</code>引擎，可以通过<code>show variables like &#39;%storage_engine%&#39;;</code>命令来查看当前所使用的引擎。</p><p>其他常见引擎如下：</p><ol><li><strong>InnoDB</strong>：默认事务型引擎，支持<strong>ACID 事务</strong>、行级锁定和外键约束，适用于高并发、数据完整性要求高的场景。</li><li><strong>MyISAM</strong>：非事务型引擎，优化<strong>读取性能</strong>，但不支持事务和行级锁定，适合读多写少的场景。</li><li><strong>NDB (Network Database)</strong>：分布式引擎，用于<strong>集群环境</strong>，提供高可用性和负载均衡，常用于需要高可靠性的应用。</li><li><strong>Archive</strong>：专为<strong>数据归档</strong>设计，仅支持 <code>INSERT</code> 和 <code>SELECT</code>，数据压缩存储，节省空间。</li><li><strong>Federated</strong>：允许<strong>跨服务器访问</strong>远程 MySQL 数据库的表，类似“分布式表”的功能。</li><li><strong>Memory</strong>：将数据存储在<strong>内存</strong>中，提供高速读写，但重启后数据会丢失，适合临时数据。</li><li><strong>Merge</strong>：将多个<strong>MyISAM 表</strong>合并为一个逻辑表，便于统一查询和管理大规模数据。</li><li><strong>Partner&#x2F;Community</strong>：指<strong>第三方或社区开发的引擎</strong>（如 tokudb、rocksdb 等），需额外安装或集成。</li></ol><p>存储引擎是<code>MySQL</code>数据库中与磁盘文件打交道的子系统，不同的引擎底层访问文件的机制也存在些许细微差异，引擎也不仅仅只负责数据的管理，也会负责库表管理、索引管理等，<code>MySQL</code>中所有与磁盘打交道的工作，最终都会交给存储引擎来完成。</p><h2 id="文件系统层"><a href="#文件系统层" class="headerlink" title="文件系统层"></a>文件系统层</h2><p>这一层主要可分为两个板块：</p><ul><li>日志板块。</li><li>数据板块。</li></ul><p>这一层则是<code>MySQL</code>数据库的基础，本质上就是基于机器物理磁盘的一个文件系统，其中包含了配置文件、库表结构文件、数据文件、索引文件、日志文件等各类<code>MySQL</code>运行时所需的文件，这一层的功能比较简单，也就是与上层的存储引擎做交互，负责数据的最终存储与持久化工作。</p><h3 id="日志模块"><a href="#日志模块" class="headerlink" title="日志模块"></a>日志模块</h3><p>在<code>MySQL</code>中主要存在七种常用的日志类型，如下：</p><ul><li>①<code>binlog</code>二进制日志，主要记录<code>MySQL</code>数据库的所有<strong>写操作</strong>（增删改）。</li><li>②<code>redo-log</code>重做&#x2F;重写日志，<code>MySQL</code>崩溃时，对于未落盘的操作会记录在这里面，用于重启时重新落盘（<code>InnoDB</code>专有的）。</li><li>③<code>undo-logs</code>撤销&#x2F;回滚日志：记录事务开始前[修改数据]的备份，用于回滚事务。</li><li>④<code>error-log</code>：错误日志：记录<code>MySQL</code>启动、运行、停止时的错误信息。</li><li>⑤<code>general-log</code>常规日志，主要记录<code>MySQL</code>收到的每一个查询或<code>SQL</code>命令。</li><li>⑥<code>slow-log</code>：慢查询日志，主要记录执行时间较长的<code>SQL</code>。</li><li>⑦<code>relay-log</code>：中继日志，主要用于主从复制做数据拷贝。</li></ul><p>上述列出了<code>MySQL</code>中较为常见的七种日志，但实际上还存在很多其他类型的日志，不过一般对调优、排查问题、数据恢复&#x2F;迁移没太大帮助，用的较少，因此不再列出。</p><h3 id="数据模块"><a href="#数据模块" class="headerlink" title="数据模块"></a>数据模块</h3><p>前面聊到过，<code>MySQL</code>的所有数据最终都会落盘（写入到磁盘），而不同的数据在磁盘空间中，存储的格式也并不相同，因此再列举出一些<code>MySQL</code>中常见的数据文件类型：</p><ul><li><code>db.opt</code>文件：主要记录当前数据库使用的字符集和验证规则等信息。</li><li><code>.frm</code>文件：存储表结构的元数据信息文件，每张表都会有一个这样的文件。</li><li><code>.MYD</code>文件：用于存储表中所有数据的文件（<code>MyISAM</code>引擎独有的）。</li><li><code>.MYI</code>文件：用于存储表中索引信息的文件（<code>MyISAM</code>引擎独有的）。</li><li><code>.ibd</code>文件：用于存储表数据和索引信息的文件（<code>InnoDB</code>引擎独有的）。</li><li><code>.ibdata</code>文件：用于存储共享表空间的数据和索引的文件（<code>InnoDB</code>引擎独有）。</li><li><code>.ibdata1</code>文件：这个主要是用于存储<code>MySQL</code>系统（自带）表数据及结构的文件。</li><li><code>.ib_logfile0/.ib_logfile1</code>文件：用于故障数据恢复时的日志文件。</li><li><code>.cnf/.ini</code>：<code>MySQL</code>的配置文件，<code>Windows</code>下是<code>.ini</code>，其他系统大多为<code>.cnf</code>。</li><li><code>......</code></li></ul><p>上述列举了一些<code>MySQL</code>中较为常见的数据文件类型，无论是前面的日志文件，亦或是现在的数据文件，这些都是后续深入剖析<code>MySQL</code>时会遇到的，因此在这里先有个简单认知，方便后续更好的理解<code>MySQL</code>。</p><h1 id="二、SQL查询语句执行流程"><a href="#二、SQL查询语句执行流程" class="headerlink" title="二、SQL查询语句执行流程"></a>二、SQL查询语句执行流程</h1><p><a href="https://mermaid-live.nodejs.cn/edit#pako:eNptkl1P2lAYx7_KyUm8A0Lpi6XZTMZ8wftdrfWiWauYSEu6NtlGSeZ0BiMSVDCYbWw4jWQLhWTZuwsfZpzT9lvslCODoOfq_J_n__yfX05OET4xNR1KcMNSCznwaFExADlzc-B-dEAwaOHqZdj8hr2vtEQND2TknePyd_9zbw3ci8cXQEamXnTWWaOeDIjqru-1_doebf59uY3f7YRntfBTJehtE4nKe-HrQ__XwO8cuEtycPURt2o0YxZl1LqNskTXBL1D_KVB4oiJ5Aa97n8ZX_Dr73G5RhPwhyMXLMvh-S662CVkE-DlcVJ3-HOfmmeAx0n4tD8VtiIPr5uocnonNm0Nf1Tx_lXQrtzmX7l5Jho8MgVeG5WPXZCVqZ4gZm8Q-zt-vYO6TfSqg64b-KTqglV5Ws_4B3X0phV4ffSn4YIM7c2A-r9PcOstdU7zrd4VkVUMGCOfZlODkm05egzmdSuvRhIWozkF2jk9rytQIldNX1edLVuBilEiYwXVeGya-fGkZTobOSitq1tPiXIKmmrri5sq-ZETi25ouvXQdAwbSvwoAUpF-AxKTJJLiCyXFlkxxQsiK8Tg86g6n5jnGI5Ni0yaZfk0V4rBF6OdyYSYZFIphhcFQWBFPiWU_gGnlliL">一图流</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">graph TD</span><br><span class="line">    %% ===== 连接阶段 =====</span><br><span class="line">    A[客户端] &lt;--&gt; B[连接器]</span><br><span class="line">    B --&gt; |管理连接、权限验证、分配线程|E[解析器]</span><br><span class="line"></span><br><span class="line">    %% ===== 解析阶段 =====</span><br><span class="line">    E --&gt; |词法分析、语法分析-&gt;生成解析树| F[预处理器]</span><br><span class="line">    F --&gt; |语义解析、权限验证-&gt;生成新解析树| G[优化器]</span><br><span class="line"></span><br><span class="line">    %% ===== 优化与执行阶段 =====</span><br><span class="line">    G --&gt; |生成执行计划| H[执行器]</span><br><span class="line">    H --&gt; |调用存储引擎| I[存储引擎]</span><br><span class="line">    H --&gt; |返回记录| B</span><br><span class="line">    </span><br><span class="line">    %% ===== 结果返回 =====</span><br><span class="line">    I --&gt; |返回记录| H</span><br></pre></td></tr></table></figure><h2 id="第一步：连接器"><a href="#第一步：连接器" class="headerlink" title="第一步：连接器"></a>第一步：连接器</h2><p>客户端通过TCP&#x2F;IP等协议发送SQL请求。服务端接收到请求，转交给连接器处理。</p><p>连接器就要开始验证用户的用户名和密码，如果用户密码都没有问题，连接器就会获取该用户的权限，然后保存起来，后续该用户在此连接里的任何操作，都会基于连接开始时读到的权限进行权限逻辑的判断。所以，如果一个用户已经建立了连接，即使管理员中途修改了该用户的权限，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。</p><p>然后为该连接创建新线程或复用线程连接池中的线程，若连接数已达上限则返回错误。</p><h2 id="第二步：查询缓存"><a href="#第二步：查询缓存" class="headerlink" title="第二步：查询缓存"></a>第二步：查询缓存</h2><blockquote><p>MySQL 8.0+ 已经删除查询缓存功能</p></blockquote><p>建立连接后，会把SQL语句发给<code>SQL Interface</code>，他会解析出 SQL 语句的第一个字段，看看是什么类型的语句。</p><p>如果 SQL 是查询语句（select 语句），MySQL 就会先去查询缓存（ Query Cache ）里查找缓存数据，看看之前有没有执行过这一条命令，这个查询缓存是以 key-value 形式保存在内存中的，key 为 SQL 查询语句，value 为 SQL 语句查询的结果。</p><p>如果查询的语句命中查询缓存，那么就会直接返回 value 给客户端。如果查询的语句没有命中查询缓存中，那么就要往下继续执行，等执行完后，查询的结果就会被存入查询缓存中。</p><p>这么看，查询缓存还挺有用，但是其实查询缓存挺鸡肋的。</p><p>对于更新比较频繁的表，查询缓存的命中率很低的，因为只要一个表有更新操作，那么这个表的查询缓存就会被清空。如果刚缓存了一个查询结果很大的数据，还没被使用的时候，刚好这个表有更新操作，查询缓冲就被清空了，相当于缓存了个寂寞。</p><blockquote><p>这里说的查询缓存是 server 层的，并不是 Innodb 存储引擎中的 buffer pool。</p></blockquote><h2 id="第三步：解析-SQL"><a href="#第三步：解析-SQL" class="headerlink" title="第三步：解析 SQL"></a>第三步：解析 SQL</h2><p>在正式执行 SQL 查询语句之前， MySQL 会先对 SQL 语句做解析，这个工作交由「解析器」来完成。</p><h3 id="解析器-1"><a href="#解析器-1" class="headerlink" title="解析器"></a>解析器</h3><p><strong>词法分析</strong>：将SQL语句拆分为Token（如关键字<code>SELECT</code>、表名<code>users</code>、运算符<code>=</code>）。</p><p><strong>语法分析</strong>：验证SQL语法合法性（如括号匹配、关键字顺序）。</p><p><strong>生成原始解析树</strong>：结构化表示SQL操作（如SELECT的目标列、WHERE条件）。</p><h2 id="第四步：执行-SQL"><a href="#第四步：执行-SQL" class="headerlink" title="第四步：执行 SQL"></a>第四步：执行 SQL</h2><p>经过解析器后，接着就要进入执行 SQL 查询语句的流程了，每条SELECT 查询语句流程主要可以分为下面这三个阶段：</p><ul><li>prepare 阶段，也就是预处理阶段；</li><li>optimize 阶段，也就是优化阶段；</li><li>execute 阶段，也就是执行阶段；</li></ul><h3 id="预处理器"><a href="#预处理器" class="headerlink" title="预处理器"></a>预处理器</h3><p>我们先来看看预处理阶段做了什么事情。</p><p><strong>语义解析</strong>：  </p><ol><li><strong>对象存在性检查</strong>：验证表、列、索引是否存在。</li><li><strong>符号解析</strong>：将<code>*</code>扩展为具体列名（如<code>SELECT *</code> → <code>SELECT id, name</code>）。</li><li><strong>视图展开</strong>：替换视图为底层表查询逻辑（如<code>SELECT * FROM view</code> → <code>SELECT * FROM base_table WHERE ...</code>）。</li><li><strong>子查询处理</strong>：将嵌套子查询转换为临时表或JOIN操作。</li></ol><p><strong>预编译语句绑定</strong>：对<code>PREPARE</code>语句的参数进行类型检查和值绑定。</p><p><strong>生成最终解析树</strong>：输出经过语义验证的解析树，然后根据SQL类型将请求路由到对应模块。</p><p><strong>细粒度权限校验</strong>：再次检查用户对<strong>具体表、列</strong>的操作权限（如SELECT <code>users.name</code>权限）。若权限不足，直接返回错误。</p><h3 id="优化器-1"><a href="#优化器-1" class="headerlink" title="优化器"></a>优化器</h3><p>经过预处理阶段后，还需要为 SQL 查询语句先制定一个执行计划，这个工作交由「优化器」来完成的。</p><p><strong>优化器主要负责将 SQL 查询语句的执行方案确定下来</strong>，比如在表里面有多个索引的时候，优化器会基于查询成本的考虑，来决定选择使用哪个索引。</p><p>当然，像<code>select * from product where id = 1</code>的SQL很简单就能看出来，就是选择使用主键索引。</p><p>要想知道优化器选择了哪个索引，我们可以在查询语句最前面加个 <code>explain</code> 命令，这样就会输出这条 SQL 语句的执行计划，然后执行计划中的 key 就表示执行过程中使用了哪个索引。<br>如果查询语句的执行计划里的 key 为 null 说明没有使用索引，那就会全表扫描（type &#x3D; ALL），这种查询扫描的方式是效率最低档次的：</p><p>product 表的 id 字段是主键索引，若现在新建了一个索引：name 字段为普通索引（二级索引）。假设执行了这条查询语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id <span class="keyword">from</span> product <span class="keyword">where</span> id <span class="operator">&gt;</span> <span class="number">1</span>  <span class="keyword">and</span> name <span class="keyword">like</span> <span class="string">&#x27;i%&#x27;</span>;</span><br></pre></td></tr></table></figure><p>这条查询语句的结果既可以使用主键索引，也可以使用普通索引，但是执行的效率会不同。这时，就需要优化器来决定使用哪个索引了。</p><p>很显然这条查询语句是<strong>覆盖索引</strong>，直接在二级索引就能查找到结果（因为二级索引的 B+ 树的叶子节点的数据存储的是主键值），就没必要在主键索引查找了，因为查询主键索引的 B+ 树的成本会比查询二级索引的 B+ 的成本大，优化器基于查询成本的考虑，会选择查询代价小的普通索引。</p><p>这条语句加个 <code>explain</code> 命令得到执行计划，就可以看到，执行过程中使用了普通索引（name），Exta 为 Using index，这就是表明使用了覆盖索引优化。</p><h3 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h3><p>经历完优化器后，就确定了执行方案，接下来 MySQL 就真正开始执行语句了，这个工作是由「执行器」完成的。在执行的过程中，执行器就会和存储引擎交互了，交互是以记录为单位的。</p><p>接下来，用三种方式执行过程，跟大家说一下执行器和存储引擎的交互过程</p><ul><li>主键索引查询</li><li>全表扫描</li><li>索引下推</li></ul><h4 id="主键索引查询"><a href="#主键索引查询" class="headerlink" title="主键索引查询"></a>主键索引查询</h4><p>以本文开头查询语句为例，看看执行器是怎么工作的。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> product <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>这条查询语句的查询条件用到了主键索引，而且是等值查询，同时主键 id 是唯一，不会有 id 相同的记录，所以优化器决定选用访问类型为 const 进行查询，也就是使用主键索引查询一条记录，那么执行器与存储引擎的执行流程是这样的：</p><ul><li>执行器第一次查询，会调用 read_first_record 函数指针指向的函数，因为优化器选择的访问类型为 const，这个函数指针被指向为 InnoDB 引擎索引查询的接口，把条件 <code>id = 1</code> 交给存储引擎，<strong>让存储引擎定位符合条件的第一条记录</strong>。</li><li>存储引擎通过主键索引的 B+ 树结构定位到 <code>id = 1</code> 的第一条记录，如果记录是不存在的，就会向执行器上报记录找不到的错误，然后查询结束。如果记录是存在的，就会将记录返回给执行器；</li><li>执行器从存储引擎读到记录后，接着判断记录是否符合查询条件，如果符合则发送给客户端，如果不符合则跳过该记录。</li><li>执行器查询的过程是一个 while 循环，所以还会再查一次，但是这次因为不是第一次查询了，所以会调用 read_record 函数指针指向的函数，因为优化器选择的访问类型为 const，这个函数指针被指向为一个永远返回 - 1 的函数，所以当调用该函数的时候，执行器就退出循环，也就是结束查询了。</li></ul><p>至此，这个语句就执行完成了。</p><h4 id="全表扫描"><a href="#全表扫描" class="headerlink" title="全表扫描"></a>全表扫描</h4><p>举个全表扫描的例子：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> product <span class="keyword">where</span> name <span class="operator">=</span> <span class="string">&#x27;iphone&#x27;</span>;</span><br></pre></td></tr></table></figure><p>这条查询语句的查询条件没有用到索引，所以优化器决定选用访问类型为 ALL 进行查询，也就是全表扫描的方式查询，那么这时执行器与存储引擎的执行流程是这样的：</p><ul><li>执行器第一次查询，会调用 read_first_record 函数指针指向的函数，因为优化器选择的访问类型为 all，这个函数指针被指向为 InnoDB 引擎全扫描的接口，<strong>让存储引擎读取表中的第一条记录</strong>；</li><li>执行器会判断读到的这条记录的 name 是不是 iphone，如果不是则跳过；如果是则将记录发给客户的（是的没错，Server 层每从存储引擎读到一条记录就会发送给客户端，之所以客户端显示的时候是直接显示所有记录的，是因为客户端是等查询语句查询完成后，才会显示出所有的记录）。</li><li>执行器查询的过程是一个 while 循环，所以还会再查一次，会调用 read_record 函数指针指向的函数，因为优化器选择的访问类型为 all，read_record 函数指针指向的还是 InnoDB 引擎全扫描的接口，所以接着向存储引擎层要求继续读刚才那条记录的下一条记录，存储引擎把下一条记录取出后就将其返回给执行器（Server层），执行器继续判断条件，不符合查询条件即跳过该记录，否则发送到客户端；</li><li>一直重复上述过程，直到存储引擎把表中的所有记录读完，然后向执行器（Server层） 返回了读取完毕的信息；</li><li>执行器收到存储引擎报告的查询完毕的信息，退出循环，停止查询。</li></ul><p>至此，这个语句就执行完成了。</p><h4 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a>索引下推</h4><p>在这部分非常适合讲索引下推（MySQL 5.6 推出的查询优化策略），这样大家能清楚的知道，「下推」这个动作，下推到了哪里。</p><p>索引下推能够减少<strong>二级索引</strong>在查询时的回表操作，提高查询的效率，因为它将 Server 层部分负责的事情，交给存储引擎层去处理了。</p><p>举一个具体的例子，方便大家理解，这里一张用户表如下，我对 age 和 reward 字段建立了联合索引（age，reward）：</p><p>现在有下面这条查询语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t_user  <span class="keyword">where</span> age <span class="operator">&gt;</span> <span class="number">20</span> <span class="keyword">and</span> reward <span class="operator">=</span> <span class="number">100000</span>;</span><br></pre></td></tr></table></figure><p>根据索引规则，联合索引当遇到范围查询 (&gt;、&lt;) 就会停止匹配，即<strong>范围查询会中断索引的后续匹配</strong>。也就是 <strong>age 字段能用到联合索引，但是 reward 字段则无法利用到索引</strong>。具体原因这里可以看这篇：<a href="https://xiaolincoding.com/mysql/index/index_interview.html#%E6%8C%89%E5%AD%97%E6%AE%B5%E4%B8%AA%E6%95%B0%E5%88%86%E7%B1%BB">索引常见面试题</a></p><p>那么，不使用索引下推（MySQL 5.6 之前的版本）时，执行器与存储引擎的执行流程是这样的：</p><ul><li>Server 层首先调用存储引擎的接口定位到满足查询条件的第一条二级索引记录，也就是定位到 age &gt; 20 的第一条记录；</li><li>存储引擎根据二级索引的 B+ 树快速定位到这条记录后，获取主键值，然后<strong>进行回表操作</strong>，将完整的记录返回给 Server 层；</li><li>Server 层在判断该记录的 reward 是否等于 100000，如果成立则将其发送给客户端；否则跳过该记录；</li><li>接着，继续向存储引擎索要下一条记录，存储引擎在二级索引定位到记录后，获取主键值，然后回表操作，将完整的记录返回给 Server 层；</li><li>如此往复，直到存储引擎把表中的所有记录读完。</li></ul><p>可以看到，没有索引下推的时候，每查询到一条二级索引记录，都要进行回表操作，然后将记录返回给 Server，接着 Server 再判断该记录的 reward 是否等于 100000。</p><p>而使用索引下推后，判断记录的 reward 是否等于 100000 的工作交给了存储引擎层，过程如下 ：</p><ul><li>Server 层首先调用存储引擎的接口定位到满足查询条件的第一条二级索引记录，也就是定位到 age &gt; 20 的第一条记录；</li><li>存储引擎定位到二级索引后，<strong>先不执行回表</strong>操作，而是先判断一下该索引中包含的列（reward列）的条件（reward 是否等于 100000）是否成立。如果<strong>条件不成立</strong>，则直接<strong>跳过该二级索引</strong>。如果<strong>成立</strong>，则<strong>执行回表</strong>操作，将完成记录返回给 Server 层。</li><li>Server 层在判断其他的查询条件（本次查询没有其他条件）是否成立，如果成立则将其发送给客户端；否则跳过该记录，然后向存储引擎索要下一条记录。</li><li>如此往复，直到存储引擎把表中的所有记录读完。</li></ul><p>可以看到，使用了索引下推后，虽然 reward 列无法使用到联合索引，但是因为它包含在联合索引（age，reward）里，所以直接在存储引擎过滤出满足 reward &#x3D; 100000 的记录后，才去执行回表操作获取整个记录。相比于没有使用索引下推，节省了很多回表操作。</p><p>当你发现执行计划里的 Extr 部分显示了 “Using index condition”，说明使用了索引下推。</p><h1 id="三、SQL更新语句执行流程"><a href="#三、SQL更新语句执行流程" class="headerlink" title="三、SQL更新语句执行流程"></a>三、SQL更新语句执行流程</h1><p>现在看看一条更新语句如何执行的呢？SQL 语句如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">update</span> tb_student A <span class="keyword">set</span> A.age<span class="operator">=</span><span class="string">&#x27;19&#x27;</span> <span class="keyword">where</span> A.name<span class="operator">=</span><span class="string">&#x27; 张三 &#x27;</span>;</span><br></pre></td></tr></table></figure><p>我们来给张三修改下年龄，在实际数据库肯定不会设置年龄这个字段的，不然要被技术负责人打的。（一般记录的是出生日期）</p><p>其实这条语句也基本上会沿着上一个查询的流程走，只不过执行更新的时候肯定要记录日志啦，这就会引入日志模块了，MySQL 自带的日志模块是 <strong>binlog（归档日志）</strong> ，所有的存储引擎都可以使用，我们常用的 InnoDB 引擎还自带了一个日志模块 <strong>redo log（重做日志）</strong>，我们就以 InnoDB 模式下来探讨这个语句的执行流程。流程如下：</p><ul><li>先查询到张三这一条数据，不会走查询缓存，因为更新语句会导致与该表相关的查询缓存失效。</li><li>然后拿到查询的语句，把 age 改为 19，然后调用引擎 API 接口，写入这一行数据，InnoDB 引擎把数据保存在内存中，同时记录 redo log，此时 redo log 进入 prepare 状态，然后告诉执行器，执行完成了，随时可以提交。</li><li>执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为提交状态。</li><li>更新完成。</li></ul><p><strong>这里肯定有同学会问，为什么要用两个日志模块，用一个日志模块不行吗?</strong></p><p>这是因为最开始 MySQL 并没有 InnoDB 引擎（InnoDB 引擎是其他公司以插件形式插入 MySQL 的），MySQL 自带的引擎是 MyISAM，但是我们知道 redo log 是 InnoDB 引擎特有的，其他存储引擎都没有，这就导致会没有 crash-safe 的能力(crash-safe 的能力即使数据库发生异常重启，之前提交的记录都不会丢失)，binlog 日志只能用来归档。</p><p>并不是说只用一个日志模块不可以，只是 InnoDB 引擎就是通过 redo log 来支持事务的。那么，又会有同学问，我用两个日志模块，但是不要这么复杂行不行，为什么 redo log 要引入 prepare 预提交状态？这里我们用反证法来说明下为什么要这么做？</p><ul><li><strong>先写 redo log 直接提交，然后写 binlog</strong>，假设写完 redo log 后，机器挂了，binlog 日志没有被写入，那么机器重启后，这台机器会通过 redo log 恢复数据，但是这个时候 binlog 并没有记录该数据，后续进行机器备份的时候，就会丢失这一条数据，同时主从同步也会丢失这一条数据。</li><li><strong>先写 binlog，然后写 redo log</strong>，假设写完了 binlog，机器异常重启了，由于没有 redo log，本机是无法恢复这一条记录的，但是 binlog 又有记录，那么和上面同样的道理，就会产生数据不一致的情况。</li></ul><p>如果采用 redo log 两阶段提交的方式就不一样了，写完 binlog 后，然后再提交 redo log 就会防止出现上述的问题，从而保证了数据的一致性。那么问题来了，有没有一个极端的情况呢？假设 redo log 处于预提交状态，binlog 也已经写完了，这个时候发生了异常重启会怎么样呢？<br>这个就要依赖于 MySQL 的处理机制了，MySQL 的处理过程如下：</p><ul><li>判断 redo log 是否完整，如果判断是完整的，就立即提交。</li><li>如果 redo log 只是预提交但不是 commit 状态，这个时候就会去判断 binlog 是否完整，如果完整就提交 redo log, 不完整就回滚事务。</li></ul><p>这样就解决了数据一致性的问题。</p><h1 id="四、慢SQL解决方案"><a href="#四、慢SQL解决方案" class="headerlink" title="四、慢SQL解决方案"></a>四、慢SQL解决方案</h1><p>MySQL 服务器的资源（CPU、IO、内存等）是有限的，尤其在高并发场景下需要快速处理掉请求，否则一旦出现慢 SQL 就会阻塞掉很多正常的请求，造成大面积的失败&#x2F;超时等。</p><p>一个 SQL 执行的很慢，我们要分两种情况讨论：  </p><ol><li><p>大多数情况下很正常，偶尔很慢，则有如下原因</p><ul><li>数据库在刷新脏页，例如 redo log 写满了需要同步到磁盘。  </li><li>执行的时候，遇到锁，如表锁、行锁。  </li><li>sql写的烂</li></ul></li><li><p>这条 SQL 语句一直执行的很慢，则有如下原因</p><ul><li>没有用上索引或则索引失效：例如该字段没有索引；或则由于对字段进行运算、函数操作导致无法用索引。  </li><li>有索引可能会走全表扫描</li></ul></li></ol><h2 id="SQL执行频率分析"><a href="#SQL执行频率分析" class="headerlink" title="SQL执行频率分析"></a>SQL执行频率分析</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> STATUS <span class="keyword">LIKE</span> <span class="string">&#x27;Com_%&#x27;</span>; <span class="comment">-- 统计所有SQL命令的执行频率（全局范围）</span></span><br></pre></td></tr></table></figure><ul><li>Com_select：执行 select 操作的次数。</li><li>Com_insert：执行 insert 操作的次数，对于批量插入的 insert，只累加一次。</li><li>Com_update：执行 update 操作的次数。</li><li>Com_delete：执行 delete 操作的次数。</li></ul><p>这些参数统计的是<strong>所有存储引擎</strong>（如InnoDB、MyISAM等）的SQL操作总次数，适用于全局负载分析。</p><p>下面这几个参数只是针对 I<strong>nnoDB</strong> 存储引擎的，累加的算法也略有不同，采用行级统计逻辑：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> STATUS <span class="keyword">LIKE</span> <span class="string">&#x27;Innodb_rows_%&#x27;</span>; <span class="comment">-- 仅统计InnoDB存储引擎的操作行为</span></span><br></pre></td></tr></table></figure><ul><li>Innodb_rows_deleted：记录通过DELETE操作实际删除的行数总和（如删除100行计数+100）。</li><li>Innodb_rows_inserted：统计通过INSERT操作实际插入的行数总和（如批量插入50行计数+50）。</li><li>Innodb_rows_read：记录SELECT查询返回的行数总和（如查询返回168行计数+168）。</li><li>Innodb_rows_updated：统计通过UPDATE操作实际更新的行数总和（如更新3行计数+3）。</li></ul><p>通过以上几个参数，我们可以快速判断数据库的工作负载类型，以及各种类型的 SQL 大致的<strong>执行比例</strong>是多少。</p><ul><li>读密集型：Com_select 占比超过 80%，需重点关注查询性能（如索引优化、缓存策略）。</li><li>写密集型：Com_insert、Com_update、Com_delete 占比高，需优化写入性能（如批量操作、减少事务粒度）。</li></ul><p>对<strong>事务型</strong>的应用，通过 Com_commit 和 Com_rollback 可以了解事务提交和回滚的情况，<strong>对于回滚操作非常频繁的数据库，可能意味着应用编写存在问题</strong>。</p><h2 id="定位慢查询"><a href="#定位慢查询" class="headerlink" title="定位慢查询"></a>定位慢查询</h2><p>可以通过以下两种方式定位执行效率较低的 SQL 语句（慢查询的统计通常由运维定期统计）：</p><ol><li>对于大量的SQL语句，一句一句分析也不是办法，可以在 MySQL 中开启SQL慢查询日志，如自定义时间为2s，则会开始记录所有超过2s的SQL执行语句。</li><li>慢查询日志在查询结束以后才纪录，所以在应用反映执行效率出现问题时，查询慢查询日志并不能定位问题。这时可以使用 <code>show processlist;</code> 命令查看当前 MySQL 在进行的线程，包括线程的状态、是否锁表等，可以实时地查看 SQL 的执行情况，同时对一些锁表操作进行优化。</li></ol><p><code>show processlist;</code> 命令只列出前 100 条正在运行的线程信息，如果想全列出需要使用 <code>show full processlist;</code>。也可以使用 <code>mysqladmin processlist;</code> 语句得到此信息。</p><p>关于该命令的原文介绍：<br><a href="https://dev.mysql.com/doc/refman/8.4/en/show-processlist.html">https://dev.mysql.com/doc/refman/8.4/en/show-processlist.html</a></p><p>下面为其简单描述：</p><p>除非有 SUPER 权限，可以看到所有线程。否则，只能看到自己的线程（也就是，与您正在使用的 MySQL 账户相关的线程）。</p><p>本语句会报告 TCP&#x2F;IP 连接的主机名称（采用 <em>host_name</em>:<em>client_port</em> 格式），以方便地判定哪个客户端正在做什么。</p><p>如果得到了“too many connections”错误信息，并且想要了解正在发生的情况，本语句是非常有用的。MySQL保留一个额外的连接，让拥有 SUPER 权限的账户使用，以确保管理员能够随时连接和检查系统（假设没有把此权限给予所有的用户）。</p><p>该命令返回内容的参数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Id       # 线程的唯一标识符，用于识别和管理线程。</span><br><span class="line">User     # 执行线程的用户。</span><br><span class="line">Host     # 发起连接的主机地址。</span><br><span class="line">db       # 当前线程所使用的数据库。</span><br><span class="line">Command  # 连接状态，一般是休眠（sleep），查询（query），连接（connect），初始化（init）</span><br><span class="line">Time     # 线程已经执行的时间（秒）。</span><br><span class="line">State    # 线程的状态，如Locked、Sending data等。</span><br><span class="line">Info     # 执行的SQL语句或命令。</span><br></pre></td></tr></table></figure><p>该命令中最关键的就是 <code>State</code> 列，它提供了线程当前执行状态的描述。<br>例如，<code>Locked</code> 状态表示线程被其他查询锁定，而 <code>Sending data</code> 状态表示正在处理SELECT查询并发送结果给客户端。<br>具体其他状态查询原文：<br><a href="https://dev.mysql.com/doc/refman/8.4/en/replica-io-thread-states.html">https://dev.mysql.com/doc/refman/8.4/en/replica-io-thread-states.html</a></p><h2 id="分析执⾏计划"><a href="#分析执⾏计划" class="headerlink" title="分析执⾏计划"></a>分析执⾏计划</h2><p>使用 <code>EXPLAIN</code> 或 <code>EXPLAIN ANALYZE</code> 分析执行计划；<br>通过查看 <code>type</code>（如 <code>index</code>, <code>range</code>, <code>ALL</code>）、<code>rows</code>（扫描行数）、<code>key</code>（使用的索引）、<code>Extra</code>（如 <code>Using where</code>, <code>Using filesort</code>）等字段，定位性能瓶颈。  </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> orders <span class="keyword">WHERE</span> user_id <span class="operator">=</span> <span class="number">100</span> <span class="keyword">AND</span> status <span class="operator">=</span> <span class="string">&#x27;completed&#x27;</span>;</span><br></pre></td></tr></table></figure><p>如果 <code>type=ALL</code>，说明全表扫描，需添加索引；若 <code>key= NULL</code>，说明索引未命中。<br>主要关注这⼏个字段即可：</p><ol><li><code>type</code>：表⽰MySQL在表中找到所需⾏的⽅式，或者叫访问类型<ul><li>type&#x3D;ALL，全表扫描，MySQL遍历全表来找到匹配⾏</li><li>type&#x3D;index，索引全扫描</li><li>type&#x3D;range，索引范围扫描</li><li>type&#x3D;eq_ref，唯⼀索引</li><li>type&#x3D;NULL，MySQL不⽤访问表或者索引，直接就能够得到结果</li></ul></li><li><code>possible_keys</code>: 表⽰查询可能使⽤的索引</li><li><code>key</code>: 实际使⽤的索引，若 <code>key= NULL</code>，说明索引未命中。</li><li><code>key_len</code>: 使⽤索引字段的⻓度</li><li><code>rows</code>: 扫描⾏的数量</li><li><code>Extra</code>：<ul><li>using index：覆盖索引，不回表</li><li>using where：回表查询</li><li>using filesort：需要额外的排序，不能通过索引得到排序结果</li></ul></li></ol><h2 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a>索引优化</h2><p>sql优化当中，有⼀个⾮常重要的内容就是：索引优化。<br>很多时候sql语句，⾛了索引，和没有⾛索引，执⾏效率差别很⼤。所以索引优化被作为sql优化的首选。索引优化的第⼀步是：检查sql语句有没有⾛索引。</p><p>那么，如何查看sql⾛了索引没？<br>可以使⽤ <code>explain</code> 命令，查看 MySQL 的执⾏计划，重点关注 <code>type</code>, <code>key</code> 字段值（回看上部分）</p><p> <strong>原则</strong>：</p><ul><li>为 <code>WHERE</code>, <code>JOIN</code>, <code>ORDER BY</code> 中的高频字段创建索引。  </li><li><strong>最左前缀原则</strong>：复合索引 <code>(a, b, c)</code> 可以支持 <code>a</code> 或 <code>(a,b)</code> 的查询，但无法支持 <code>(b,c)</code>。  </li><li><strong>覆盖索引</strong>：索引本身包含查询所需的所有字段，避免回表。</li></ul><p><strong>索引失效场景</strong>：</p><ul><li>在索引列上使用函数或计算（如 <code>WHERE YEAR(create_time) = 2023</code> → 应改为 <code>WHERE create_time BETWEEN &#39;2023-01-01&#39; AND &#39;2023-12-31&#39;</code>）。  </li><li><code>OR</code> 条件导致索引失效（如 <code>WHERE a=1 OR b=2</code> → 拆分为 <code>UNION ALL</code>）。</li></ul><p><strong>案例</strong>：</p><ul><li><strong>问题</strong>：<code>SELECT * FROM user WHERE mobile = &#39;13812345678&#39;</code>，<code>mobile</code> 是 <code>VARCHAR</code> 类型，但查询时条件传入数字 <code>13812345678</code>，导致隐式转换索引失效（所有记录的 mobile 字段值都要经历一次类型转换）。  </li><li><strong>优化</strong>：确保参数类型与字段一致，或在查询时强制类型：<code>WHERE mobile = &#39;13812345678&#39;</code>。</li></ul><h2 id="SQL语句优化"><a href="#SQL语句优化" class="headerlink" title="SQL语句优化"></a>SQL语句优化</h2><h3 id="避免使⽤select"><a href="#避免使⽤select" class="headerlink" title="避免使⽤select *"></a>避免使⽤<code>select *</code></h3><p>sql 语句查询时，只查需要⽤到的列，多余的列根本⽆需查出来。</p><p>反例：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> id<span class="operator">=</span><span class="number">1</span>;</span><br></pre></td></tr></table></figure><ul><li>在实际业务场景中，可能我们真正需要使⽤的只有其中⼀两列。查了很多数据，但是不⽤，⽩⽩浪费了数据库资源，⽐如：内存或者cpu。</li><li>此外，多查出来的数据，通过⽹络IO传输的过程中，也会增加数据传输的时间。</li><li>还有⼀个最重要的问题是：<code>select *</code> 不会⾛覆盖索引，会出现⼤量的回表操作，⽽从导致查询sql的性能很低。</li></ul><p>正例：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> name,age <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> id<span class="operator">=</span><span class="number">1</span>;</span><br></pre></td></tr></table></figure><h3 id="⽤union-all代替union"><a href="#⽤union-all代替union" class="headerlink" title="⽤union all代替union"></a>⽤<code>union all</code>代替<code>union</code></h3><p><code>union</code> 和 <code>union all</code> 的差异主要是前者需要将结果集合并后再进⾏唯⼀性过滤操作，这就会涉及到排序，增加⼤量的CPU运算，加⼤资源消耗及延迟。<br>⽽如果使⽤ <code>union all</code> 关键字，可以获取所有数据，包含重复的数据。</p><p>反例：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> id<span class="operator">=</span><span class="number">1</span>)</span><br><span class="line"><span class="keyword">union</span></span><br><span class="line">(<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> id<span class="operator">=</span><span class="number">2</span>);</span><br></pre></td></tr></table></figure><p>排重的过程需要遍历、排序和⽐较，它更耗时，更消耗cpu资源。<br>所以如果能⽤ <code>union all</code> 的时候，尽量不⽤ <code>union</code>。</p><p>正例：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> id<span class="operator">=</span><span class="number">1</span>)</span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">(<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> id<span class="operator">=</span><span class="number">2</span>);</span><br></pre></td></tr></table></figure><p>除⾮是有些特殊的场景，⽐如 <code>union all</code> 之后，结果集中出现了重复数据，⽽业务场景中<br>是不允许产⽣重复数据的，这时可以使⽤ <code>union</code>。</p><h3 id="⼩表驱动⼤表，区分in和exists"><a href="#⼩表驱动⼤表，区分in和exists" class="headerlink" title="⼩表驱动⼤表，区分in和exists"></a>⼩表驱动⼤表，区分<code>in</code>和<code>exists</code></h3><p>⼩表驱动⼤表，也就是说⽤⼩表的数据集驱动⼤表的数据集。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> 表A <span class="keyword">where</span> id <span class="keyword">in</span> (<span class="keyword">select</span> id <span class="keyword">from</span> 表B)</span><br></pre></td></tr></table></figure><p>上⾯的语句相当于：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> 表A <span class="keyword">where</span> <span class="keyword">exists</span>(<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> 表B <span class="keyword">where</span> 表B.id<span class="operator">=</span>表A.id)</span><br></pre></td></tr></table></figure><p>区分 <code>in</code> 和 <code>exists</code> 主要是造成了驱动顺序的改变（这是性能变化的关键）</p><p>如果 SQL 语句中包含了 <code>in</code> 关键字，则它会优先执⾏ <code>in</code> ⾥⾯的⼦查询语句，然后再执⾏ <code>in</code> 外⾯的语句。如果 <code>in</code> ⾥⾯的数据量很少，作为条件查询速度更快。<br>⽽如果 SQL 语句中包含了 <code>exists</code> 关键字，它优先执⾏ <code>exists</code> 左边的语句（即主查询语句）。然后把它作为条件，去跟右边的语句匹配。如果匹配上，则可以查询出数据。如果匹配不上，数据就被过滤掉了。</p><p>总结⼀下：</p><ul><li>in 适⽤于左边⼤表，右边⼩表。</li><li>exists 适⽤于左边⼩表，右边⼤表。</li></ul><h3 id="用连接查询代替子查询"><a href="#用连接查询代替子查询" class="headerlink" title="用连接查询代替子查询"></a>用连接查询代替子查询</h3><p>MySQL 中如果需要从两张以上的表中查询出数据的话，一般有两种实现方式：子查询和连接查询。</p><p>子查询语句可以通过<code>in</code>关键字实现，如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> 表A <span class="keyword">where</span> id <span class="keyword">in</span></span><br><span class="line">(<span class="keyword">select</span> id <span class="keyword">from</span> 表B <span class="keyword">where</span> status<span class="operator">=</span><span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>但是对于数据库来说，在绝⼤部分情况下，连接会⽐⼦查询更快，使⽤连接的⽅式，MySQL 优化器⼀般可以⽣成更佳的执⾏计划，更⾼效地处理查询。</p><p>⽽⼦查询往往需要运⾏重复的查询，⼦查询⽣成的临时表上也没有索引， 因此效率会更低。所以建议使用连接查询替代：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> 表A.<span class="operator">*</span> <span class="keyword">from</span> 表A</span><br><span class="line"><span class="keyword">inner</span> <span class="keyword">join</span> 表B <span class="keyword">on</span> 表A.id <span class="operator">=</span> 表B.id</span><br><span class="line"><span class="keyword">where</span> 表B.status<span class="operator">=</span><span class="number">1</span></span><br></pre></td></tr></table></figure><h3 id="批量操作"><a href="#批量操作" class="headerlink" title="批量操作"></a>批量操作</h3><p>如果你有⼀批数据经过业务处理之后，需要插⼊数据，该怎么办？</p><p>反例：<br>在循环中逐条插⼊数据。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(Order order: list)&#123;</span><br><span class="line">orderMapper.insert(order):</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该操作需要多次请求数据库，才能完成这批数据的插⼊。<br>但众所周知，我们在代码中，每次远程请求数据库，是会消耗⼀定性能的。⽽如果我们的代码需要请求多次数据库，才能完成本次业务功能，势必会消耗更多的性能。</p><p>正例：<br>提供⼀个批量插⼊数据的⽅法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">orderMapper.insertBatch(list):</span><br></pre></td></tr></table></figure><p>这样只需要远程请求⼀次数据库，sql 性能会得到提升，数据量越多，提升越⼤。<br>但需要注意的是，不建议⼀次批量操作太多的数据，如果数据太多数据库响应也会很慢。批量操作需要把握⼀个度，建议每批数据尽量控制在 500 以内。如果数据多于 500，则分多批次处理。</p><h3 id="当只要一行数据时使用-LIMIT-1"><a href="#当只要一行数据时使用-LIMIT-1" class="headerlink" title="当只要一行数据时使用 LIMIT 1"></a>当只要一行数据时使用 <code>LIMIT 1</code></h3><p>针对非主键的其他查询，加上 <code>LIMIT 1</code> 可以增加性能。这样 MySQL 数据库引擎会在找到一条数据后停止搜索，而不是继续往后查下一条符合记录的数据（否则即使已经查到一条结果，也会继续查询是否还存在等值结果，再返回结果）。</p><p>例如：<br>有时候，我们需要查询某些数据中的第⼀条，⽐如：查询某个⽤⼾下的第⼀个订单，想看看他第⼀次的首单时间。</p><p>反例：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id, create_date <span class="keyword">from</span> 表A</span><br><span class="line"><span class="keyword">where</span> user_id<span class="operator">=</span><span class="number">123</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> create_date <span class="keyword">asc</span>;</span><br></pre></td></tr></table></figure><p>根据⽤⼾ id 查询订单，按下单时间排序，先查出该⽤⼾所有的订单数据，得到⼀个订单集合。然后在代码中，获取第⼀个元素的数据，即首单的数据，就能获取首单时间。虽说这种做法在功能上没有问题，但它的效率⾮常不⾼，需要先查询出所有的数据，有点浪费资源。</p><p>正例：<br>使⽤ <code>limit 1</code>，只返回该⽤⼾下单时间最⼩的那⼀条数据即可。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id, create_date <span class="keyword">from</span> 表A</span><br><span class="line"><span class="keyword">where</span> user_id<span class="operator">=</span><span class="number">123</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> create_date <span class="keyword">asc</span></span><br><span class="line">limit <span class="number">1</span>;</span><br></pre></td></tr></table></figure><h3 id="调整where子句中的连接顺序"><a href="#调整where子句中的连接顺序" class="headerlink" title="调整where子句中的连接顺序"></a>调整<code>where</code>子句中的连接顺序</h3><p>MySQL 采用从左往右的顺序解析 <code>where</code> 子句，可以将过滤数据多的条件放在前面，最快速度缩小结果集。</p><p>例子：查询用户表中北京地区且年龄大于 30 岁的用户。<br>优化前：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 若 age 无索引，city 有索引</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> users </span><br><span class="line"><span class="keyword">where</span> age <span class="operator">&gt;</span> <span class="number">30</span>          <span class="comment">-- 先执行：全表扫描过滤 age &gt; 30</span></span><br><span class="line"><span class="keyword">and</span> city <span class="operator">=</span> <span class="string">&#x27;北京&#x27;</span>;     <span class="comment">-- 后执行：再通过索引过滤 city</span></span><br></pre></td></tr></table></figure><p>问题：若 <code>age &gt; 30</code> 过滤性差（例如 80% 用户年龄 &gt;30），会先扫描大量数据，再通过索引过滤。</p><p>优化后：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> users </span><br><span class="line"><span class="keyword">where</span> city <span class="operator">=</span> <span class="string">&#x27;北京&#x27;</span>      <span class="comment">-- 先执行：通过索引快速过滤 city</span></span><br><span class="line"><span class="keyword">and</span> age <span class="operator">&gt;</span> <span class="number">30</span>;         <span class="comment">-- 后执行：仅对少量数据检查 age</span></span><br></pre></td></tr></table></figure><p>优先利用 <code>city</code> 索引快速缩小数据集，再检查 <code>age</code> 条件，减少计算量。</p><p>最后可以再通过 <code>EXPLAIN</code> 分析执行计划，验证优化效果。</p><h3 id="不要使用ORDER-BY-RAND"><a href="#不要使用ORDER-BY-RAND" class="headerlink" title="不要使用ORDER BY RAND()"></a>不要使用<code>ORDER BY RAND()</code></h3><p>想打乱返回的数据行？随机挑一个数据？但你却不了解这样做有多么可怕的性能问题。</p><p>如果你真的想把返回的数据行打乱了，你有 N 种方法可以达到这个目的。而这样使用只让你的数据库的性能呈指数级的下降。这里的问题是：MySQL会不得不去执行 RAND() 函数（很耗 CPU），而且这是为每一行记录去记行（扫全表），然后再对其排序，就算是用了 <code>limit 1</code> 也无济于事（因为要排序）。</p><h3 id="优化GROUP-BY"><a href="#优化GROUP-BY" class="headerlink" title="优化GROUP BY"></a>优化<code>GROUP BY</code></h3><p><code>GROUP BY</code> 关键字，它主要的功能是去重和分组。</p><p><strong>从排序优化</strong><br>当使用 <code>GROUP BY</code> 分组时，MySQL 默认会按分组字段的升序对结果进行排序（即使没有显式使用 <code>ORDER BY</code>）。这种排序操作会触发 <code>Using filesort</code>（文件排序），尤其是在分组字段未使用索引时，可能会显著增加查询时间。并且尽量让 <code>group by</code> 过程⽤上表的索引。<br>确认⽅法是 <code>explain</code> 结果⾥没有 <code>Using temporary</code> 和 <code>Using filesort</code>。</p><p>如果业务逻辑不需要结果有序（例如仅需要统计结果），禁用排序可以提升性能。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> … <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">NULL</span>;  <span class="comment">-- 禁止排序</span></span><br></pre></td></tr></table></figure><hr><p><strong>从条件优化</strong><br>通常它会跟<code>having</code>一起配合使用，表示分组后再根据一定的条件过滤数据。</p><p>反例：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> user_id,user_name <span class="keyword">from</span> <span class="keyword">order</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> user_id,user_name</span><br><span class="line"><span class="keyword">having</span> user_id <span class="operator">&lt;=</span> <span class="number">200</span>;</span><br></pre></td></tr></table></figure><p>这种写法性能不好，它先把所有的订单根据用户id分组之后，再去过滤用户id大于等于200的用户。分组是一个相对耗时的操作，为什么我们不先缩小数据的范围之后，再分组呢？</p><p>正例：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> user_id,user_name <span class="keyword">from</span> <span class="keyword">order</span></span><br><span class="line"><span class="keyword">where</span> user_id <span class="operator">&lt;=</span> <span class="number">200</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> user_id,user_name</span><br></pre></td></tr></table></figure><p>使用where条件在分组前，就把多余的数据过滤掉了，这样分组时效率就会更高一些。</p><blockquote><p>其实这是一种思路，不仅限于group by的优化。我们的sql语句在做一些耗时的操作之前，应尽可能缩小数据范围，这样能提升sql整体的性能。</p></blockquote><h3 id="JOIN查询"><a href="#JOIN查询" class="headerlink" title="JOIN查询"></a><code>JOIN</code>查询</h3><p>我们在涉及到多张表联合查询的时候，一般会使用<code>join</code>关键字。</p><p><strong>索引优化</strong><br>如果你的应用程序有很多 <code>JOIN</code> 查询，你应该确认两个表中 <code>JOIN</code> 的字段是被建过<strong>索引</strong>的。这样，MySQL 内部会启动为你优化 <code>JOIN</code> 语句的机制。</p><p>而且，这些被用来 <code>JOIN</code> 的字段，应是<strong>相同类型</strong>的。例如：如果你要把 <code>DECIMAL</code> 字段和一个 <code>INT</code> 字段 <code>JOIN</code> 在一起，MySQL 就无法使用它们的索引。对于 <code>STRING</code> 类型，还需要有<strong>相同的字符集</strong>才行（两个表的字符集有可能不一样）。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> company_name <span class="keyword">from</span> users</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> companies <span class="keyword">on</span> users.state <span class="operator">=</span> companies.state</span><br><span class="line"><span class="keyword">where</span> users.id <span class="operator">=</span> ...</span><br></pre></td></tr></table></figure><p>例如以上两个 state 字段应该是被建过索引的，而且应是相当类型、相同字符集的。</p><hr><p><strong>小表驱动大表</strong><br>而 <code>join</code> 使用最多的是 <code>left join</code> 和 <code>inner join</code>。</p><ul><li><code>left join</code>：求两个表的交集外加左表剩下的数据。</li><li><code>inner join</code>：求两个表交集的数据。</li></ul><p><code>join</code> 用法亦存在小表驱动大表的思想；如果两张表使用 <code>left join</code> 关联，MySQL 会默认用 <code>left join</code> 关键字左边的表，去驱动它右边的表。如果左边的表数据很多时，就会出现性能问题。</p><p>假设有两张表，<code>users</code>（用户表，大表）存在1000 万条数据。<code>orders</code>（订单表，小表）存在100 万条数据。现在需要查询所有用户及其订单信息（包含无订单的用户）。</p><p>低效写法（大表驱动小表）</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 使用 left join，左表 users 是大表</span></span><br><span class="line"><span class="keyword">select</span> u.id, u.name, o.order_id, o.amount</span><br><span class="line"><span class="keyword">from</span> users u</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> orders o <span class="keyword">on</span> u.id <span class="operator">=</span> o.user_id</span><br><span class="line"><span class="keyword">where</span> u.country <span class="operator">=</span> <span class="string">&#x27;cn&#x27;</span>;  <span class="comment">-- 假设查询中国用户</span></span><br></pre></td></tr></table></figure><p><code>left join</code> 强制以左表 <code>users</code> 作为驱动表，需遍历 1000 万行。即使 <code>orders.user_id</code> 有索引，仍需对 1000 万行的 <code>users</code> 逐行查找右表。</p><p>优化方案：使用 <code>inner join</code><br>如果两张表使用 <code>inner join</code> 关联，MySQL 会自动选择两张表中的小表，去驱动大表，所以性能上不会有太大的问题。（自动小表驱动大表）</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 仅查询有订单的中国用户（inner join）</span></span><br><span class="line"><span class="keyword">select</span> u.id, u.name, o.order_id, o.amount</span><br><span class="line"><span class="keyword">from</span> orders o                  <span class="comment">-- 小表作为驱动表</span></span><br><span class="line"><span class="keyword">inner</span> <span class="keyword">join</span> users u <span class="keyword">on</span> o.user_id <span class="operator">=</span> u.id</span><br><span class="line"><span class="keyword">where</span> u.country <span class="operator">=</span> <span class="string">&#x27;cn&#x27;</span>;</span><br></pre></td></tr></table></figure><p>总结：<br>在用 <code>left join</code> 关联查询时，左边要用小表，右边可以用大表。如果能用 <code>inner join</code> 的地方，尽量少用 &#96;left join。</p><h3 id="高效的分页"><a href="#高效的分页" class="headerlink" title="高效的分页"></a>高效的分页</h3><p>有时候，列表页在查询数据时，为了避免一次性返回过多的数据影响接口性能，我们一般会对查询接口做分页处理。</p><p>在mysql中分页一般用的<code>limit</code>关键字：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id,name,age <span class="keyword">from</span> <span class="keyword">user</span> limit <span class="number">10</span>,<span class="number">20</span>;</span><br></pre></td></tr></table></figure><p>如果表中数据量少，用limit关键字做分页，没啥问题。但如果表中数据量很多，用它就会出现性能问题。</p><p>比如现在分页参数变成了：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id,name,age <span class="keyword">from</span> <span class="keyword">user</span> limit <span class="number">1000000</span>, <span class="number">20</span>;</span><br></pre></td></tr></table></figure><p>mysql 会查到 1000020 条数据，然后丢弃前面的 1000000 条，只查后面的 20 条数据，这个是非常浪费资源的。那么，这种海量数据该怎么分页呢？</p><p>优化后：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id,name,age <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> id <span class="operator">&gt;</span> <span class="number">1000000</span> limit <span class="number">20</span>;</span><br></pre></td></tr></table></figure><p>先找到上次分页最大的id，然后利用id上的索引查询。不过该方案，要求id是连续的，并且有序的。</p><p>还能使用<code>between</code>优化分页。但需要注意的是 <code>between</code> 要在唯一索引上分页，不然会出现每页大小不一致的问题。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id,name,age <span class="keyword">from</span> <span class="keyword">user</span> <span class="keyword">where</span> id <span class="keyword">between</span> <span class="number">1000000</span> <span class="keyword">and</span> <span class="number">1000020</span>;</span><br></pre></td></tr></table></figure><h3 id="避免函数运算导致索引失效"><a href="#避免函数运算导致索引失效" class="headerlink" title="避免函数运算导致索引失效"></a>避免函数运算导致索引失效</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t <span class="keyword">where</span> <span class="keyword">year</span>(d) <span class="operator">&gt;=</span> <span class="number">2016</span>;</span><br></pre></td></tr></table></figure><p>即使 d 字段有索引，也会全盘扫描，因为在 <code>year(d) &gt;= 2016</code> 中，<code>year(d)</code> 是对字段 d 的函数运算。数据库无法直接使用 d 的索引，因为索引存储的是原始值（如日期 2023-01-01），而非运算后的结果（如 2023）。应该优化为：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t <span class="keyword">where</span> d <span class="operator">&gt;=</span> <span class="string">&#x27;2016-01-01&#x27;</span>;</span><br></pre></td></tr></table></figure><h3 id="使用IN替换OR"><a href="#使用IN替换OR" class="headerlink" title="使用IN替换OR"></a>使用<code>IN</code>替换<code>OR</code></h3><p>低效查询</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t <span class="keyword">where</span> LOC_ID <span class="operator">=</span> <span class="number">10</span> <span class="keyword">or</span> LOC_ID <span class="operator">=</span> <span class="number">20</span> <span class="keyword">or</span> LOC_ID <span class="operator">=</span> <span class="number">30</span>;</span><br></pre></td></tr></table></figure><p>若 LOC_ID 上有非聚簇索引，数据库需要为每个 <code>or</code> 条件单独执行一次索引查询。即分别以 10, 20, 30 为条件查询了三次</p><p>⾼效查询</p><p>而使⽤ <code>in</code> 之后只⾛⼀次。MySQL对于 <code>in</code> 做了相应的优化，即将 <code>in</code> 中的常量全部存储在⼀个数组⾥⾯，⽽且这个数组是排好序的，通过一次索引扫描完成所有条件的匹配。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t <span class="keyword">where</span> LOC_IN <span class="keyword">in</span> (<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>);</span><br></pre></td></tr></table></figure><p>但是如果数值较多，产⽣的消耗也是⽐较⼤的。再例如：<code>in(1, 2, 3)</code> 对于连续的数值，能⽤ <code>between</code> 就不要⽤ <code>in</code> 了；再或者使⽤连接来替换。</p><h3 id="LIKE使用右模糊"><a href="#LIKE使用右模糊" class="headerlink" title="LIKE使用右模糊"></a><code>LIKE</code>使用右模糊</h3><p><code>LIKE</code>双百分号⽆法使⽤到索引</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t <span class="keyword">where</span> name <span class="keyword">like</span> <span class="string">&#x27;%de%&#x27;</span>;</span><br></pre></td></tr></table></figure><p>应优化为右模糊</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t <span class="keyword">where</span> name <span class="keyword">like</span> <span class="string">&#x27;de%&#x27;</span>;</span><br></pre></td></tr></table></figure><h2 id="表结构优化"><a href="#表结构优化" class="headerlink" title="表结构优化"></a>表结构优化</h2><ol><li><p><strong>永远为每张表创建主键</strong><br> 我们应该为数据库⾥的每张表都设置⼀个 id 作为主键，最好还是 <code>INT</code> 类型的（推荐使⽤  <code>UNSIGNED</code> 即⽆符号化），并设置上⾃动增加的 <code>AUTO_INCREMENT</code> 标志。</p><ul><li>表数据的存储在磁盘中是按照主键顺序存放的，所以使⽤主键查询数据速度最快。</li><li><code>INT</code> 类型相⽐字符串类型，其⻓度更为固定，查询效率更⾼。</li><li>还有⼀些操作需要⽤到主键，⽐如集群、分区等。在这些情况下，主键的性能和设置变得⾮常重要。</li></ul><p> 所以建表时⼀定要带有主键，后续优化效果最好。</p></li><li><p><strong>固定⻓度的表会更快</strong><br> 如果表中的所有字段都是“固定⻓度”的，整个表会被认为是 “static” 或 “fixed-length”。 例如，表中没有如下类型的字段： <code>VARCHAR</code>、<code>TEXT</code>、<code>BLOB</code>。只要你包括了其中⼀个这些字段，那么这个表就不是“固定⻓度静态表”了，这样，MySQL 引擎会⽤另⼀种⽅法来处理。</p><p> 固定⻓度的表会提⾼性能，因为 MySQL 搜寻得会更快⼀些，因为这些固定的⻓度是很容易计算下⼀个数据的偏移量，所以读取的⾃然也会很快。⽽如果字段不是定⻓的，那么，每⼀次要找下⼀条的话，需要程序找到主键。</p><p> 并且，固定⻓度的表也更容易被缓存和重建。不过，唯⼀的副作⽤是，固定⻓度的字段会浪费⼀些空间，因为定⻓的字段⽆论你⽤不⽤，他都是要分配那么多的空间。</p></li><li><p><strong>通过拆分表结构，提⾼访问效率</strong><br> 把数据库中的表按列变成⼏张表的⽅法，这样可以降低表的复杂度和字段的数⽬，从⽽达到优化的⽬的。</p></li><li><p><strong>越⼩的列会越快</strong><br> 对于⼤多数的数据库引擎来说，硬盘操作可能是最重⼤的瓶颈。所以，把你的数据变得紧凑会对这种情况⾮常有帮助，因为这减少了对硬盘的访问。<br> 如果⼀个表只会有⼏列罢了（⽐如说字典表、配置表），那么，我们就没有理由使⽤ <code>INT</code> 来做主键，使⽤ <code>MEDIUMINT</code>、<code>SMALLINT</code> 或是更⼩的 <code>TINYINT</code> 会更经济⼀些。如果你不需要记录时间，使⽤ <code>DATE</code> 要⽐ <code>DATETIME</code> 好得多。</p></li><li><p><strong>字段类型</strong><br> 用 <code>INT</code> 替代 <code>VARCHAR</code> 存储性别、状态等枚举值；用 <code>DATETIME</code> 替代 <code>VARCHAR</code> 存储时间。</p></li><li><p><strong>范式与反范式</strong><br> 高频查询的关联字段可冗余存储（如订单表中冗余用户名称），减少 <code>JOIN</code> 次数。  </p></li><li><p><strong>分区与分表</strong>：  </p><ul><li>对大表按时间或范围分区（如按 <code>create_time</code> 分区），加速范围查询。  </li><li>通过水平分表（如按用户ID哈希）解决单表数据量过大问题。</li></ul></li></ol><h2 id="MySQL服务端参数优化"><a href="#MySQL服务端参数优化" class="headerlink" title="MySQL服务端参数优化"></a>MySQL服务端参数优化</h2><p><strong>Innodb_buffer_pool_size</strong><br>影响性能的最主要参数，⼀般建议配置为系统总内存的 70-80%，这个参数决定了服务可分配的最⼤内存。</p><p><strong>Innodb_log_buffer_size</strong><br>顾名思义，这个参数就是⽤来设置 Innodb 的 Log Buffer ⼤⼩的，系统默认值为 1MB 。<br>Log Buffer 的主要作⽤就是缓冲 Log 数据，提⾼写 Log 的 I&#x2F;O 性能。<br>⼀般来说，如果你的系统不是写负载⾮常⾼且以⼤事务居多的话， 8MB 以内的⼤⼩就完全⾜够了。</p><p><strong>连接数</strong><br>当数据库连接池被占满时，如果有新的 SQL 语句要执行，只能排队等待，等待连接池中的连接被释放（等待之前的 SQL 语句执行完成）。</p><p>如果监控发现数据库连接池的使用率过高，甚至是经常出现排队的情况，则需要进行调优。</p><p><em>查看&#x2F;设置最大连接数</em></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查看最大连接数</span></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;%max_connection%&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------+-------+</span></span><br><span class="line"><span class="operator">|</span> Variable_name         <span class="operator">|</span> <span class="keyword">Value</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------+-------+</span></span><br><span class="line"><span class="operator">|</span> extra_max_connections <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> max_connections       <span class="operator">|</span> <span class="number">2512</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------+-------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 重新设置最大连接数</span></span><br><span class="line"><span class="keyword">set</span> <span class="keyword">global</span> max_connections<span class="operator">=</span><span class="number">1000</span>;</span><br></pre></td></tr></table></figure><p>在 &#x2F;etc&#x2F;my.cnf 里面设置数据库的最大连接数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">max_connections = 1000</span><br></pre></td></tr></table></figure><p><em>查看当前连接数</em></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> status <span class="keyword">like</span>  <span class="string">&#x27;Threads%&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+-------+</span></span><br><span class="line"><span class="operator">|</span> Variable_name     <span class="operator">|</span> <span class="keyword">Value</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+-------+</span></span><br><span class="line"><span class="operator">|</span> Threads_cached    <span class="operator">|</span> <span class="number">32</span>    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Threads_connected <span class="operator">|</span> <span class="number">10</span>    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Threads_created   <span class="operator">|</span> <span class="number">50</span>    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Threads_rejected  <span class="operator">|</span> <span class="number">0</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Threads_running   <span class="operator">|</span> <span class="number">1</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+-------+</span></span><br><span class="line"><span class="number">5</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><ul><li>Threads_connected：表示当前连接数。跟 show processlist 结果相同。准确的来说，Threads_running 代表的是当前并发数。</li><li>Threads_running：表示激活的连接数。一般远低于 connected 数值。</li><li>Threads_created：表示创建过的线程数。</li></ul><p>如果我们在 MySQL 服务器配置文件中设置了 thread_cache_size，那么当客户端断开之后，服务器处理此客户的线程将会缓存起来以响应下一个客户而不是销毁（前提是缓存数未达上限）。<br>如果发现 Threads_created 值过大的话，表明 MySQL 服务器一直在创建线程，这也是比较耗资源，因此可以适当增加配置文件中 thread_cache_size 值。</p><p><strong>thread_cache_size</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;thread_cache_size&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+-------+</span></span><br><span class="line"><span class="operator">|</span> Variable_name <span class="operator">|</span> <span class="keyword">Value</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+-------+</span></span><br><span class="line"><span class="operator">|</span> thread_cache_size <span class="operator">|</span> <span class="number">100</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+-------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hexo+Github Pages+Github Action</title>
      <link href="/6178418ef979/"/>
      <url>/6178418ef979/</url>
      
        <content type="html"><![CDATA[<p>本博客是使用<a href="https://hexo.io/zh-cn/">Hexo博客框架</a>+利用Github Pages建立的一个静态站点</p><p>唯一的缺点是Hexo编译代码后，基本不能对编译后的文件进行更改，添加新的文章也需要使用Hexo对其重新编译；所以只能在设备部署Hexo, NodeJS之类后才能给新添加的东西进行编译。</p><p>解决办法就是利用Github Action之类的进行CICD。这样无需部署任何服务，只要仓库收到了新的提交，即可自动完成上述的一系列操作。（前提是文件、位置啥的符合Hexo规范）</p><p>首先了解一下什么是Github Pages和Action吧：<br><a href="https://docs.github.com/zh/pages/getting-started-with-github-pages">GitHub Pages 使用入门</a><br><a href="https://docs.github.com/zh/actions/writing-workflows/quickstart">GitHub Actions 快速入门</a></p><p>使用也很简单，跟其他CICD区别不大。</p><p>步骤：</p><ol><li>先给Hexo创建一个本地仓库和远程仓库</li><li>在Hexo项目根目录创建<code>.github/workflows/deploy.yml</code>文件，并填写工作流</li><li>回到Hexo的配置文件<code>_config.yml</code>，<code>deploy: branch</code>参数改成<code>gh-pages</code></li><li>到Github个人设置的开发者设置处添加一个密钥，必须拥有<code>repo</code>和<code>workflow</code>权限</li><li>到Hexo的Github远程仓库<code>Setting-&gt;Security-&gt;Actions secrets and variables-&gt;action</code>添加上面生成的密钥，名字写成<code>GH_TOKEN</code></li><li>给这个远程仓库创建一个<code>gh-pages</code>分支，在远程仓库<code>Setting-&gt;Pages</code>处，选择刚才创建的分支作为静态页面的文件源</li><li>本地推送后，等待action完成即可访问静态页面（<code>userName.github.io/[repo]</code>）</li></ol><blockquote><p>工作流示例：<a href="https://github.com/ECAMT35/ecamt35.github.io/blob/master/.github/workflows/deploy.yml">Github Action’s workflow</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 其他 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> Github </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Arch+Labwc 使用</title>
      <link href="/ce269dce74a9/"/>
      <url>/ce269dce74a9/</url>
      
        <content type="html"><![CDATA[<p>Archlinux + Labwc WM (Wayland)</p><p>My dotfiles : <a href="https://github.com/ECAMT35/dotfiles.git">https://github.com/ECAMT35/dotfiles.git</a></p><h1 id="Arch"><a href="#Arch" class="headerlink" title="Arch"></a>Arch</h1><p>主文件系统：ext4<br>分区：&#x2F;boot&#x3D;1G, &#x2F;&#x3D;128G, SWAP&#x3D;32G, &#x2F;home&#x3D;remaining, total&#x3D;1T<br>boot：GRUB</p><p>命令解释器: bash<br>文本编辑器: neovim<br>网络: NetworkManager<br>硬盘检测: smartmontools<br>监控: htop<br>笔记本电源管理: TLP</p><h1 id="labwc"><a href="#labwc" class="headerlink" title="labwc"></a>labwc</h1><p>官方文档：<a href="https://labwc.github.io/integration.html">labwc</a></p><h2 id="桌面环境软件包"><a href="#桌面环境软件包" class="headerlink" title="桌面环境软件包"></a>桌面环境软件包</h2><p>字体:<br>noto-fonts<br>noto-fonts-cjk<br>ttf-nerd-fonts-symbols<br>ttf-nerd-fonts-symbols-common</p><p>屏幕管理:<br>锁屏: swaylock + swayidle<br>关闭屏幕: wlopm + swayidle<br>屏幕分辨率: <a href="https://sr.ht/~emersion/wlr-randr/">wlr-randr</a><br>背光调节: brightnessctl<br>桌面壁纸: <a href="https://github.com/swaywm/swaybg">swaybg</a><br>bar: waybar</p><p>终端模拟器: foot<br>输入法: fcitx5<br>启动器: <a href="https://man.archlinux.org/man/wofi.1.en">wofi</a><br>剪切板: wofi + wl-clipboard + <a href="https://github.com/sentriz/cliphist">cliphist</a><br>截图: <a href="https://sr.ht/~emersion/grim/">grim</a> + slurp + swappy<br>终端文件管理: yazi<br>浏览器: firefox<br>文件下载: aria2c, <a href="https://github.com/P3TERX/aria2.conf">aria2c config</a><br><del>消息提醒: dunst</del><br>安卓模拟器: waydroid</p><p>音视频媒体:<br>声音设置: alsa + pipewire + wireplumber<br>图片查看器: swayimg<br>视频播放器: mpv<br>视频录制: OBS<br>XDG 桌面门户: xdg-desktop-portal-gtk, xdg-desktop-portal-wlr</p><p>游戏: wine, steam, <del>KVM</del></p><p>文档编辑: LibreOffice, obsiadian<br>画板、图片编辑: krita<br>小沙箱: flatpak</p><hr><p>其他wayland应用查看<br><a href="https://arewewaylandyet.com/">https://arewewaylandyet.com/</a></p><h1 id="优化部分"><a href="#优化部分" class="headerlink" title="优化部分"></a>优化部分</h1><h2 id="ext4挂载选项"><a href="#ext4挂载选项" class="headerlink" title="ext4挂载选项"></a>ext4挂载选项</h2><ul><li>noatime</li><li>commit&#x3D;180</li><li>开启 fast_commit</li></ul><h2 id="硬盘"><a href="#硬盘" class="headerlink" title="硬盘"></a>硬盘</h2><ul><li>开启 Periodic TRIM</li></ul><h2 id="禁用看门狗"><a href="#禁用看门狗" class="headerlink" title="禁用看门狗"></a>禁用看门狗</h2><ul><li>禁用看门狗</li></ul><h2 id="视频硬件加速"><a href="#视频硬件加速" class="headerlink" title="视频硬件加速"></a>视频硬件加速</h2><p>相关驱动(部分已经合并到mesa)：<br><a href="https://wiki.archlinux.org/title/Hardware_video_acceleration">https://wiki.archlinux.org/title/Hardware_video_acceleration</a></p><p>firefox进<code>about:config</code>设置：<br><a href="https://wiki.archlinux.org/title/Firefox#Hardware_video_acceleration">https://wiki.archlinux.org/title/Firefox#Hardware_video_acceleration</a></p><ul><li>media.ffmpeg.vaapi.enabled&#x3D;true</li><li>media.hardware-video-decoding.force-enabled&#x3D;true</li></ul><h2 id="firefox"><a href="#firefox" class="headerlink" title="firefox"></a>firefox</h2><p>关闭磁盘缓存：</p><ul><li>browser.cache.disk.enable&#x3D;false</li><li>browser.cache.memory.enable&#x3D;true</li></ul><p>其他可选调整：<br><a href="https://wiki.archlinux.org/title/Firefox/Tweaks">https://wiki.archlinux.org/title/Firefox/Tweaks</a><br><a href="https://github.com/arkenfox/user.js/">https://github.com/arkenfox/user.js/</a></p>]]></content>
      
      
      <categories>
          
          <category> GNU/Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Archlinux </tag>
            
            <tag> Labwc </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>置顶</title>
      <link href="/78fcc30b2e20/"/>
      <url>/78fcc30b2e20/</url>
      
        <content type="html"><![CDATA[<p>我不时会思考这样的事情。</p><p>世界的界限在哪里呢……</p><p>世界的……世界的尽头的再尽头……</p><p>如果有那种地方……</p><p>如果我能站在那种地方……我还能不能跟平时一样眺望那尽头的风景呢？？会怎样呢……</p><p>把这当做理所当然……觉得有点奇怪吧？</p><p>因为那里是世界的尽头啊。</p><p>是世界的界限哦。</p><p>如果我能看得到……那世界的界限……不就与“我的界限”是同义的了？</p><p>因为，我在那个地方所看到的世界……不就是我一直见到的……我的世界吗。</p><p>也就是说，世界的界限……即是我的界限。</p><p>世界是我所看到的、触摸到的、以及感受到的。</p><p>那么，世界到底是什么呢。</p><p>我会想，世界跟我区别是什么呢……</p><p>有吗？</p><p>世界跟我的差别。</p><p>所以我说道。</p><p>我跟世界没有什么差别……</p><p>我如此坚信着。</p><p>正因如此，我抱有疑问。</p><p>包含了他人的世界是什么？</p><p>如果世界就是我，那其它的人是什么？</p><p>他们也拥有世界吗？</p><p>如果有，那些是互相独立、互不相交的世界吗？</p><p>还是说这些世界能够相交呢？</p><p>所有的世界……所有的灵魂……能看到同样的一个世界吗？</p><p>我所看到的、世界尽头的风景。</p><p>世界的风景。</p><p>最尽头的风景。</p><p>在那个时候，你也同样地在看着世界的尽头吧。</p><p>你所看到的世界尽头的天空。</p><p>世界之界限的天空。</p><p>最尽头的天空。</p><p>我能不能够和你一起看呢？</p><p>在那里看着同一个世界的终结……</p><p>虽然不在同一片天空之下……却在同一片天空之下看着……</p><p>……我不时会思考这样的事情。</p><p>在回忆起……</p><p>回忆起那片向日葵前方的坡道时。</p><p>——— <em>《Wonderful Everyday Down the Rabbit-Hole》</em></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>系统维护日志</title>
      <link href="/b8b5bdbd8486/"/>
      <url>/b8b5bdbd8486/</url>
      
        <content type="html"><![CDATA[<h1 id="Fontconfig"><a href="#Fontconfig" class="headerlink" title="Fontconfig"></a>Fontconfig</h1><p>参考资料：<br><a href="https://wiki.archlinux.org/title/Font_configuration">Font configuration</a></p><p><a href="https://www.freedesktop.org/wiki/Software/fontconfig/">Fontconfig</a> 是一个用于向应用程序提供可用的<a href="https://wiki.archlinuxcn.org/wiki/%E5%AD%97%E4%BD%93" title="字体">字体</a>列表，以及字体渲染配置的库。</p><p>Fontconfig 的默认字体路径是 <code>/usr/share/fonts/</code> 和 <code>~/.local/share/fonts</code>（以及过时的 <code>~/.fonts/</code>）。Fontconfig 将在这些路径下递归查找字体。</p><p>用户配置文件位于 <code>$XDG_CONFIG_HOME/fontconfig/fonts.conf</code> 中（通常是 <code>$HOME/.config/fontconfig/fonts.conf</code>）。全局配置文件位于 <code>/etc/fonts/local.conf</code>。 用户配置优先级高于全局配置。两个文件使用相同的语法。<br>Fontconfig 配置文件使用 <a href="https://zh.wikipedia.org/wiki/XML" title="zhwp:XML">XML</a> 格式，其需要的头部如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">fontconfig</span> <span class="keyword">SYSTEM</span> <span class="string">&quot;urn:fontconfig:fonts.dtd&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">fontconfig</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- settings go here --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">fontconfig</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="中文字体显示奇怪"><a href="#中文字体显示奇怪" class="headerlink" title="中文字体显示奇怪"></a>中文字体显示奇怪</h2><p>June 4, 2024</p><p>本次更新后中文不再是 Noto Sans 字体，变成了更细、发虚的字体（各种意义上太难看了</p><p>Arch论坛看了下：<br>由于近期 noto-fonts-cjk 打包变化，导致默认CJK回落字体不再是 Noto 系列字体。<a href="https://gitlab.archlinux.org/archlinux/packaging/packages/noto-fonts-cjk/-/issues/2">详情</a></p><p>解决方案：<br>在 ~&#x2F;.config&#x2F;fontconfig&#x2F; 下 新建一个字体文件（xxx.conf），让 <code>Noto Sans CJK SC</code> 优先使用即可：<br>参考：<a href="https://wiki.archlinuxcn.org/wiki/%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87%E6%9C%AC%E5%9C%B0%E5%8C%96">修正简体中文显示为异体（日文）字形</a></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">fontconfig</span> <span class="keyword">SYSTEM</span> <span class="string">&quot;fonts.dtd&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">fontconfig</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">alias</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">family</span>&gt;</span>sans-serif<span class="tag">&lt;/<span class="name">family</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">prefer</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">family</span>&gt;</span>Noto Sans CJK SC<span class="tag">&lt;/<span class="name">family</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">family</span>&gt;</span>Noto Sans CJK TC<span class="tag">&lt;/<span class="name">family</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">family</span>&gt;</span>Noto Sans CJK JP<span class="tag">&lt;/<span class="name">family</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">prefer</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">alias</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">alias</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">family</span>&gt;</span>monospace<span class="tag">&lt;/<span class="name">family</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">prefer</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">family</span>&gt;</span>Noto Sans Mono CJK SC<span class="tag">&lt;/<span class="name">family</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">family</span>&gt;</span>Noto Sans Mono CJK TC<span class="tag">&lt;/<span class="name">family</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">family</span>&gt;</span>Noto Sans Mono CJK JP<span class="tag">&lt;/<span class="name">family</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">prefer</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">alias</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">fontconfig</span>&gt;</span></span><br></pre></td></tr></table></figure><h1 id="Waydroid"><a href="#Waydroid" class="headerlink" title="Waydroid"></a>Waydroid</h1><p><del>没有waydroid，我怎么玩碧蓝航线啊（悲</del></p><h2 id="ERROR-Can’t-open-dev-binder-No-such-file-or-directory"><a href="#ERROR-Can’t-open-dev-binder-No-such-file-or-directory" class="headerlink" title="ERROR: Can’t open &#x2F;dev&#x2F;binder: No such file or directory"></a>ERROR: Can’t open &#x2F;dev&#x2F;binder: No such file or directory</h2><p>December 24, 2024</p><p>更新后发现 waydroid 挂了，表现为 <code>waydroid session start</code> 出错：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[13:02:43] Failed to add presence handler: None  </span><br><span class="line">[gbinder] ERROR: Can&#x27;t open /dev/binder: No such file or directory</span><br></pre></td></tr></table></figure><p>看看 <code>binder_linux-dkms</code> 貌似也没啥问题</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">pacman -Qi binder_linux-dkms-git</span></span><br><span class="line">名字           : binder_linux-dkms-git</span><br><span class="line">版本           : r57.ee4c25f-3</span><br><span class="line">描述           : Android kernel driver fork by @choff in DKMS format, binder only</span><br><span class="line">架构           : any</span><br><span class="line">URL            : https://github.com/choff/anbox-modules</span><br><span class="line">软件许可       : GPL-2.0-only</span><br><span class="line">组             : 无</span><br><span class="line">提供           : 无</span><br><span class="line">依赖于         : dkms</span><br><span class="line">可选依赖       : 无</span><br><span class="line">依赖它         : 无</span><br><span class="line">被可选依赖     : 无</span><br><span class="line">与它冲突       : binder_linux-dkms  anbox-modules-dkms</span><br><span class="line">取代           : binder_linux-dkms</span><br><span class="line">安装后大小     : 279.35 KiB</span><br><span class="line">打包者         : lilac-alarm (on behalf of i7arch) &lt;i7arch@member.fsf.org&gt;</span><br><span class="line">编译日期       : 2024年10月03日 星期四 19时16分59秒</span><br><span class="line">安装日期       : 2024年10月07日 星期一 19时46分44秒</span><br><span class="line">安装原因       : 单独指定安装</span><br><span class="line">安装脚本       : 否</span><br><span class="line">验证者         : SHA-256 校验值  数字签名</span><br></pre></td></tr></table></figure><p>去论坛看了下发现上周core&#x2F;linux已经启用了 binderfs 的MR合并，那可能是冲突了？然而卸载了<code>binder_linux-dkms-git</code>并没有成功启动。</p><p>最后根据waydroid文档的建议，尝试重置镜像之后就能正常使用了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">sudo</span> waydroid init -f</span></span><br></pre></td></tr></table></figure><h2 id="gbinder-Service-manager-dev-anbox-binder-has-appeared"><a href="#gbinder-Service-manager-dev-anbox-binder-has-appeared" class="headerlink" title="[gbinder] Service manager &#x2F;dev&#x2F;anbox-binder has appeared"></a><code>[gbinder]</code> Service manager &#x2F;dev&#x2F;anbox-binder has appeared</h2><p>January 18, 2025</p><p>今天重装了系统，发现Waydroid是挂的，一直在启动中挂起：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">waydroid session start</span></span><br><span class="line"></span><br><span class="line">[11:22:15] Starting waydroid session</span><br><span class="line">[gbinder] Service manager /dev/anbox-binder has appeared</span><br></pre></td></tr></table></figure><p>日志里只有lxc的地方看上去有点奇怪，但是我看不懂（</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">waydroid <span class="built_in">log</span></span></span><br><span class="line">(000837) [22:08:19] % mkdir -p /dev/binderfs</span><br><span class="line">(000837) [22:08:19] % mount -t binder binder /dev/binderfs</span><br><span class="line">(000837) [22:08:19] % ln -s /dev/binderfs/anbox-hwbinder /dev/binderfs/anbox-vndbinder /dev/binderfs/anbox-binder /dev/binderfs/features /dev/binderfs/binder-control /dev/</span><br><span class="line">(000837) [22:08:19] Save config: /var/lib/waydroid/waydroid.cfg</span><br><span class="line">(000837) [22:08:19] % modprobe -q ashmem_linux</span><br><span class="line">(000837) [22:08:19] % lxc-info --version</span><br><span class="line">6.0.3</span><br><span class="line">(000837) [22:08:19] % mkdir -p /var/lib/waydroid/lxc/waydroid</span><br><span class="line">(000837) [22:08:19] % sh -c cat &quot;/usr/lib/waydroid/data/configs/config_base&quot; &quot;/usr/lib/waydroid/data/configs/config_3&quot; &quot;/usr/lib/waydroid/data/configs/config_4&quot; &gt; &quot;/var/lib/waydroid/lxc/waydroid/config&quot;</span><br><span class="line">(000837) [22:08:19] % sed -i s/LXCARCH/x86_64/ /var/lib/waydroid/lxc/waydroid/config</span><br><span class="line">(000837) [22:08:19] % cp -fpr /usr/lib/waydroid/data/configs/waydroid.seccomp /var/lib/waydroid/lxc/waydroid/waydroid.seccomp</span><br><span class="line">(000837) [22:08:19] % systemctl is-active -q apparmor</span><br><span class="line">(000837) [22:08:19] % mv /var/lib/waydroid/config_nodes /var/lib/waydroid/lxc/waydroid</span><br><span class="line">(000592) [22:08:19] % lxc-info -P /var/lib/waydroid/lxc -n waydroid -sH</span><br><span class="line">STOPPED</span><br><span class="line">(000592) [22:08:19] % modprobe -q ashmem_linux</span><br><span class="line">(000592) [22:08:19] % chmod 666 -R /dev/anbox-binder</span><br><span class="line">(000592) [22:08:19] % chmod 666 -R /dev/anbox-vndbinder</span><br><span class="line">(000592) [22:08:19] % chmod 666 -R /dev/anbox-hwbinder</span><br><span class="line">(000592) [22:09:15] % /usr/lib/waydroid/data/scripts/waydroid-net.sh start</span><br><span class="line">vnic is waydroid0</span><br><span class="line">(000592) [22:09:15] % systemctl is-active -q nfcd</span><br><span class="line">(000592) [22:09:15] % chmod 777 -R /dev/dri</span><br><span class="line">(000592) [22:09:15] % chmod 777 -R /dev/fb0</span><br><span class="line">(000592) [22:09:15] % chmod 777 -R /dev/video0</span><br><span class="line">(000592) [22:09:15] % chmod 777 -R /dev/video1</span><br><span class="line">(000592) [22:09:15] % mv /var/lib/waydroid/config_session /var/lib/waydroid/lxc/waydroid</span><br><span class="line">(000592) [22:09:15] % mount -o ro /usr/share/waydroid-extra/images/system.img /var/lib/waydroid/rootfs</span><br><span class="line">(000592) [22:09:15] % mkdir -p /var/lib/waydroid/overlay_work/system</span><br><span class="line">(000592) [22:09:15] % mount -t overlay -o ro,lowerdir=/var/lib/waydroid/overlay:/var/lib/waydroid/rootfs,upperdir=/var/lib/waydroid/overlay_rw/system,workdir=/var/lib/waydroid/overlay_work/system,xino=off overlay /var/lib/waydroid/rootfs</span><br><span class="line">(000592) [22:09:15] % mount -o ro /usr/share/waydroid-extra/images/vendor.img /var/lib/waydroid/rootfs/vendor</span><br><span class="line">(000592) [22:09:15] % mkdir -p /var/lib/waydroid/overlay_work/vendor</span><br><span class="line">(000592) [22:09:15] % mount -t overlay -o ro,lowerdir=/var/lib/waydroid/overlay/vendor:/var/lib/waydroid/rootfs/vendor,upperdir=/var/lib/waydroid/overlay_rw/vendor,workdir=/var/lib/waydroid/overlay_work/vendor,xino=off overlay /var/lib/waydroid/rootfs/vendor</span><br><span class="line">(000592) [22:09:15] % mount -o bind /var/lib/waydroid/waydroid.prop /var/lib/waydroid/rootfs/vendor/waydroid.prop</span><br><span class="line">(000592) [22:09:15] Save config: /var/lib/waydroid/waydroid.cfg</span><br><span class="line">(000592) [22:09:15] % lxc-start -P /var/lib/waydroid/lxc -F -n waydroid -- /init</span><br><span class="line">(000592) [22:09:15] New background process: pid=1129, output=background</span><br><span class="line">(000592) [22:09:15] % lxc-info -P /var/lib/waydroid/lxc -n waydroid -sH</span><br><span class="line">RUNNING</span><br><span class="line">(001076) [22:09:15] Skipping clipboard manager service because of missing pyclip package</span><br><span class="line">(001577) [22:09:41] % tail -n 60 -F /var/lib/waydroid/waydroid.log</span><br><span class="line">(001577) [22:09:41] *** output passed to waydroid stdout, not to this log ***</span><br></pre></td></tr></table></figure><p>排查了很久，根本找不到问题所在。直到我尝试用软解成功启动waydroid。那肯定是显卡的问题。有点纳闷我寻思也是混合模式啊，不应该是优先核显嘛…<br>而且检查结果也没问题。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">glxinfo | grep <span class="string">&#x27;OpenGL renderer&#x27;</span></span></span><br><span class="line">OpenGL renderer string: AMD Radeon 680M (radeonsi, rembrandt, LLVM 19.1.6, DRM 3.59, 6.12.9-arch1-1)</span><br></pre></td></tr></table></figure><p>看着waydroid的默认配置，我还是觉得和显卡有关，但是死活找不出原因（</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/var/lib/waydroid/waydroid_base.prop</span><br><span class="line">------------------------------------</span><br><span class="line">sys.use_memfd=true</span><br><span class="line">debug.stagefright.ccodec=0</span><br><span class="line">ro.hardware.gralloc=gbm</span><br><span class="line">ro.hardware.egl=mesa</span><br><span class="line">ro.hardware.vulkan=radeon</span><br><span class="line">ro.hardware.camera=v4l2</span><br><span class="line">ro.opengles.version=196609</span><br><span class="line">waydroid.system_ota=https://ota.waydro.id/system/lineage/waydroid_x86_64/VANILLA.json</span><br><span class="line">waydroid.vendor_ota=https://ota.waydro.id/vendor/waydroid_x86_64/MAINLINE.json</span><br><span class="line">waydroid.tools_version=1.4.3</span><br><span class="line">ro.vndk.lite=true</span><br></pre></td></tr></table></figure><p>直到我看到了一个issues：<br><a href="https://github.com/waydroid/waydroid/issues/1487">[gbinder] Service manager &#x2F;dev&#x2F;anbox-binder has appeared <em>than hangs</em></a></p><p>eglinfo看了下，已经确定是同一个问题，内核早加载的时候，优先使用了Nvidia</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">eglinfo -B</span></span><br><span class="line">GBM platform:</span><br><span class="line">EGL API version: 1.5</span><br><span class="line">EGL vendor string: NVIDIA</span><br><span class="line">EGL version string: 1.5</span><br><span class="line">EGL client APIs: OpenGL_ES OpenGL</span><br><span class="line">OpenGL core profile vendor: NVIDIA Corporation</span><br><span class="line">OpenGL core profile renderer: NVIDIA GeForce RTX 3060 Laptop GPU/PCIe/SSE2</span><br><span class="line">OpenGL core profile version: 4.6.0 NVIDIA 565.77</span><br><span class="line">OpenGL core profile shading language version: 4.60 NVIDIA</span><br><span class="line">OpenGL compatibility profile vendor: NVIDIA Corporation</span><br><span class="line">OpenGL compatibility profile renderer: NVIDIA GeForce RTX 3060 Laptop GPU/PCIe/SSE2</span><br><span class="line">OpenGL compatibility profile version: 4.6.0 NVIDIA 565.77</span><br><span class="line">OpenGL compatibility profile shading language version: 4.60 NVIDIA</span><br><span class="line">OpenGL ES profile vendor: NVIDIA Corporation</span><br><span class="line">OpenGL ES profile renderer: NVIDIA GeForce RTX 3060 Laptop GPU/PCIe/SSE2</span><br><span class="line">OpenGL ES profile version: OpenGL ES 3.2 NVIDIA 565.77</span><br><span class="line">OpenGL ES profile shading language version: OpenGL ES GLSL ES 3.20</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>解决办法是，在 <code>/etc/mkinitcpio.conf</code> 的HOOK数组上添加回来 <code>kms</code> ，并重做 <code>mkinitcpio</code> ，重启之后，gbm就会优先让AMD工作。最后再重置waydroid镜像就正常工作了</p><p><a href="https://wiki.archlinuxcn.org/wiki/NVIDIA#">在HOOK数组删 <code>kms</code> 模块的原因</a><br>但是当我加上 <code>kms</code> 后，也没在 journalctl -b 找到 <code>nouveau</code> 的东西，估计没啥大问题。</p><h2 id="镜像Bug"><a href="#镜像Bug" class="headerlink" title="镜像Bug"></a>镜像Bug</h2><p>May 20, 2025</p><p>今天久违更新了镜像，发现 <code>adb shell wm size 1280x720</code> 后鼠标触摸出错，只能点击部分区域（1280x720大小），应该是把Los20版本的一些东西搞到Los18版本出现的不兼容。</p><p>解决方法是回到推出Los20测试镜像前的Los18镜像，即版本时间线为2025-04-13的system和vendor。</p><p>关于如何自定义镜像版本：<br><a href="https://docs.waydro.id/faq/using-custom-waydroid-images">https://docs.waydro.id/faq/using-custom-waydroid-images</a></p><h1 id="屏幕刷新率"><a href="#屏幕刷新率" class="headerlink" title="屏幕刷新率"></a>屏幕刷新率</h1><p>February 04, 2025</p><p>今天更新后发现核显的刷新率只能以60HZ显示了（习惯了240HZ看60HZ真难受）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wlr-randr</span></span><br><span class="line">eDP-1 &quot;Thermotrex Corporation TL160ADMP11-0 (eDP-1)&quot;</span><br><span class="line">  Make: Thermotrex Corporation</span><br><span class="line">  Model: TL160ADMP11-0</span><br><span class="line">  Serial: (null)</span><br><span class="line">  Physical size: 350x220 mm</span><br><span class="line">  Enabled: yes</span><br><span class="line">  Modes:</span><br><span class="line">    2560x1600 px, 60.000000 Hz (preferred, current)</span><br><span class="line">    1920x1200 px, 60.000000 Hz</span><br><span class="line">    1920x1080 px, 60.000000 Hz</span><br><span class="line">    1600x1200 px, 60.000000 Hz</span><br><span class="line">    1680x1050 px, 60.000000 Hz</span><br><span class="line">    1280x1024 px, 60.000000 Hz</span><br><span class="line">    1440x900 px, 60.000000 Hz</span><br><span class="line">    1280x800 px, 60.000000 Hz</span><br><span class="line">    1280x720 px, 60.000000 Hz</span><br><span class="line">    1024x768 px, 60.000000 Hz</span><br><span class="line">    800x600 px, 60.000000 Hz</span><br><span class="line">    640x480 px, 60.000000 Hz</span><br><span class="line">  Position: 0,0</span><br><span class="line">  Transform: normal</span><br><span class="line">  Scale: 1.500000</span><br><span class="line">  Adaptive Sync: disabled</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">uname</span> -a</span></span><br><span class="line">Linux ATRI 6.13.1-arch1-1 #1 SMP PREEMPT_DYNAMIC Sun, 02 Feb 2025 01:02:29 +0000 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure><p>切换了一下内核发现又能核显240HZ了，估计是内核的bug。不太懂，摆了</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wlr-randr</span></span><br><span class="line">eDP-1 &quot;Thermotrex Corporation TL160ADMP11-0 (eDP-1)&quot;</span><br><span class="line">  Make: Thermotrex Corporation</span><br><span class="line">  Model: TL160ADMP11-0</span><br><span class="line">  Serial: (null)</span><br><span class="line">  Physical size: 350x220 mm</span><br><span class="line">  Enabled: yes</span><br><span class="line">  Modes:</span><br><span class="line">    2560x1600 px, 239.998001 Hz (preferred, current)</span><br><span class="line">    2560x1600 px, 59.999001 Hz (preferred)</span><br><span class="line">    1920x1200 px, 239.998001 Hz</span><br><span class="line">    1920x1080 px, 239.998001 Hz</span><br><span class="line">    1600x1200 px, 239.998001 Hz</span><br><span class="line">    1680x1050 px, 239.998001 Hz</span><br><span class="line">    1280x1024 px, 239.998001 Hz</span><br><span class="line">    1440x900 px, 239.998001 Hz</span><br><span class="line">    1280x800 px, 239.998001 Hz</span><br><span class="line">    1280x720 px, 239.998001 Hz</span><br><span class="line">    1024x768 px, 239.998001 Hz</span><br><span class="line">    800x600 px, 239.998001 Hz</span><br><span class="line">    640x480 px, 239.998001 Hz</span><br><span class="line">  Position: 0,0</span><br><span class="line">  Transform: normal</span><br><span class="line">  Scale: 1.500000</span><br><span class="line">  Adaptive Sync: disabled</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">uname</span> -a</span></span><br><span class="line">Linux ATRI 6.12.12-1-lts #1 SMP PREEMPT_DYNAMIC Sat, 01 Feb 2025 18:47:29 +0000 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure><p>August 20, 2025<br>七月的某次更新修复了这个问题，具体内容有点忘记了，做个结果补记一下</p><h1 id="home挂载失败"><a href="#home挂载失败" class="headerlink" title="&#x2F;home挂载失败"></a>&#x2F;home挂载失败</h1><p>开机显示<br><img src="/b8b5bdbd8486/20251021105415.png"><br>貌似是硬盘的问题，但是其他分区能挂载，应该不是整个盘炸了</p><p>由开机时的报错提示看应该是 <code>/home</code> 出了问题</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[FAILED] Failed to start File System Check on /dev/disk/by-uuid/0d34532b-4120-4ad6-8153-e208696ac4f1. See &#x27;systemctl status &quot;systemd-fsck@dev-disk-by\\x2duuid-0d34532b\\x2d4120\\x2d4ad6\\x2d8153\\x2de208696ac4f1.service&quot;&#x27; for details. [DEPEND] Dependency failed for /home. [DEPEND] Dependency failed for Local File Systems. [ OK ] Started D-Bus User Bus.</span><br></pre></td></tr></table></figure><p>挂载失败？使用 <code>blkid</code> 对比了<code>/etc/fstab</code>上的UUID好像也没问题。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lsblk</span></span><br><span class="line">NAME          MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS</span><br><span class="line">nvme0n1       259:5    0   1.9T  0 disk /mnt/data</span><br><span class="line">nvme1n1       259:0    0 931.5G  0 disk</span><br><span class="line">├─nvme1n1p1   259:1    0     1G  0 part /boot</span><br><span class="line">├─nvme1n1p2   259:2    0    32G  0 part [SWAP]</span><br><span class="line">├─nvme1n1p3   259:3    0   128G  0 part /</span><br><span class="line">└─nvme1n1p4   259:4    0 770.5G  0 part</span><br></pre></td></tr></table></figure><p>使用 <code>mount -a</code> 查看显示分区出现错误，奇怪的是再次使用 <code>lsblk</code> 查看又能挂载了（重试了几次发现是 <code>mount -a</code> 命令导致的，并且使用 <code>mount -a</code> 一次之后再次使用将不显示分区出现错误，检测不出错误了）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mount -a</span></span><br><span class="line">[  34.606814] EXT4-fs (nvme1n1p4): warning: mounting fs with errors, running e2fsck is recommended</span><br><span class="line"></span><br><span class="line"><span class="comment"># lsblk</span></span><br><span class="line">NAME          MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS</span><br><span class="line">nvme1n1       259:0    0 931.5G  0 disk</span><br><span class="line">├─nvme1n1p1   259:1    0     1G  0 part /boot</span><br><span class="line">├─nvme1n1p2   259:2    0    32G  0 part [SWAP]</span><br><span class="line">├─nvme1n1p3   259:3    0   128G  0 part /</span><br><span class="line">└─nvme1n1p4   259:4    0 770.5G  0 part /home</span><br><span class="line">nvme0n1       259:5    0   1.9T  0 disk /mnt/data</span><br></pre></td></tr></table></figure><p>按提示使用e2fsck（Linux 系统中用于检查和修复 ext2、ext3、ext4 文件系统的命令行工具）</p><p>由于薛定谔的挂载，还是手动卸载挂载 <code>/home</code> 先</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># umount /dev/nvme0n1p4</span></span><br></pre></td></tr></table></figure><p>然后使用工具修复</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># e2fsck -y /dev/nvme0n1p4</span></span><br><span class="line">......</span><br><span class="line">/dev/nvme0n1p4: ***** FILE SYSTEM WAS MODIFIED ***** </span><br><span class="line">/dev/nvme0n1p4: 309933/50503680 files (1.3% non-contiguous), 17569752/201985024 blocks </span><br></pre></td></tr></table></figure><p>重启完事</p><p>原因猜测：<br>这几天我没有进行系统更新啥的，也没有修改系统设置。<br>唯一让我觉得有关联的事情就是，前段时间宿舍频繁停电，可能埋下了问题。<br>也有可能是其他原因。</p><h1 id="强制关机导致文件系统受损"><a href="#强制关机导致文件系统受损" class="headerlink" title="强制关机导致文件系统受损"></a>强制关机导致文件系统受损</h1><p>Jan 01, 2026</p><p>那天我正在虚拟机干活，隐约记得的是，在虚拟机打开微信的小程序后整个虚拟机卡住了，CPU占用率80%，但是宿主机还没有崩溃，然后我选择关闭虚拟机，然后…就又又又损坏了文件系统……</p><p>具体表现是开机进不了系统，显示：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[ OK ] Stopped Virtual Console Setup.</span><br><span class="line">Starting Virtual Console Setup...</span><br><span class="line">[ OK ] Found device WD Blue SN570 1TB SSD root.</span><br><span class="line">[ OK ] Reached target Initrd Root Device.</span><br><span class="line">Starting File System Check on /dev/disk/by-uuid/84c2a117-1984-4674-a991</span><br><span class="line">[FAILED] Failed to start File System Check on /dev/disk/by-uuid/84c2a117-1984-4674-a991. See &#x27;systemctl status systemd-fsck-root.service’ for details.</span><br><span class="line">[DEPEND] Dependency failed for /sysroot.</span><br><span class="line">[DEPEND] Dependency failed for Initrd Root File System.</span><br><span class="line">[DEPEND] Dependency failed for Mountpoints Configured in the Real Root.</span><br><span class="line">[ OK ] Stopped target Basic System.</span><br><span class="line">[ OK ] Reached target Emergency Mode.</span><br><span class="line">[ OK ] Stopped target System Initialization.</span><br><span class="line">[ OK ] Started Emergency Shell.</span><br><span class="line">[ OK ] Reached target Emergency Mode.</span><br><span class="line"></span><br><span class="line">You are in emergency mode. After logging in, type &quot;journalctl -xb” to view system logs, “systemctl reboot&quot; to reboot, or &quot;exit&quot; to continue bootup.</span><br><span class="line">Cannot open access to console, the root account is locked. See sulogin(8) man page for more details.</span><br><span class="line">Press Enter to continue</span><br></pre></td></tr></table></figure><p>大概是这个样的，但是按了回车后依旧卡住没反应，只能请出我的 ArchLinux ISO 了……</p><p>进去首先先扫扫硬盘分区看看能不能扫出来，</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ lsblk -o +FSTYPE,PARTTYPENAME,UUID</span><br><span class="line">NAME        MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS FSTYPE PARTTYPENAME     UUID</span><br><span class="line">nvme0n1     259:0    0 931.5G  0 disk                                     </span><br><span class="line">├─nvme0n1p1 259:2    0     1G  0 part /boot       vfat   EFI System       C495-41D3</span><br><span class="line">├─nvme0n1p2 259:3    0    32G  0 part [SWAP]      swap   Linux swap       1bc97bf5-4fc2-412c-a482-08ba80bb7389</span><br><span class="line">├─nvme0n1p3 259:4    0   128G  0 part /           ext4   Linux filesystem 04c2a117-1984-4b74-a991-8c869db4c7bc</span><br><span class="line">└─nvme0n1p4 259:5    0 770.5G  0 part /home       ext4   Linux filesystem 0d34532b-4120-4ad6-8153-e208696ac4f1</span><br><span class="line">nvme1n1     259:1    0   1.9T  0 disk /mnt/data   ext4                    909f516c-e629-4444-8c0b-745465bc8d70</span><br></pre></td></tr></table></figure><p>扫出来了的话，因为我的文件系统是 EXT4，所以要用到 <a href="wiki.archlinux.org/title/Fsck">fsck</a> 。</p><p>使用 fsck 以只读的方式去读下分区：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fsck.ext4 -n /dev/xxx</span><br></pre></td></tr></table></figure><blockquote><p>我听大佬说 fsck 修复不是万能的，可能还会加剧损坏，那我只好先备份我的 &#x2F;home 下的一些重要资料了（我有两个盘）。<br>当然这也是为什么上面使用只读的方式扫盘的原因，而不是直接修复。</p></blockquote><p>果然是系统分区出的问题，读 nvme0n1p3 系统分区时弹出一堆信息，显示 error。</p><p>还是先备份吧……<br>Archlinux ISO 的默认挂载目录是 <code>/mnt</code>（不需要自己创建），先创建两个挂载点，然后 <strong>挂载源与目标分区</strong> ：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建挂载点</span></span><br><span class="line"><span class="built_in">mkdir</span> -p /mnt/source /mnt/backup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 挂载源分区</span></span><br><span class="line">mount /dev/nvme1n1p4 /mnt/source</span><br><span class="line"><span class="comment"># 挂载目标分区</span></span><br><span class="line">mount /dev/nvme0n1 /mnt/backup</span><br></pre></td></tr></table></figure><p>这时可以用 ls 之类的看看 &#x2F;mnt&#x2F;source 的文件，选出要备份的目录&#x2F;文件，使用 <code>cp</code> 或者 <code>rsync</code> 完成数据复制，例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> -a /mnt/source/download/ /mnt/backup/download/</span><br><span class="line"><span class="built_in">cp</span> -a /mnt/source/Document/ /mnt/backup/Document/</span><br><span class="line"><span class="built_in">cp</span> -a /mnt/source/software/ /mnt/backup/software/</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>然后就是修复文件系统了，但是在这之前，<strong>需要把挂载的分区全部卸载避免损坏！！！</strong>（建议重启一下自动卸载）</p><p>然后就是让它自动修复了，反正我也看不懂怎么判断选择要修复的 Inode 相关的东西：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fsck -y /dev/nvme1n1p3</span><br></pre></td></tr></table></figure><p>之后貌似成功了，使用 fsck 读取不再提示损坏。<br>最后关机重启结束。</p><p>原因猜测：smartmontools扫过一下硬盘也没事。基本每次断电文件系统都会出问题，也许是我的 EXT4 的 Commit 时间设置太过激进了吗？</p>]]></content>
      
      
      <categories>
          
          <category> GNU/Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Archlinux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Arch日常维护手册</title>
      <link href="/0b5e5b638425/"/>
      <url>/0b5e5b638425/</url>
      
        <content type="html"><![CDATA[<h1 id="包管理"><a href="#包管理" class="headerlink" title="包管理"></a>包管理</h1><h2 id="pacman"><a href="#pacman" class="headerlink" title="pacman"></a>pacman</h2><h3 id="升级"><a href="#升级" class="headerlink" title="升级"></a>升级</h3><p>升级系统及所有已经安装的软件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacman -Syu</span><br></pre></td></tr></table></figure><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>直接安装某一个包</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacman -S &lt;packageName&gt;</span><br></pre></td></tr></table></figure><h3 id="安装原因"><a href="#安装原因" class="headerlink" title="安装原因"></a>安装原因</h3><p>pacman 数据库将软件包按照安装的原因分为两类：</p><ul><li><strong>显式安装</strong>：那些真正地被传递给通用 pacman <code>-S</code>和<code>-U</code>命令的包；</li><li><strong>依赖</strong>：那些虽然（一般）从未被传递给 pacman 安装命令，但由于被其它显式安装的包<a href="https://wiki.archlinuxcn.org/wzh/index.php?title=Dependency&action=edit&redlink=1" title="Dependency（页面不存在）">需要</a>从而被隐式安装的包</li></ul><p>当安装软件包时，可以把安装原因强制设为<strong>依赖</strong>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacman -S --asdeps &lt;package_name&gt;</span><br></pre></td></tr></table></figure><p>该命令使用的原因通常是显式安装的包可能会提供<a href="https://wiki.archlinuxcn.org/wiki/PKGBUILD#optdepends" title="PKGBUILD">可选安装包</a>，这些包提供了非必须功能，可供用户自由选择。</p><blockquote><p>提示：用<code>--asdeps</code>安装可选依赖将确保如果你<a href="https://wiki.archlinuxcn.org/wiki/Pacman/%E6%8F%90%E7%A4%BA%E5%92%8C%E6%8A%80%E5%B7%A7#%E5%88%A0%E9%99%A4%E6%9C%AA%E4%BD%BF%E7%94%A8%E7%9A%84%E8%BD%AF%E4%BB%B6%E5%8C%85%EF%BC%88%E5%AD%A4%E7%AB%8B%E8%BD%AF%E4%BB%B6%E5%8C%85%EF%BC%89" title="Pacman&#x2F;提示和技巧">移除孤立包</a>，pacman 将会一同移除按照上述方法指定安装的可选依赖。</p></blockquote><p>但是重新安装该软件包，当前安装原因默认会被保留。</p><p>显式安装的软件包列表可用<code>pacman -Qe</code>获取, 设置为依赖的软件包可用<code>pacman -Qd</code>获取。</p><p>改变某个已安装软件包的安装原因，可以执行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacman -D --asdeps &lt;package_name&gt;</span><br></pre></td></tr></table></figure><p>反过来的对应参数<code>--asexplicit</code></p><p><strong>注意：</strong> 在升级时使用<code>--asdeps</code>和<code>--asexplicit</code>选项，例如<code>pacman -Syu &lt;package_name&gt; --asdeps</code>，是不被推荐的。这会导致不仅改变要被安装的软件包的安装原因，也会改变被升级的软件包的安装原因。</p><blockquote><p>根据2021.05-1之后的行为变化，即使指定了 <code>--asdeps</code> 参数，<code>&lt;package_name&gt;</code> 本身仍然会被视为显式安装的包。只能显示安装后在通过 <code>pacman -D --asdeps &lt;package_name&gt;</code> 变为以依赖安装</p></blockquote><h3 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">pacman -Ss &lt;packageName&gt; <span class="comment"># 在仓库中搜索含关键字的软件包（本地已安装的会标记）</span></span><br><span class="line"></span><br><span class="line">pacman -Qs &lt;packageName&gt; <span class="comment"># 搜索已安装的软件包</span></span><br><span class="line"></span><br><span class="line">pacman -Qu <span class="comment"># 列出所有可升级的软件包</span></span><br><span class="line"></span><br><span class="line">pacman -Qt <span class="comment"># 列出不被任何软件要求的软件包</span></span><br><span class="line"></span><br><span class="line">pacman -Q &lt;packageName&gt; <span class="comment"># 查看软件包是否已安装，已安装则显示软件包名称和版本</span></span><br><span class="line"></span><br><span class="line">pacman -Qi &lt;packageName&gt; <span class="comment"># 查看某个软件包信息，显示较为详细的信息，包括描述、构架、依赖、大小等等</span></span><br><span class="line"></span><br><span class="line">pacman -Ql &lt;packageName&gt; <span class="comment"># 列出软件包内所有文件，包括软件安装的每个文件、文件夹的名称和路径</span></span><br><span class="line"></span><br><span class="line">pacman -Qo /path/to/a/file <span class="comment"># 可以通过查询数据库获知目前你的文件系统中某个文件是属于哪个软件包</span></span><br><span class="line"></span><br><span class="line">pacman -Qdt <span class="comment"># 罗列所有不再作为依赖的软件包（孤立 orphans)</span></span><br></pre></td></tr></table></figure><h3 id="清理"><a href="#清理" class="headerlink" title="清理"></a>清理</h3><p>删除孤立软件包</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacman -Rns $(pacman -Qtdq)</span><br></pre></td></tr></table></figure><p>删除当前未安装的所有缓存包和未使用的同步数据库</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacman -Sc</span><br></pre></td></tr></table></figure><p>从缓存中删除所有文件，这是最激进的方法，不会在缓存文件夹中留下任何内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacman -Scc</span><br></pre></td></tr></table></figure><h3 id="卸载"><a href="#卸载" class="headerlink" title="卸载"></a>卸载</h3><p>删除指定软件包，及其所有没有被其他已安装软件包使用的依赖关系：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pacman -Rns &lt;packageName&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># -R 删除单个软件包，会保留其全部已经安装的依赖关系</span></span><br><span class="line"><span class="comment"># -n pacman 删除某些程序时会备份重要配置文件，在其后面加上*.pacsave扩展名。-n 选项可以避免备份这些文件</span></span><br><span class="line"><span class="comment"># -s 删除其所有没有被其他已安装软件包使用的依赖关系</span></span><br></pre></td></tr></table></figure><h3 id="其他用法"><a href="#其他用法" class="headerlink" title="其他用法"></a>其他用法</h3><p>在不同的 <code>-大写字母</code>，可跟着不同的小写字母实现更多不同的功能，具体可用指南查看</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pacman -h <span class="comment"># 查看指南</span></span><br><span class="line"></span><br><span class="line">pacman &#123;-R --remove&#125; <span class="comment"># 查看 -R 的可选参数</span></span><br></pre></td></tr></table></figure><h2 id="yay"><a href="#yay" class="headerlink" title="yay"></a>yay</h2><h3 id="升级-1"><a href="#升级-1" class="headerlink" title="升级"></a>升级</h3><p>升级系统，相当于yay -Syu</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yay</span><br></pre></td></tr></table></figure><h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yay -S &lt;packageName&gt;</span><br></pre></td></tr></table></figure><h3 id="搜索-1"><a href="#搜索-1" class="headerlink" title="搜索"></a>搜索</h3><p>查看仅通过yay安装的包</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yay -Qm</span><br></pre></td></tr></table></figure><h3 id="卸载-1"><a href="#卸载-1" class="headerlink" title="卸载"></a>卸载</h3><p>要删除包及其依赖项</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yay -Rns &lt;packageName&gt;</span><br></pre></td></tr></table></figure><h3 id="清理-1"><a href="#清理-1" class="headerlink" title="清理"></a>清理</h3><p>清理 yay 缓存</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> -rf ~/.cache/yay</span><br></pre></td></tr></table></figure><p>清理孤立的包</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yay -Yc</span><br><span class="line"></span><br><span class="line"><span class="comment"># -Y：表示同时清理未使用的依赖项。</span></span><br><span class="line"><span class="comment"># -c：表示清理缓存，即删除已下载的软件包文件。</span></span><br></pre></td></tr></table></figure><h3 id="其他用法-1"><a href="#其他用法-1" class="headerlink" title="其他用法"></a>其他用法</h3><p>打印系统统计信息，显示已安装软件包和系统健康状况的统计数据</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yay -Ps</span><br></pre></td></tr></table></figure><h2 id="pacnew处理"><a href="#pacnew处理" class="headerlink" title="pacnew处理"></a>pacnew处理</h2><p>处理过程基本一致，请看<code>mkinitcpio.conf变动</code>章节</p><h2 id="mkinitcpio-conf变动"><a href="#mkinitcpio-conf变动" class="headerlink" title="mkinitcpio.conf变动"></a>mkinitcpio.conf变动</h2><p>在Arch Linux系统中，<code>mkinitcpio.conf</code> 是一个非常重要的配置文件，它用于定义在初始化ramdisk（initrd或initramfs）创建过程中包含哪些模块和文件。<br>这个配置对系统启动至关重要。当系统更新并且这个更新影响到 <code>mkinitcpio</code> 时，可能会生成一个新的配置文件示例，名为 <code>mkinitcpio.conf.pacnew</code> 。</p><p>处理 <code>mkinitcpio.conf</code> 和 <code>mkinitcpio.conf.pacnew</code> 文件步骤如下：</p><ol><li>首先，你需要检查 <code>.pacnew</code> 文件与现有的 <code>mkinitcpio.conf</code> 文件之间的差异。可以使用 <code>nvim -d</code> （Diff mode）来完成这一任务。如：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvim -d /etc/mkinitcpio.conf /etc/mkinitcpio.conf.pacnew</span><br><span class="line"><span class="comment"># 这将显示两个文件之间的差异。vimdiff 的使用看 vim 篇</span></span><br></pre></td></tr></table></figure><ol start="2"><li>在做任何更改之前，建议备份原始的 <code>mkinitcpio.conf</code> 文件。这样，如果新的配置导致问题，你可以轻松地回滚到之前的配置。如：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> /etc/mkinitcpio.conf /etc/mkinitcpio.conf.bak</span><br></pre></td></tr></table></figure><ol start="3"><li><p>把 <code>mkinitcpio.conf.pavnew</code> 的新增参数内容复制到 <code>mkinitcpio.conf</code> ，对于不同的参数的值，请谨慎更改或保留。（建议使用 vim&#x2F;neovim 的 <a href="https://neovim.io/doc/user/diff.html#_1.-starting-diff-mode">diff 模式</a> 完成）</p></li><li><p>一旦你合并了并保存了 <code>mkinitcpio.conf</code> 文件，你需要重新生成 initramfs 使更改生效：</p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkinitcpio -P</span><br><span class="line"><span class="comment"># 为所有已安装的内核生成新的initramfs。</span></span><br></pre></td></tr></table></figure><ol start="5"><li>更改生效后，重启你的系统以确保一切正常工作。没啥问题就可以删除<code>.pacnew</code>文件和备份文件了</li></ol><h3 id="mkinitcpio-P"><a href="#mkinitcpio-P" class="headerlink" title="mkinitcpio -P"></a>mkinitcpio -P</h3><p>命令<code>mkinitcpio -P</code>在Arch Linux及其衍生系统中用于重新生成所有已安装内核的初始RAM磁盘（initramfs）。initramfs是一个临时的根文件系统，加载到内存中，在Linux系统启动过程中被用来准备真正的根文件系统。</p><p>具体来说，<code>mkinitcpio -P</code>命令的作用包括：</p><ul><li><p><strong>自动检测</strong>：该命令会自动检测<code>/boot</code>目录下所有已安装的Linux内核，并为每个内核生成对应的initramfs。这意味着如果你有多个内核版本（例如，标准Linux内核和LTS版本内核），该命令将为它们每一个重新生成initramfs。</p></li><li><p><strong>应用配置更改</strong>：如果你更改了<code>/etc/mkinitcpio.conf</code>配置文件或者相关的钩子脚本（hooks），使用<code>mkinitcpio -P</code>可以确保这些更改被应用到所有内核的initramfs中。这对于添加驱动、修改启动行为等操作至关重要。</p></li><li><p><strong>修复启动问题</strong>：在某些情况下，如果系统无法启动，可能是因为initramfs损坏或配置不正确。在这种情况下，重新生成initramfs可能有助于解决问题。</p></li><li><p><strong>更新内核后的必要步骤</strong>：当通过包管理器更新Linux内核后，通常会自动重新生成initramfs。然而，在手动安装或更新内核、更改重要的启动配置时，运行<code>mkinitcpio -P</code>确保initramfs是最新的并且包含所有必要的模块和配置。</p></li></ul><h1 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h1><h2 id="df命令（Disk-Free）"><a href="#df命令（Disk-Free）" class="headerlink" title="df命令（Disk Free）"></a>df命令（Disk Free）</h2><p>显示 <strong>文件系统级别（挂载的磁盘&#x2F;分区）</strong> 的整体磁盘空间使用情况，包括总容量、已用空间、剩余空间等。-h 后的默认参数为 <code>/</code> ，即根目录，查看的是根目录中所有分区的空间使用。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">df</span> -h <span class="comment"># 以人类可读格式显示</span></span><br></pre></td></tr></table></figure><p>若想查看指定一目录的分区的空间使用情况，可以在 -h 后自定义</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">df</span> -h /mnt <span class="comment"># 查看/mnt目录下空间使用情况</span></span><br></pre></td></tr></table></figure><h2 id="du命令（Disk-Usage）"><a href="#du命令（Disk-Usage）" class="headerlink" title="du命令（Disk Usage）"></a>du命令（Disk Usage）</h2><p>计算 <strong>文件或目录</strong> 的实际磁盘使用量（递归统计文件和子目录占用的空间）。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">du</span> -sh /path/to/dir   <span class="comment"># 统计目录总大小（-s 汇总，-h 易读格式）</span></span><br><span class="line"><span class="built_in">du</span> -ah /path/to/dir   <span class="comment"># 显示目录下所有文件和子目录的详细大小</span></span><br></pre></td></tr></table></figure><h2 id="Smartmontools"><a href="#Smartmontools" class="headerlink" title="Smartmontools"></a>Smartmontools</h2><ol><li>安装 smartmontools</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacman -S smartmontools</span><br></pre></td></tr></table></figure><ol start="2"><li>使用以下命令获取磁盘设备名称或路径</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fdisk -l</span><br></pre></td></tr></table></figure><ol start="3"><li>使用 <code>smartctl</code> 命令来查看磁盘信息：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">smartctl -A /dev/sdx <span class="comment"># 硬盘</span></span><br><span class="line">smartctl -d sat -A /dev/sdx <span class="comment"># USB 设备</span></span><br></pre></td></tr></table></figure><p>   这两个命令的主要区别是添加了 <code>-d</code> 选项，该选项指定驱动程序，以便 <code>smartctl</code> 可以与相应的设备进行通信。<br>   如果需要更加详细的信息，请把 <code>-A</code> 改为 <code>-a</code> 。</p><h2 id="trim"><a href="#trim" class="headerlink" title="trim"></a>trim</h2><ol><li>查看trim定时器状态</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl status fstrim.timer  </span><br></pre></td></tr></table></figure><ol start="2"><li>手动 trim</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fstrim -a -v</span><br></pre></td></tr></table></figure><ul><li><code>-a</code> 或 <code>--all</code>：这个选项指示<code>fstrim</code>命令尝试对所有挂载的文件系统进行trim操作，但它会跳过那些不支持trim的文件系统。</li><li><code>-v</code> 或 <code>--verbose</code>：这个选项让<code>fstrim</code>命令在执行时显示更多信息，特别是关于它对每个文件系统进行了多少trim操作的详细信息。</li></ul><h1 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h1><h2 id="日志清理"><a href="#日志清理" class="headerlink" title="日志清理"></a>日志清理</h2><p>清理最早两周前的日志.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">journalctl --vacuum-time=2s</span><br></pre></td></tr></table></figure><p>清理日志使总大小小于 100M:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">journalctl --vacuum-size=100M</span><br></pre></td></tr></table></figure><h2 id="pacman日志"><a href="#pacman日志" class="headerlink" title="pacman日志"></a>pacman日志</h2><p>一般只会保留数天的记录，使用 cat 抓取就行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> /var/log/pacman.log </span><br></pre></td></tr></table></figure><h2 id="读取日志"><a href="#读取日志" class="headerlink" title="读取日志"></a>读取日志</h2><p>检查上一次引导（boot）时的系统日志的命令（包括内核和用户空间日志）。依赖 <code>systemd-journald</code> 的持久化存储。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">journalctl -b -1</span><br><span class="line"></span><br><span class="line"><span class="comment"># `-b` 表示启动周期（`boot`），`-1` 表示上一次启动（`-0` 是当前启动，默认值）。</span></span><br></pre></td></tr></table></figure><hr><p>直接读取 <strong>内核环形缓冲区</strong>（<code>kernel ring buffer</code>）的内容，记录内核启动过程中和运行时的日志（如硬件检测、驱动加载、内核错误等）。<br>这些日志是内核直接生成的，<strong>不依赖任何日志系统</strong>（如 <code>systemd-journald</code>）。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> dmesg</span><br><span class="line"></span><br><span class="line"><span class="comment"># 默认显示当前启动周期的内核日志（重启后会丢失之前的日志）。  </span></span><br><span class="line"><span class="comment"># 可通过 `-T` 或 `--time-format` 选项显示时间戳（需内核支持）。</span></span><br></pre></td></tr></table></figure><h1 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h1><h2 id="1-使用ps命令"><a href="#1-使用ps命令" class="headerlink" title="1. 使用ps命令"></a>1. 使用ps命令</h2><p><code>ps</code>命令是一个非常通用的命令，它在几乎所有的Linux发行版中都可用，包括Arch Linux。</p><p>查看当前系统中的所有进程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef</span><br></pre></td></tr></table></figure><p>  这里，<code>-e</code>表示显示所有进程，<code>-f</code>表示全格式显示。</p><p>查看与某个用户相关的进程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -u &lt;用户名&gt;</span><br></pre></td></tr></table></figure><p>查看某个特定进程的信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -p &lt;进程ID&gt;</span><br></pre></td></tr></table></figure><h2 id="2-使用top命令"><a href="#2-使用top命令" class="headerlink" title="2. 使用top命令"></a>2. 使用top命令</h2><p><code>top</code>命令提供了一个实时更新的进程列表，显示系统中进程的动态视图。</p><p>启动<code>top</code>命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top</span><br></pre></td></tr></table></figure><p><code>top</code>命令会显示一系列的进程信息，包括CPU使用率、内存使用率等。可以在<code>top</code>运行时按键来改变其行为:</p><ol><li>如按<code>P</code>排序显示CPU使用率最高的进程。</li><li>按 <code>q</code> 退出。</li></ol><blockquote><p>可以使用拥有更好交互图形界面的 htop。</p></blockquote><h1 id="蓝牙"><a href="#蓝牙" class="headerlink" title="蓝牙"></a>蓝牙</h1><p>开启蓝牙服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl start bluetooth</span><br></pre></td></tr></table></figure><h1 id="WIFI-NetworkManager"><a href="#WIFI-NetworkManager" class="headerlink" title="WIFI-NetworkManager"></a>WIFI-NetworkManager</h1><h2 id="nmcli-examples"><a href="#nmcli-examples" class="headerlink" title="nmcli examples"></a>nmcli examples</h2><p><a href="https://wiki.archlinuxcn.org/wiki/NetworkManager">https://wiki.archlinuxcn.org/wiki/NetworkManager</a></p><p>List nearby Wi-Fi networks:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nmcli device wifi list</span><br></pre></td></tr></table></figure><p>Connect to a Wi-Fi network:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nmcli device wifi connect _SSID_or_BSSID_ password _password_</span><br></pre></td></tr></table></figure><p>Connect to a hidden Wi-Fi network:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nmcli device wifi connect _SSID_or_BSSID_ password _password_ hidden <span class="built_in">yes</span></span><br></pre></td></tr></table></figure><p>Get a list of connections with their names, UUIDs, types and backing devices:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nmcli connection show</span><br></pre></td></tr></table></figure><p>Delete a connection:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nmcli connection delete _name_or_uuid_</span><br></pre></td></tr></table></figure><p>See a list of network devices and their state:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nmcli device</span><br></pre></td></tr></table></figure><p>Turn off Wi-Fi:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nmcli radio wifi off</span><br></pre></td></tr></table></figure><h1 id="临时粘贴版-fars-ee"><a href="#临时粘贴版-fars-ee" class="headerlink" title="临时粘贴版 fars.ee"></a>临时粘贴版 fars.ee</h1><p>官网： <a href="http://fars.ee/">http://fars.ee/</a></p><p><del>用于把日志、配置贴到任何人都能访问的网络上，用于让大佬给你分析问题</del></p><blockquote><p>注意隐私</p></blockquote><p>以下为基本使用，更多用法看官网<br>Create a paste from the output of ‘dmesg’:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ dmesg | curl -F <span class="string">&quot;c=@-&quot;</span> <span class="string">&quot;http://fars.ee/&quot;</span></span><br><span class="line"></span><br><span class="line">:<span class="string">&#x27; output</span></span><br><span class="line"><span class="string">long: AGhkV6JANmmQRVssSUzFWa_0VNyq</span></span><br><span class="line"><span class="string">sha1: 686457a240366990455b2c494cc559aff454dcaa</span></span><br><span class="line"><span class="string">short: VNyq</span></span><br><span class="line"><span class="string">url: http://fars.ee/VNyq</span></span><br><span class="line"><span class="string">uuid: 17c5829d-81a0-4eb6-8681-ba72f83ffbf3</span></span><br><span class="line"><span class="string">&#x27;</span></span><br></pre></td></tr></table></figure><h1 id="显卡"><a href="#显卡" class="headerlink" title="显卡"></a>显卡</h1><p>首先确保已经安装了 <code>mesa-utils</code> 、<code>lib32-nvidia-utils</code>、<code>nvidia-utils</code>、<code>nvidia</code> 和 <code>nvidia-utils</code>等相关驱动（或者AMD的相关包）</p><h2 id="查看当前的显卡渲染器"><a href="#查看当前的显卡渲染器" class="headerlink" title="查看当前的显卡渲染器"></a>查看当前的显卡渲染器</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">glxinfo | grep <span class="string">&quot;OpenGL renderer&quot;</span></span><br></pre></td></tr></table></figure><h2 id="监控-Nvidia-GPU"><a href="#监控-Nvidia-GPU" class="headerlink" title="监控 Nvidia GPU"></a>监控 Nvidia GPU</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure><h1 id="Archiving-and-compression"><a href="#Archiving-and-compression" class="headerlink" title="Archiving and compression"></a>Archiving and compression</h1><h2 id="推荐算法"><a href="#推荐算法" class="headerlink" title="推荐算法"></a>推荐算法</h2><ul><li>LZMA2(xz)：高压缩率的代表，但是压缩&#x2F;解压占用更多的cpu等资源</li><li>Zstd：是LZMA2和LZ4的平衡，压缩率与速度的性价比很高</li><li>LZ4：极速压缩&#x2F;解压的代表，占用资源低，但是压缩率比较低</li></ul><p>根据数据的冷热自行选择</p><h2 id="bsdtar"><a href="#bsdtar" class="headerlink" title="bsdtar"></a>bsdtar</h2><blockquote><p>提示：GNU 和 BSD tar 都自动为 bzip2、compress、gzip、lzip、lzma、lzop、zstd 和 xz 压缩归档执行解压缩。lz4 只有 BSD tar 支持（但是 GNU tar 可以使用–use-compress-program&#x3D;lz4&#x2F;-Ilz4进行等效操作）。当创建归档文件时，两者都支持-a开关，以根据文件扩展名通过正确的压缩程序自动处理创建的归档。BSD tar 根据格式识别压缩格式，而 GNU tar 只根据文件扩展名猜测压缩格式。</p></blockquote><p><a href="https://man.archlinux.org/man/bsdtar.1">bsdtar-man手册</a></p><p>常规用法：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">First option must be a mode specifier:</span><br><span class="line">  -c Create  -r Add/Replace  -t List  -u Update  -x Extract</span><br><span class="line">Common Options:</span><br><span class="line">  -b <span class="comment">#  Use # 512-byte records per I/O block</span></span><br><span class="line">  -f &lt;filename&gt;  Location of archive (default /dev/st0)</span><br><span class="line">  -v    Verbose</span><br><span class="line">  -w    Interactive</span><br><span class="line">Create: bsdtar -c [options] [&lt;file&gt; | &lt;<span class="built_in">dir</span>&gt; | @&lt;archive&gt; | -C &lt;<span class="built_in">dir</span>&gt; ]</span><br><span class="line">  &lt;file&gt;, &lt;<span class="built_in">dir</span>&gt;  add these items to archive</span><br><span class="line">  -z, -j, -J, --lzma  Compress archive with gzip/bzip2/xz/lzma</span><br><span class="line">  --format &#123;ustar|pax|cpio|shar&#125;  Select archive format</span><br><span class="line">  --exclude &lt;pattern&gt;  Skip files that match pattern</span><br><span class="line">  -C &lt;<span class="built_in">dir</span>&gt;  Change to &lt;<span class="built_in">dir</span>&gt; before processing remaining files</span><br><span class="line">  @&lt;archive&gt;  Add entries from &lt;archive&gt; to output</span><br><span class="line">List: bsdtar -t [options] [&lt;patterns&gt;]</span><br><span class="line">  &lt;patterns&gt;  If specified, list only entries that match</span><br><span class="line">Extract: bsdtar -x [options] [&lt;patterns&gt;]</span><br><span class="line">  &lt;patterns&gt;  If specified, extract only entries that match</span><br><span class="line">  -k    Keep (don<span class="string">&#x27;t overwrite) existing files</span></span><br><span class="line"><span class="string">  -m    Don&#x27;</span>t restore modification <span class="built_in">times</span></span><br><span class="line">  -O    Write entries to stdout, don<span class="string">&#x27;t restore to disk</span></span><br><span class="line"><span class="string">  -p    Restore permissions (including ACLs, owner, file flags)</span></span><br></pre></td></tr></table></figure><p>示例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bsdtar -cJf &lt;archive_name.tar.xz&gt; [--options xz:compression-level=9] &lt;/path/to/directory&gt;</span><br></pre></td></tr></table></figure><p>针对 .tar.xz 文件完整性检查</p><ul><li>bsdtar 的 -t 选项可以列出压缩包内的文件列表，确保元数据正常。如果压缩包损坏，此操作会直接报错。</li><li>通过对比归档的哈希值，确保整个归档未被篡改<br>e.g.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bsdtar -tvf &lt;filename&gt;</span><br><span class="line"></span><br><span class="line"><span class="built_in">sha256sum</span> &lt;filename&gt;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> GNU/Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Archlinux </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
